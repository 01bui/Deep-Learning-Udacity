{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4embtkV0pNxM"
   },
   "source": [
    "Deep Learning\n",
    "=============\n",
    "\n",
    "Assignment 4\n",
    "------------\n",
    "\n",
    "Previously in `2_fullyconnected.ipynb` and `3_regularization.ipynb`, we trained fully connected networks to classify [notMNIST](http://yaroslavvb.blogspot.com/2011/09/notmnist-dataset.html) characters.\n",
    "\n",
    "The goal of this assignment is make the neural network convolutional."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "cellView": "both",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "tm2CQN_Cpwj0"
   },
   "outputs": [],
   "source": [
    "# These are all the modules we'll be using later. Make sure you can import them\n",
    "# before proceeding further.\n",
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from six.moves import cPickle as pickle\n",
    "from six.moves import range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "cellView": "both",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "collapsed": false,
    "executionInfo": {
     "elapsed": 11948,
     "status": "ok",
     "timestamp": 1446658914837,
     "user": {
      "color": "",
      "displayName": "",
      "isAnonymous": false,
      "isMe": true,
      "permissionId": "",
      "photoUrl": "",
      "sessionId": "0",
      "userId": ""
     },
     "user_tz": 480
    },
    "id": "y3-cj1bpmuxc",
    "outputId": "016b1a51-0290-4b08-efdb-8c95ffc3cd01"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set (200000, 28, 28) (200000,)\n",
      "Validation set (10000, 28, 28) (10000,)\n",
      "Test set (10000, 28, 28) (10000,)\n"
     ]
    }
   ],
   "source": [
    "pickle_file = 'notMNIST.pickle'\n",
    "\n",
    "with open(pickle_file, 'rb') as f:\n",
    "  save = pickle.load(f)\n",
    "  train_dataset = save['train_dataset']\n",
    "  train_labels = save['train_labels']\n",
    "  valid_dataset = save['valid_dataset']\n",
    "  valid_labels = save['valid_labels']\n",
    "  test_dataset = save['test_dataset']\n",
    "  test_labels = save['test_labels']\n",
    "  del save  # hint to help gc free up memory\n",
    "  print('Training set', train_dataset.shape, train_labels.shape)\n",
    "  print('Validation set', valid_dataset.shape, valid_labels.shape)\n",
    "  print('Test set', test_dataset.shape, test_labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "L7aHrm6nGDMB"
   },
   "source": [
    "Reformat into a TensorFlow-friendly shape:\n",
    "- convolutions need the image data formatted as a cube (width by height by #channels)\n",
    "- labels as float 1-hot encodings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "cellView": "both",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "collapsed": false,
    "executionInfo": {
     "elapsed": 11952,
     "status": "ok",
     "timestamp": 1446658914857,
     "user": {
      "color": "",
      "displayName": "",
      "isAnonymous": false,
      "isMe": true,
      "permissionId": "",
      "photoUrl": "",
      "sessionId": "0",
      "userId": ""
     },
     "user_tz": 480
    },
    "id": "IRSyYiIIGIzS",
    "outputId": "650a208c-8359-4852-f4f5-8bf10e80ef6c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set (200000, 28, 28, 1) (200000, 10)\n",
      "Validation set (10000, 28, 28, 1) (10000, 10)\n",
      "Test set (10000, 28, 28, 1) (10000, 10)\n"
     ]
    }
   ],
   "source": [
    "image_size = 28\n",
    "num_labels = 10\n",
    "num_channels = 1 # grayscale\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def reformat(dataset, labels):\n",
    "  dataset = dataset.reshape((-1, image_size, image_size, num_channels)).astype(np.float32)\n",
    "  labels = (np.arange(num_labels) == labels[:,None]).astype(np.float32)\n",
    "  return dataset, labels\n",
    "train_dataset, train_labels = reformat(train_dataset, train_labels)\n",
    "valid_dataset, valid_labels = reformat(valid_dataset, valid_labels)\n",
    "test_dataset, test_labels = reformat(test_dataset, test_labels)\n",
    "print('Training set', train_dataset.shape, train_labels.shape)\n",
    "print('Validation set', valid_dataset.shape, valid_labels.shape)\n",
    "print('Test set', test_dataset.shape, test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "cellView": "both",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "AgQDIREv02p1"
   },
   "outputs": [],
   "source": [
    "def accuracy(predictions, labels):\n",
    "  return (100.0 * np.sum(np.argmax(predictions, 1) == np.argmax(labels, 1))\n",
    "          / predictions.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5rhgjmROXu2O"
   },
   "source": [
    "Let's build a small network with two convolutional layers, followed by one fully connected layer. Convolutional networks are more expensive computationally, so we'll limit its depth and number of fully connected nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "cellView": "both",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "IZYv70SvvOan"
   },
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "patch_size = 5\n",
    "depth = 16\n",
    "num_hidden = 64\n",
    "\n",
    "graph = tf.Graph()\n",
    "\n",
    "with graph.as_default():\n",
    "\n",
    "  # Input data.\n",
    "  tf_train_dataset = tf.placeholder(tf.float32, shape=(batch_size, image_size, image_size, num_channels))\n",
    "  tf_train_labels = tf.placeholder(tf.float32, shape=(batch_size, num_labels))\n",
    "  tf_valid_dataset = tf.constant(valid_dataset)\n",
    "  tf_test_dataset = tf.constant(test_dataset)\n",
    "  \n",
    "  # Variables.\n",
    "  layer1_weights = tf.Variable(tf.truncated_normal([patch_size, patch_size, num_channels, depth], stddev=0.1))\n",
    "  layer1_biases = tf.Variable(tf.zeros([depth]))\n",
    "  layer2_weights = tf.Variable(tf.truncated_normal([patch_size, patch_size, depth, depth], stddev=0.1))\n",
    "  layer2_biases = tf.Variable(tf.constant(1.0, shape=[depth]))\n",
    "  layer3_weights = tf.Variable(tf.truncated_normal([image_size // 4 * image_size // 4 * depth, num_hidden], stddev=0.1))\n",
    "  layer3_biases = tf.Variable(tf.constant(1.0, shape=[num_hidden]))\n",
    "  layer4_weights = tf.Variable(tf.truncated_normal([num_hidden, num_labels], stddev=0.1))\n",
    "  layer4_biases = tf.Variable(tf.constant(1.0, shape=[num_labels]))\n",
    "  \n",
    "  # Model.\n",
    "  def model(data):\n",
    "    conv = tf.nn.conv2d(data, layer1_weights, [1, 2, 2, 1], padding='SAME')\n",
    "    hidden = tf.nn.relu(conv + layer1_biases)\n",
    "    conv = tf.nn.conv2d(hidden, layer2_weights, [1, 2, 2, 1], padding='SAME')\n",
    "    hidden = tf.nn.relu(conv + layer2_biases)\n",
    "    shape = hidden.get_shape().as_list()\n",
    "    reshape = tf.reshape(hidden, [shape[0], shape[1] * shape[2] * shape[3]])\n",
    "    hidden = tf.nn.relu(tf.matmul(reshape, layer3_weights) + layer3_biases)\n",
    "    return tf.matmul(hidden, layer4_weights) + layer4_biases\n",
    "  \n",
    "  # Training computation.\n",
    "  logits = model(tf_train_dataset)\n",
    "  loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits, tf_train_labels))\n",
    "    \n",
    "  # Optimizer.\n",
    "  optimizer = tf.train.GradientDescentOptimizer(0.05).minimize(loss)\n",
    "  \n",
    "  # Predictions for the training, validation, and test data.\n",
    "  train_prediction = tf.nn.softmax(logits)\n",
    "  valid_prediction = tf.nn.softmax(model(tf_valid_dataset))\n",
    "  test_prediction = tf.nn.softmax(model(tf_test_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "cellView": "both",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "output_extras": [
      {
       "item_id": 37
      }
     ]
    },
    "colab_type": "code",
    "collapsed": false,
    "executionInfo": {
     "elapsed": 63292,
     "status": "ok",
     "timestamp": 1446658966251,
     "user": {
      "color": "",
      "displayName": "",
      "isAnonymous": false,
      "isMe": true,
      "permissionId": "",
      "photoUrl": "",
      "sessionId": "0",
      "userId": ""
     },
     "user_tz": 480
    },
    "id": "noKFb2UovVFR",
    "outputId": "28941338-2ef9-4088-8bd1-44295661e628"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized\n",
      "Minibatch loss at step 0: 3.766778\n",
      "Minibatch accuracy: 6.2%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 50: 1.145408\n",
      "Minibatch accuracy: 56.2%\n",
      "Validation accuracy: 72.6%\n",
      "Minibatch loss at step 100: 0.816857\n",
      "Minibatch accuracy: 68.8%\n",
      "Validation accuracy: 76.8%\n",
      "Minibatch loss at step 150: 0.363143\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 77.4%\n",
      "Minibatch loss at step 200: 0.807926\n",
      "Minibatch accuracy: 81.2%\n",
      "Validation accuracy: 79.6%\n",
      "Minibatch loss at step 250: 0.941471\n",
      "Minibatch accuracy: 68.8%\n",
      "Validation accuracy: 79.3%\n",
      "Minibatch loss at step 300: 0.215978\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 79.7%\n",
      "Minibatch loss at step 350: 0.459496\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 79.0%\n",
      "Minibatch loss at step 400: 0.218808\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 80.7%\n",
      "Minibatch loss at step 450: 0.967271\n",
      "Minibatch accuracy: 81.2%\n",
      "Validation accuracy: 80.2%\n",
      "Minibatch loss at step 500: 0.634462\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 80.5%\n",
      "Minibatch loss at step 550: 1.181684\n",
      "Minibatch accuracy: 75.0%\n",
      "Validation accuracy: 80.3%\n",
      "Minibatch loss at step 600: 0.354366\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 81.2%\n",
      "Minibatch loss at step 650: 0.789978\n",
      "Minibatch accuracy: 81.2%\n",
      "Validation accuracy: 81.9%\n",
      "Minibatch loss at step 700: 0.996045\n",
      "Minibatch accuracy: 68.8%\n",
      "Validation accuracy: 81.0%\n",
      "Minibatch loss at step 750: 0.080528\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 82.4%\n",
      "Minibatch loss at step 800: 0.756224\n",
      "Minibatch accuracy: 68.8%\n",
      "Validation accuracy: 82.8%\n",
      "Minibatch loss at step 850: 0.947049\n",
      "Minibatch accuracy: 75.0%\n",
      "Validation accuracy: 82.4%\n",
      "Minibatch loss at step 900: 0.731823\n",
      "Minibatch accuracy: 81.2%\n",
      "Validation accuracy: 83.0%\n",
      "Minibatch loss at step 950: 0.586967\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 82.4%\n",
      "Minibatch loss at step 1000: 0.470123\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 81.9%\n",
      "Test accuracy: 89.1%\n"
     ]
    }
   ],
   "source": [
    "num_steps = 1001\n",
    "\n",
    "with tf.Session(graph=graph) as session:\n",
    "  tf.initialize_all_variables().run()\n",
    "  print('Initialized')\n",
    "  for step in range(num_steps):\n",
    "    offset = (step * batch_size) % (train_labels.shape[0] - batch_size)\n",
    "    #print(offset)\n",
    "    batch_data = train_dataset[offset:(offset + batch_size), :, :, :]\n",
    "    batch_labels = train_labels[offset:(offset + batch_size), :]\n",
    "    feed_dict = {tf_train_dataset : batch_data, tf_train_labels : batch_labels}\n",
    "    _, l, predictions = session.run([optimizer, loss, train_prediction], feed_dict=feed_dict)\n",
    "    if (step % 50 == 0):\n",
    "      print('Minibatch loss at step %d: %f' % (step, l))\n",
    "      print('Minibatch accuracy: %.1f%%' % accuracy(predictions, batch_labels))\n",
    "      print('Validation accuracy: %.1f%%' % accuracy(valid_prediction.eval(), valid_labels))\n",
    "  print('Test accuracy: %.1f%%' % accuracy(test_prediction.eval(), test_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test with ELU (Faster than RELU)\n",
    "Batch size changed from 16 to 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "batch_size = 128\n",
    "patch_size = 5\n",
    "depth = 16\n",
    "num_hidden = 64\n",
    "\n",
    "graph = tf.Graph()\n",
    "\n",
    "with graph.as_default():\n",
    "\n",
    "  # Input data.\n",
    "  tf_train_dataset = tf.placeholder(tf.float32, shape=(batch_size, image_size, image_size, num_channels))\n",
    "  tf_train_labels = tf.placeholder(tf.float32, shape=(batch_size, num_labels))\n",
    "  tf_valid_dataset = tf.constant(valid_dataset)\n",
    "  tf_test_dataset = tf.constant(test_dataset)\n",
    "  \n",
    "  # Variables.\n",
    "  layer1_weights = tf.Variable(tf.truncated_normal([patch_size, patch_size, num_channels, depth], stddev=0.1))\n",
    "  layer1_biases = tf.Variable(tf.zeros([depth]))\n",
    "  layer2_weights = tf.Variable(tf.truncated_normal([patch_size, patch_size, depth, depth], stddev=0.1))\n",
    "  layer2_biases = tf.Variable(tf.constant(1.0, shape=[depth]))\n",
    "  layer3_weights = tf.Variable(tf.truncated_normal([image_size // 4 * image_size // 4 * depth, num_hidden], stddev=0.1))\n",
    "  layer3_biases = tf.Variable(tf.constant(1.0, shape=[num_hidden]))\n",
    "  layer4_weights = tf.Variable(tf.truncated_normal([num_hidden, num_labels], stddev=0.1))\n",
    "  layer4_biases = tf.Variable(tf.constant(1.0, shape=[num_labels]))\n",
    "  \n",
    "  # Model.\n",
    "  def model(data):\n",
    "    conv = tf.nn.conv2d(data, layer1_weights, [1, 2, 2, 1], padding='SAME')\n",
    "    hidden = tf.nn.elu(conv + layer1_biases)\n",
    "    conv = tf.nn.conv2d(hidden, layer2_weights, [1, 2, 2, 1], padding='SAME')\n",
    "    hidden = tf.nn.elu(conv + layer2_biases)\n",
    "    shape = hidden.get_shape().as_list()\n",
    "    reshape = tf.reshape(hidden, [shape[0], shape[1] * shape[2] * shape[3]])\n",
    "    hidden = tf.nn.elu(tf.matmul(reshape, layer3_weights) + layer3_biases)\n",
    "    return tf.matmul(hidden, layer4_weights) + layer4_biases\n",
    "  \n",
    "  # Training computation.\n",
    "  logits = model(tf_train_dataset)\n",
    "  loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits, tf_train_labels))\n",
    "    \n",
    "  # Optimizer.\n",
    "  optimizer = tf.train.GradientDescentOptimizer(0.05).minimize(loss)\n",
    "  \n",
    "  # Predictions for the training, validation, and test data.\n",
    "  train_prediction = tf.nn.softmax(logits)\n",
    "  valid_prediction = tf.nn.softmax(model(tf_valid_dataset))\n",
    "  test_prediction = tf.nn.softmax(model(tf_test_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized\n",
      "Minibatch loss at step 0: 3.003078\n",
      "Minibatch accuracy: 12.5%\n",
      "Validation accuracy: 13.8%\n",
      "Minibatch loss at step 50: 0.749019\n",
      "Minibatch accuracy: 82.0%\n",
      "Validation accuracy: 76.6%\n",
      "Minibatch loss at step 100: 0.731732\n",
      "Minibatch accuracy: 79.7%\n",
      "Validation accuracy: 79.5%\n",
      "Minibatch loss at step 150: 0.797420\n",
      "Minibatch accuracy: 75.8%\n",
      "Validation accuracy: 80.4%\n",
      "Minibatch loss at step 200: 0.648261\n",
      "Minibatch accuracy: 85.9%\n",
      "Validation accuracy: 80.2%\n",
      "Minibatch loss at step 250: 0.551041\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 81.1%\n",
      "Minibatch loss at step 300: 0.622786\n",
      "Minibatch accuracy: 78.9%\n",
      "Validation accuracy: 81.9%\n",
      "Minibatch loss at step 350: 0.491006\n",
      "Minibatch accuracy: 85.2%\n",
      "Validation accuracy: 81.5%\n",
      "Minibatch loss at step 400: 0.597648\n",
      "Minibatch accuracy: 85.2%\n",
      "Validation accuracy: 82.1%\n",
      "Minibatch loss at step 450: 0.529020\n",
      "Minibatch accuracy: 86.7%\n",
      "Validation accuracy: 82.1%\n",
      "Minibatch loss at step 500: 0.435512\n",
      "Minibatch accuracy: 86.7%\n",
      "Validation accuracy: 83.0%\n",
      "Minibatch loss at step 550: 0.837681\n",
      "Minibatch accuracy: 80.5%\n",
      "Validation accuracy: 82.3%\n",
      "Minibatch loss at step 600: 0.597965\n",
      "Minibatch accuracy: 82.0%\n",
      "Validation accuracy: 83.0%\n",
      "Minibatch loss at step 650: 0.560968\n",
      "Minibatch accuracy: 83.6%\n",
      "Validation accuracy: 83.0%\n",
      "Minibatch loss at step 700: 0.625586\n",
      "Minibatch accuracy: 81.2%\n",
      "Validation accuracy: 83.3%\n",
      "Minibatch loss at step 750: 0.593890\n",
      "Minibatch accuracy: 81.2%\n",
      "Validation accuracy: 83.1%\n",
      "Minibatch loss at step 800: 0.368861\n",
      "Minibatch accuracy: 86.7%\n",
      "Validation accuracy: 83.3%\n",
      "Minibatch loss at step 850: 0.610277\n",
      "Minibatch accuracy: 81.2%\n",
      "Validation accuracy: 83.7%\n",
      "Minibatch loss at step 900: 0.631434\n",
      "Minibatch accuracy: 82.0%\n",
      "Validation accuracy: 83.9%\n",
      "Minibatch loss at step 950: 0.639423\n",
      "Minibatch accuracy: 80.5%\n",
      "Validation accuracy: 83.9%\n",
      "Minibatch loss at step 1000: 0.663184\n",
      "Minibatch accuracy: 81.2%\n",
      "Validation accuracy: 83.8%\n",
      "Test accuracy: 90.8%\n"
     ]
    }
   ],
   "source": [
    "num_steps = 1001\n",
    "\n",
    "with tf.Session(graph=graph) as session:\n",
    "  tf.initialize_all_variables().run()\n",
    "  print('Initialized')\n",
    "  for step in range(num_steps):\n",
    "    offset = (step * batch_size) % (train_labels.shape[0] - batch_size)\n",
    "    batch_data = train_dataset[offset:(offset + batch_size), :, :, :]\n",
    "    batch_labels = train_labels[offset:(offset + batch_size), :]\n",
    "    feed_dict = {tf_train_dataset : batch_data, tf_train_labels : batch_labels}\n",
    "    _, l, predictions = session.run([optimizer, loss, train_prediction], feed_dict=feed_dict)\n",
    "    if (step % 50 == 0):\n",
    "      print('Minibatch loss at step %d: %f' % (step, l))\n",
    "      print('Minibatch accuracy: %.1f%%' % accuracy(predictions, batch_labels))\n",
    "      print('Validation accuracy: %.1f%%' % accuracy(valid_prediction.eval(), valid_labels))\n",
    "  print('Test accuracy: %.1f%%' % accuracy(test_prediction.eval(), test_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KedKkn4EutIK"
   },
   "source": [
    "---\n",
    "Problem 1\n",
    "---------\n",
    "\n",
    "The convolutional model above uses convolutions with stride 2 to reduce the dimensionality. Replace the strides by a max pooling operation (`nn.max_pool()`) of stride 2 and kernel size 2.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "patch_size = 5\n",
    "depth = 16\n",
    "num_hidden = 64\n",
    "\n",
    "graph = tf.Graph()\n",
    "\n",
    "with graph.as_default():\n",
    "\n",
    "  # Input data.\n",
    "  tf_train_dataset = tf.placeholder(tf.float32, shape=(batch_size, image_size, image_size, num_channels))\n",
    "  tf_train_labels = tf.placeholder(tf.float32, shape=(batch_size, num_labels))\n",
    "  tf_valid_dataset = tf.constant(valid_dataset)\n",
    "  tf_test_dataset = tf.constant(test_dataset)\n",
    "  \n",
    "  # Variables.\n",
    "  layer1_weights = tf.Variable(tf.truncated_normal([patch_size, patch_size, num_channels, depth], stddev=0.1))\n",
    "  layer1_biases = tf.Variable(tf.zeros([depth]))\n",
    "  layer2_weights = tf.Variable(tf.truncated_normal([patch_size, patch_size, depth, depth], stddev=0.1))\n",
    "  layer2_biases = tf.Variable(tf.constant(1.0, shape=[depth]))\n",
    "  layer3_weights = tf.Variable(tf.truncated_normal([image_size // 4 * image_size // 4 * depth, num_hidden], stddev=0.1))\n",
    "  layer3_biases = tf.Variable(tf.constant(1.0, shape=[num_hidden]))\n",
    "  layer4_weights = tf.Variable(tf.truncated_normal([num_hidden, num_labels], stddev=0.1))\n",
    "  layer4_biases = tf.Variable(tf.constant(1.0, shape=[num_labels]))\n",
    "  \n",
    "  # Model.\n",
    "  def model(data):\n",
    "    conv = tf.nn.conv2d(data, layer1_weights, [1, 1, 1, 1], padding='SAME')\n",
    "    hidden = tf.nn.relu(conv + layer1_biases)\n",
    "    # Max pooling. The kernel size spec {ksize} also follows the layout of\n",
    "    # the data. Here we have a pooling window of 2, and a stride of 2.\n",
    "    pool = tf.nn.max_pool(hidden,ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "    conv = tf.nn.conv2d(pool, layer2_weights, [1, 1, 1, 1], padding='SAME')\n",
    "    hidden = tf.nn.relu(conv + layer2_biases)\n",
    "    pool = tf.nn.max_pool(hidden,ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "    shape = pool.get_shape().as_list()\n",
    "    reshape = tf.reshape(pool, [shape[0], shape[1] * shape[2] * shape[3]])\n",
    "    hidden = tf.nn.relu(tf.matmul(reshape, layer3_weights) + layer3_biases)\n",
    "    return tf.matmul(hidden, layer4_weights) + layer4_biases\n",
    "  \n",
    "  # Training computation.\n",
    "  logits = model(tf_train_dataset)\n",
    "  loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits, tf_train_labels))\n",
    "    \n",
    "  # Optimizer.\n",
    "  optimizer = tf.train.GradientDescentOptimizer(0.05).minimize(loss)\n",
    "  \n",
    "  # Predictions for the training, validation, and test data.\n",
    "  train_prediction = tf.nn.softmax(logits)\n",
    "  valid_prediction = tf.nn.softmax(model(tf_valid_dataset))\n",
    "  test_prediction = tf.nn.softmax(model(tf_test_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized\n",
      "Minibatch loss at step 0: 2.893854\n",
      "Minibatch accuracy: 12.5%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 50: 2.087864\n",
      "Minibatch accuracy: 25.0%\n",
      "Validation accuracy: 28.7%\n",
      "Minibatch loss at step 100: 1.329527\n",
      "Minibatch accuracy: 50.0%\n",
      "Validation accuracy: 55.0%\n",
      "Minibatch loss at step 150: 0.751715\n",
      "Minibatch accuracy: 81.2%\n",
      "Validation accuracy: 71.2%\n",
      "Minibatch loss at step 200: 1.182177\n",
      "Minibatch accuracy: 75.0%\n",
      "Validation accuracy: 75.7%\n",
      "Minibatch loss at step 250: 1.117778\n",
      "Minibatch accuracy: 68.8%\n",
      "Validation accuracy: 76.7%\n",
      "Minibatch loss at step 300: 0.373301\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 80.0%\n",
      "Minibatch loss at step 350: 0.604092\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 78.6%\n",
      "Minibatch loss at step 400: 0.172199\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 80.1%\n",
      "Minibatch loss at step 450: 0.879360\n",
      "Minibatch accuracy: 68.8%\n",
      "Validation accuracy: 78.7%\n",
      "Minibatch loss at step 500: 0.766709\n",
      "Minibatch accuracy: 81.2%\n",
      "Validation accuracy: 80.2%\n",
      "Minibatch loss at step 550: 0.707372\n",
      "Minibatch accuracy: 75.0%\n",
      "Validation accuracy: 82.2%\n",
      "Minibatch loss at step 600: 0.456596\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 82.3%\n",
      "Minibatch loss at step 650: 0.781068\n",
      "Minibatch accuracy: 81.2%\n",
      "Validation accuracy: 82.6%\n",
      "Minibatch loss at step 700: 0.986369\n",
      "Minibatch accuracy: 75.0%\n",
      "Validation accuracy: 82.9%\n",
      "Minibatch loss at step 750: 0.062079\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 83.0%\n",
      "Minibatch loss at step 800: 0.758350\n",
      "Minibatch accuracy: 68.8%\n",
      "Validation accuracy: 83.3%\n",
      "Minibatch loss at step 850: 0.837922\n",
      "Minibatch accuracy: 68.8%\n",
      "Validation accuracy: 83.8%\n",
      "Minibatch loss at step 900: 0.595549\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 83.6%\n",
      "Minibatch loss at step 950: 0.541227\n",
      "Minibatch accuracy: 81.2%\n",
      "Validation accuracy: 83.5%\n",
      "Minibatch loss at step 1000: 0.360472\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 84.2%\n",
      "Test accuracy: 90.7%\n"
     ]
    }
   ],
   "source": [
    "num_steps = 1001\n",
    "\n",
    "with tf.Session(graph=graph) as session:\n",
    "  tf.initialize_all_variables().run()\n",
    "  print('Initialized')\n",
    "  for step in range(num_steps):\n",
    "    offset = (step * batch_size) % (train_labels.shape[0] - batch_size)\n",
    "    batch_data = train_dataset[offset:(offset + batch_size), :, :, :]\n",
    "    batch_labels = train_labels[offset:(offset + batch_size), :]\n",
    "    feed_dict = {tf_train_dataset : batch_data, tf_train_labels : batch_labels}\n",
    "    _, l, predictions = session.run(\n",
    "      [optimizer, loss, train_prediction], feed_dict=feed_dict)\n",
    "    if (step % 50 == 0):\n",
    "      print('Minibatch loss at step %d: %f' % (step, l))\n",
    "      print('Minibatch accuracy: %.1f%%' % accuracy(predictions, batch_labels))\n",
    "      print('Validation accuracy: %.1f%%' % accuracy(\n",
    "        valid_prediction.eval(), valid_labels))\n",
    "  print('Test accuracy: %.1f%%' % accuracy(test_prediction.eval(), test_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test with ELU\n",
    "Batch size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "patch_size = 5\n",
    "depth = 16\n",
    "num_hidden = 64\n",
    "\n",
    "graph = tf.Graph()\n",
    "\n",
    "with graph.as_default():\n",
    "\n",
    "  # Input data.\n",
    "  tf_train_dataset = tf.placeholder(tf.float32, shape=(batch_size, image_size, image_size, num_channels))\n",
    "  tf_train_labels = tf.placeholder(tf.float32, shape=(batch_size, num_labels))\n",
    "  tf_valid_dataset = tf.constant(valid_dataset)\n",
    "  tf_test_dataset = tf.constant(test_dataset)\n",
    "  \n",
    "  # Variables.\n",
    "  layer1_weights = tf.Variable(tf.truncated_normal([patch_size, patch_size, num_channels, depth], stddev=0.1))\n",
    "  layer1_biases = tf.Variable(tf.zeros([depth]))\n",
    "  layer2_weights = tf.Variable(tf.truncated_normal([patch_size, patch_size, depth, depth], stddev=0.1))\n",
    "  layer2_biases = tf.Variable(tf.constant(1.0, shape=[depth]))\n",
    "  layer3_weights = tf.Variable(tf.truncated_normal([image_size // 4 * image_size // 4 * depth, num_hidden], stddev=0.1))\n",
    "  layer3_biases = tf.Variable(tf.constant(1.0, shape=[num_hidden]))\n",
    "  layer4_weights = tf.Variable(tf.truncated_normal([num_hidden, num_labels], stddev=0.1))\n",
    "  layer4_biases = tf.Variable(tf.constant(1.0, shape=[num_labels]))\n",
    "  \n",
    "  # Model.\n",
    "  def model(data):\n",
    "    conv = tf.nn.conv2d(data, layer1_weights, [1, 1, 1, 1], padding='SAME')\n",
    "    hidden = tf.nn.elu(conv + layer1_biases)\n",
    "    # Max pooling. The kernel size spec {ksize} also follows the layout of\n",
    "    # the data. Here we have a pooling window of 2, and a stride of 2.\n",
    "    pool = tf.nn.max_pool(hidden,ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "    conv = tf.nn.conv2d(pool, layer2_weights, [1, 1, 1, 1], padding='SAME')\n",
    "    hidden = tf.nn.elu(conv + layer2_biases)\n",
    "    pool = tf.nn.max_pool(hidden,ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "    shape = pool.get_shape().as_list()\n",
    "    reshape = tf.reshape(pool, [shape[0], shape[1] * shape[2] * shape[3]])\n",
    "    hidden = tf.nn.elu(tf.matmul(reshape, layer3_weights) + layer3_biases)\n",
    "    return tf.matmul(hidden, layer4_weights) + layer4_biases\n",
    "  \n",
    "  # Training computation.\n",
    "  logits = model(tf_train_dataset)\n",
    "  loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits, tf_train_labels))\n",
    "    \n",
    "  # Optimizer.\n",
    "  optimizer = tf.train.GradientDescentOptimizer(0.05).minimize(loss)\n",
    "  \n",
    "  # Predictions for the training, validation, and test data.\n",
    "  train_prediction = tf.nn.softmax(logits)\n",
    "  valid_prediction = tf.nn.softmax(model(tf_valid_dataset))\n",
    "  test_prediction = tf.nn.softmax(model(tf_test_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized\n",
      "Minibatch loss at step 0: 3.140803\n",
      "Minibatch accuracy: 10.9%\n",
      "Validation accuracy: 12.5%\n",
      "Minibatch loss at step 50: 0.839501\n",
      "Minibatch accuracy: 77.3%\n",
      "Validation accuracy: 71.6%\n",
      "Minibatch loss at step 100: 0.737142\n",
      "Minibatch accuracy: 78.9%\n",
      "Validation accuracy: 78.7%\n",
      "Minibatch loss at step 150: 0.893893\n",
      "Minibatch accuracy: 74.2%\n",
      "Validation accuracy: 79.7%\n",
      "Minibatch loss at step 200: 0.738219\n",
      "Minibatch accuracy: 81.2%\n",
      "Validation accuracy: 79.9%\n",
      "Minibatch loss at step 250: 0.520592\n",
      "Minibatch accuracy: 88.3%\n",
      "Validation accuracy: 80.8%\n",
      "Minibatch loss at step 300: 0.645235\n",
      "Minibatch accuracy: 75.0%\n",
      "Validation accuracy: 81.5%\n",
      "Minibatch loss at step 350: 0.468050\n",
      "Minibatch accuracy: 85.9%\n",
      "Validation accuracy: 82.0%\n",
      "Minibatch loss at step 400: 0.650908\n",
      "Minibatch accuracy: 80.5%\n",
      "Validation accuracy: 82.2%\n",
      "Minibatch loss at step 450: 0.545229\n",
      "Minibatch accuracy: 85.2%\n",
      "Validation accuracy: 82.5%\n",
      "Minibatch loss at step 500: 0.394252\n",
      "Minibatch accuracy: 90.6%\n",
      "Validation accuracy: 83.5%\n",
      "Minibatch loss at step 550: 0.762775\n",
      "Minibatch accuracy: 77.3%\n",
      "Validation accuracy: 83.2%\n",
      "Minibatch loss at step 600: 0.650549\n",
      "Minibatch accuracy: 81.2%\n",
      "Validation accuracy: 84.0%\n",
      "Minibatch loss at step 650: 0.573395\n",
      "Minibatch accuracy: 81.2%\n",
      "Validation accuracy: 83.7%\n",
      "Minibatch loss at step 700: 0.638614\n",
      "Minibatch accuracy: 83.6%\n",
      "Validation accuracy: 84.1%\n",
      "Minibatch loss at step 750: 0.584707\n",
      "Minibatch accuracy: 84.4%\n",
      "Validation accuracy: 84.6%\n",
      "Minibatch loss at step 800: 0.318639\n",
      "Minibatch accuracy: 88.3%\n",
      "Validation accuracy: 84.8%\n",
      "Minibatch loss at step 850: 0.608209\n",
      "Minibatch accuracy: 84.4%\n",
      "Validation accuracy: 84.9%\n",
      "Minibatch loss at step 900: 0.508392\n",
      "Minibatch accuracy: 85.9%\n",
      "Validation accuracy: 85.2%\n",
      "Minibatch loss at step 950: 0.621160\n",
      "Minibatch accuracy: 81.2%\n",
      "Validation accuracy: 85.4%\n",
      "Minibatch loss at step 1000: 0.625371\n",
      "Minibatch accuracy: 79.7%\n",
      "Validation accuracy: 85.1%\n",
      "Test accuracy: 91.8%\n"
     ]
    }
   ],
   "source": [
    "num_steps = 1001\n",
    "\n",
    "with tf.Session(graph=graph) as session:\n",
    "  tf.initialize_all_variables().run()\n",
    "  print('Initialized')\n",
    "  for step in range(num_steps):\n",
    "    offset = (step * batch_size) % (train_labels.shape[0] - batch_size)\n",
    "    batch_data = train_dataset[offset:(offset + batch_size), :, :, :]\n",
    "    batch_labels = train_labels[offset:(offset + batch_size), :]\n",
    "    feed_dict = {tf_train_dataset : batch_data, tf_train_labels : batch_labels}\n",
    "    _, l, predictions = session.run(\n",
    "      [optimizer, loss, train_prediction], feed_dict=feed_dict)\n",
    "    if (step % 50 == 0):\n",
    "      print('Minibatch loss at step %d: %f' % (step, l))\n",
    "      print('Minibatch accuracy: %.1f%%' % accuracy(predictions, batch_labels))\n",
    "      print('Validation accuracy: %.1f%%' % accuracy(\n",
    "        valid_prediction.eval(), valid_labels))\n",
    "  print('Test accuracy: %.1f%%' % accuracy(test_prediction.eval(), test_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "klf21gpbAgb-"
   },
   "source": [
    "---\n",
    "Problem 2\n",
    "---------\n",
    "\n",
    "Try to get the best performance you can using a convolutional net. Look for example at the classic [LeNet5](http://yann.lecun.com/exdb/lenet/) architecture, adding Dropout, and/or adding learning rate decay.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import math as math\n",
    "batch_size = 128\n",
    "patch_size = 4\n",
    "depth = 16\n",
    "l1_size = 705\n",
    "l2_size = 205\n",
    "\n",
    "\n",
    "graph = tf.Graph()\n",
    "\n",
    "with graph.as_default():\n",
    "\n",
    "  # Input data.\n",
    "  tf_train_dataset = tf.placeholder(tf.float32, shape=(batch_size, image_size, image_size, num_channels))\n",
    "  tf_train_labels = tf.placeholder(tf.float32, shape=(batch_size, num_labels))\n",
    "  tf_valid_dataset = tf.constant(valid_dataset)\n",
    "  tf_test_dataset = tf.constant(test_dataset)\n",
    "  \n",
    "  # Variables.\n",
    "  layerConv1_weights = tf.Variable(tf.truncated_normal(\n",
    "            [patch_size, patch_size, num_channels, depth], stddev=0.1))\n",
    "  layerConv1_biases = tf.Variable(tf.zeros([depth]))\n",
    "  layerConv2_weights = tf.Variable(tf.truncated_normal(\n",
    "            [patch_size, patch_size, depth, depth*2], stddev=math.sqrt(2.0/(patch_size*patch_size*depth))))\n",
    "  layerConv2_biases = tf.Variable(tf.zeros([depth*2]))\n",
    "  layerConv3_weights = tf.Variable(tf.truncated_normal(\n",
    "            [patch_size, patch_size, depth*2, depth*4], stddev=math.sqrt(2.0/(patch_size*patch_size*depth*2))))\n",
    "  layerConv3_biases = tf.Variable(tf.zeros([depth*4]))\n",
    "  layerConv4_weights = tf.Variable(tf.truncated_normal(\n",
    "            [patch_size, patch_size, depth*4, depth*4], stddev=math.sqrt(2.0/(patch_size*patch_size*depth*4))))\n",
    "  layerConv4_biases = tf.Variable(tf.zeros([depth*4]))\n",
    "  layerConv5_weights = tf.Variable(tf.truncated_normal(\n",
    "            [patch_size, patch_size, depth*4, depth*16], stddev=math.sqrt(2.0/(patch_size*patch_size*depth*4))))\n",
    "  layerConv5_biases = tf.Variable(tf.zeros([depth*16]))\n",
    "\n",
    "  layer1_weights = tf.Variable(tf.truncated_normal(\n",
    "            [image_size//7*image_size//7*(depth*4), l1_size], \n",
    "            stddev=math.sqrt(2.0/(image_size//7*image_size//7*(depth*4)))))\n",
    "  layer1_biases = tf.Variable(tf.zeros([l1_size]))\n",
    "  layer2_weights = tf.Variable(tf.truncated_normal(\n",
    "            [l1_size, l2_size], stddev=math.sqrt(2.0/(l1_size))))\n",
    "  layer2_biases = tf.Variable(tf.zeros([l2_size]))\n",
    "  layer3_weights = tf.Variable(tf.truncated_normal(\n",
    "            [l2_size, num_labels], stddev=math.sqrt(2.0/(l2_size))))\n",
    "  layer3_biases = tf.Variable(tf.zeros([num_labels]))\n",
    "  \n",
    "  # Model.\n",
    "  def model(data, use_dropout=False):\n",
    "    conv = tf.nn.conv2d(data, layerConv1_weights, [1, 1, 1, 1], padding='SAME')\n",
    "    hidden = tf.nn.elu(conv + layerConv1_biases)\n",
    "    pool = tf.nn.max_pool(hidden, [1, 2, 2, 1], [1, 2, 2, 1], padding='SAME')\n",
    "    \n",
    "    conv = tf.nn.conv2d(pool, layerConv2_weights, [1, 1, 1, 1], padding='SAME')\n",
    "    hidden = tf.nn.elu(conv + layerConv2_biases)\n",
    "\n",
    "    conv = tf.nn.conv2d(hidden, layerConv3_weights, [1, 1, 1, 1], padding='SAME')\n",
    "    hidden = tf.nn.elu(conv + layerConv3_biases)\n",
    "    pool = tf.nn.max_pool(hidden, [1, 2, 2, 1], [1, 2, 2, 1], padding='SAME')\n",
    "    \n",
    "    conv = tf.nn.conv2d(pool, layerConv4_weights, [1, 1, 1, 1], padding='SAME')\n",
    "    hidden = tf.nn.elu(conv + layerConv4_biases)\n",
    "    pool = tf.nn.max_pool(hidden, [1, 2, 2, 1], [1, 2, 2, 1], padding='SAME')\n",
    "   \n",
    "    conv = tf.nn.conv2d(pool, layerConv5_weights, [1, 1, 1, 1], padding='SAME')\n",
    "    hidden = tf.nn.elu(conv + layerConv5_biases)\n",
    "    pool = tf.nn.max_pool(hidden, [1, 2, 2, 1], [1, 2, 2, 1], padding='SAME')\n",
    "\n",
    "    shape = pool.get_shape().as_list()\n",
    "    reshape = tf.reshape(pool, [shape[0], shape[1] * shape[2] * shape[3]])\n",
    "    hidden = tf.nn.elu(tf.matmul(reshape, layer1_weights) + layer1_biases)\n",
    "    \n",
    "    if use_dropout:\n",
    "        hidden = tf.nn.dropout(hidden, 0.75)\n",
    "    \n",
    "    nn_hidden_layer = tf.matmul(hidden, layer2_weights) + layer2_biases\n",
    "    hidden = tf.nn.elu(nn_hidden_layer)\n",
    "    \n",
    "    if use_dropout:\n",
    "        hidden = tf.nn.dropout(hidden, 0.75)\n",
    "    return tf.matmul(hidden, layer3_weights) + layer3_biases\n",
    "  \n",
    "  # Training computation.\n",
    "  logits = model(tf_train_dataset, True)\n",
    "  loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits, tf_train_labels))\n",
    "    \n",
    "  global_step = tf.Variable(0)  # count the number of steps taken.\n",
    "  learning_rate = tf.train.exponential_decay(0.1, global_step, 3000, 0.86, staircase=True)\n",
    "  \n",
    "  # Optimizer.\n",
    "  optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(loss, global_step=global_step)\n",
    "  \n",
    "  # Predictions for the training, validation, and test data.\n",
    "  train_prediction = tf.nn.softmax(logits)\n",
    "  valid_prediction = tf.nn.softmax(model(tf_valid_dataset))\n",
    "  test_prediction = tf.nn.softmax(model(tf_test_dataset))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized\n",
      "Minibatch loss at step 0: 2.462052\n",
      "Minibatch accuracy: 10.9%\n",
      "Validation accuracy: 17.1%\n",
      "Minibatch loss at step 50: 0.583806\n",
      "Minibatch accuracy: 83.6%\n",
      "Validation accuracy: 80.4%\n",
      "Minibatch loss at step 100: 0.612285\n",
      "Minibatch accuracy: 82.0%\n",
      "Validation accuracy: 83.2%\n",
      "Minibatch loss at step 150: 0.708149\n",
      "Minibatch accuracy: 79.7%\n",
      "Validation accuracy: 84.7%\n",
      "Minibatch loss at step 200: 0.598113\n",
      "Minibatch accuracy: 83.6%\n",
      "Validation accuracy: 85.3%\n",
      "Minibatch loss at step 250: 0.370525\n",
      "Minibatch accuracy: 89.8%\n",
      "Validation accuracy: 86.2%\n",
      "Minibatch loss at step 300: 0.591497\n",
      "Minibatch accuracy: 83.6%\n",
      "Validation accuracy: 86.2%\n",
      "Minibatch loss at step 350: 0.295489\n",
      "Minibatch accuracy: 91.4%\n",
      "Validation accuracy: 86.4%\n",
      "Minibatch loss at step 400: 0.439530\n",
      "Minibatch accuracy: 85.9%\n",
      "Validation accuracy: 87.5%\n",
      "Minibatch loss at step 450: 0.329455\n",
      "Minibatch accuracy: 89.8%\n",
      "Validation accuracy: 87.9%\n",
      "Minibatch loss at step 500: 0.328938\n",
      "Minibatch accuracy: 89.8%\n",
      "Validation accuracy: 88.0%\n",
      "Minibatch loss at step 550: 0.682357\n",
      "Minibatch accuracy: 82.8%\n",
      "Validation accuracy: 87.5%\n",
      "Minibatch loss at step 600: 0.477647\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 88.0%\n",
      "Minibatch loss at step 650: 0.506337\n",
      "Minibatch accuracy: 85.2%\n",
      "Validation accuracy: 88.1%\n",
      "Minibatch loss at step 700: 0.470768\n",
      "Minibatch accuracy: 88.3%\n",
      "Validation accuracy: 88.7%\n",
      "Minibatch loss at step 750: 0.407526\n",
      "Minibatch accuracy: 89.1%\n",
      "Validation accuracy: 88.4%\n",
      "Minibatch loss at step 800: 0.233379\n",
      "Minibatch accuracy: 93.0%\n",
      "Validation accuracy: 88.6%\n",
      "Minibatch loss at step 850: 0.401828\n",
      "Minibatch accuracy: 89.8%\n",
      "Validation accuracy: 88.4%\n",
      "Minibatch loss at step 900: 0.414162\n",
      "Minibatch accuracy: 86.7%\n",
      "Validation accuracy: 88.9%\n",
      "Minibatch loss at step 950: 0.475570\n",
      "Minibatch accuracy: 84.4%\n",
      "Validation accuracy: 89.1%\n",
      "Minibatch loss at step 1000: 0.490964\n",
      "Minibatch accuracy: 85.2%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss at step 1050: 0.210477\n",
      "Minibatch accuracy: 94.5%\n",
      "Validation accuracy: 89.5%\n",
      "Minibatch loss at step 1100: 0.313337\n",
      "Minibatch accuracy: 91.4%\n",
      "Validation accuracy: 89.2%\n",
      "Minibatch loss at step 1150: 0.409448\n",
      "Minibatch accuracy: 88.3%\n",
      "Validation accuracy: 89.7%\n",
      "Minibatch loss at step 1200: 0.285967\n",
      "Minibatch accuracy: 91.4%\n",
      "Validation accuracy: 89.5%\n",
      "Minibatch loss at step 1250: 0.281637\n",
      "Minibatch accuracy: 91.4%\n",
      "Validation accuracy: 89.7%\n",
      "Minibatch loss at step 1300: 0.353107\n",
      "Minibatch accuracy: 91.4%\n",
      "Validation accuracy: 89.5%\n",
      "Minibatch loss at step 1350: 0.393479\n",
      "Minibatch accuracy: 89.1%\n",
      "Validation accuracy: 89.5%\n",
      "Minibatch loss at step 1400: 0.263733\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 90.0%\n",
      "Minibatch loss at step 1450: 0.275972\n",
      "Minibatch accuracy: 89.8%\n",
      "Validation accuracy: 90.1%\n",
      "Minibatch loss at step 1500: 0.221599\n",
      "Minibatch accuracy: 93.0%\n",
      "Validation accuracy: 90.0%\n",
      "Minibatch loss at step 1550: 0.338409\n",
      "Minibatch accuracy: 91.4%\n",
      "Validation accuracy: 89.9%\n",
      "Minibatch loss at step 1600: 0.380226\n",
      "Minibatch accuracy: 88.3%\n",
      "Validation accuracy: 90.1%\n",
      "Minibatch loss at step 1650: 0.320251\n",
      "Minibatch accuracy: 89.1%\n",
      "Validation accuracy: 90.3%\n",
      "Minibatch loss at step 1700: 0.277452\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 90.2%\n",
      "Minibatch loss at step 1750: 0.303310\n",
      "Minibatch accuracy: 91.4%\n",
      "Validation accuracy: 90.2%\n",
      "Minibatch loss at step 1800: 0.377718\n",
      "Minibatch accuracy: 88.3%\n",
      "Validation accuracy: 90.2%\n",
      "Minibatch loss at step 1850: 0.389396\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 90.2%\n",
      "Minibatch loss at step 1900: 0.445028\n",
      "Minibatch accuracy: 85.9%\n",
      "Validation accuracy: 89.7%\n",
      "Minibatch loss at step 1950: 0.234343\n",
      "Minibatch accuracy: 93.0%\n",
      "Validation accuracy: 90.4%\n",
      "Minibatch loss at step 2000: 0.264910\n",
      "Minibatch accuracy: 92.2%\n",
      "Validation accuracy: 90.2%\n",
      "Minibatch loss at step 2050: 0.264635\n",
      "Minibatch accuracy: 91.4%\n",
      "Validation accuracy: 90.3%\n",
      "Minibatch loss at step 2100: 0.316909\n",
      "Minibatch accuracy: 90.6%\n",
      "Validation accuracy: 90.6%\n",
      "Minibatch loss at step 2150: 0.322816\n",
      "Minibatch accuracy: 89.8%\n",
      "Validation accuracy: 90.1%\n",
      "Minibatch loss at step 2200: 0.360092\n",
      "Minibatch accuracy: 88.3%\n",
      "Validation accuracy: 90.8%\n",
      "Minibatch loss at step 2250: 0.413714\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 90.8%\n",
      "Minibatch loss at step 2300: 0.394317\n",
      "Minibatch accuracy: 89.8%\n",
      "Validation accuracy: 90.6%\n",
      "Minibatch loss at step 2350: 0.305568\n",
      "Minibatch accuracy: 90.6%\n",
      "Validation accuracy: 91.0%\n",
      "Minibatch loss at step 2400: 0.333177\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 90.7%\n",
      "Minibatch loss at step 2450: 0.232935\n",
      "Minibatch accuracy: 93.0%\n",
      "Validation accuracy: 90.7%\n",
      "Minibatch loss at step 2500: 0.250095\n",
      "Minibatch accuracy: 93.0%\n",
      "Validation accuracy: 90.9%\n",
      "Minibatch loss at step 2550: 0.207880\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 91.1%\n",
      "Minibatch loss at step 2600: 0.443197\n",
      "Minibatch accuracy: 85.9%\n",
      "Validation accuracy: 90.4%\n",
      "Minibatch loss at step 2650: 0.255339\n",
      "Minibatch accuracy: 90.6%\n",
      "Validation accuracy: 90.9%\n",
      "Minibatch loss at step 2700: 0.299843\n",
      "Minibatch accuracy: 90.6%\n",
      "Validation accuracy: 91.1%\n",
      "Minibatch loss at step 2750: 0.188280\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 91.1%\n",
      "Minibatch loss at step 2800: 0.231519\n",
      "Minibatch accuracy: 92.2%\n",
      "Validation accuracy: 91.0%\n",
      "Minibatch loss at step 2850: 0.207113\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 90.9%\n",
      "Minibatch loss at step 2900: 0.232959\n",
      "Minibatch accuracy: 94.5%\n",
      "Validation accuracy: 90.6%\n",
      "Minibatch loss at step 2950: 0.293915\n",
      "Minibatch accuracy: 90.6%\n",
      "Validation accuracy: 91.1%\n",
      "Minibatch loss at step 3000: 0.302182\n",
      "Minibatch accuracy: 89.8%\n",
      "Validation accuracy: 90.8%\n",
      "Minibatch loss at step 3050: 0.337366\n",
      "Minibatch accuracy: 89.8%\n",
      "Validation accuracy: 91.2%\n",
      "Minibatch loss at step 3100: 0.247082\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 91.2%\n",
      "Minibatch loss at step 3150: 0.299537\n",
      "Minibatch accuracy: 89.8%\n",
      "Validation accuracy: 91.2%\n",
      "Minibatch loss at step 3200: 0.217716\n",
      "Minibatch accuracy: 93.0%\n",
      "Validation accuracy: 91.1%\n",
      "Minibatch loss at step 3250: 0.245252\n",
      "Minibatch accuracy: 90.6%\n",
      "Validation accuracy: 91.2%\n",
      "Minibatch loss at step 3300: 0.229433\n",
      "Minibatch accuracy: 93.0%\n",
      "Validation accuracy: 91.4%\n",
      "Minibatch loss at step 3350: 0.323534\n",
      "Minibatch accuracy: 88.3%\n",
      "Validation accuracy: 91.2%\n",
      "Minibatch loss at step 3400: 0.229286\n",
      "Minibatch accuracy: 91.4%\n",
      "Validation accuracy: 91.4%\n",
      "Minibatch loss at step 3450: 0.283477\n",
      "Minibatch accuracy: 92.2%\n",
      "Validation accuracy: 91.5%\n",
      "Minibatch loss at step 3500: 0.289985\n",
      "Minibatch accuracy: 90.6%\n",
      "Validation accuracy: 91.3%\n",
      "Minibatch loss at step 3550: 0.122088\n",
      "Minibatch accuracy: 96.1%\n",
      "Validation accuracy: 91.3%\n",
      "Minibatch loss at step 3600: 0.316851\n",
      "Minibatch accuracy: 89.8%\n",
      "Validation accuracy: 91.3%\n",
      "Minibatch loss at step 3650: 0.296366\n",
      "Minibatch accuracy: 90.6%\n",
      "Validation accuracy: 91.3%\n",
      "Minibatch loss at step 3700: 0.419479\n",
      "Minibatch accuracy: 85.2%\n",
      "Validation accuracy: 91.2%\n",
      "Minibatch loss at step 3750: 0.185045\n",
      "Minibatch accuracy: 94.5%\n",
      "Validation accuracy: 91.8%\n",
      "Minibatch loss at step 3800: 0.169083\n",
      "Minibatch accuracy: 94.5%\n",
      "Validation accuracy: 91.5%\n",
      "Minibatch loss at step 3850: 0.109378\n",
      "Minibatch accuracy: 96.9%\n",
      "Validation accuracy: 91.5%\n",
      "Minibatch loss at step 3900: 0.303841\n",
      "Minibatch accuracy: 90.6%\n",
      "Validation accuracy: 91.4%\n",
      "Minibatch loss at step 3950: 0.215864\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 91.5%\n",
      "Minibatch loss at step 4000: 0.223759\n",
      "Minibatch accuracy: 94.5%\n",
      "Validation accuracy: 91.8%\n",
      "Minibatch loss at step 4050: 0.246597\n",
      "Minibatch accuracy: 91.4%\n",
      "Validation accuracy: 91.6%\n",
      "Minibatch loss at step 4100: 0.269237\n",
      "Minibatch accuracy: 91.4%\n",
      "Validation accuracy: 91.5%\n",
      "Minibatch loss at step 4150: 0.144219\n",
      "Minibatch accuracy: 95.3%\n",
      "Validation accuracy: 91.5%\n",
      "Minibatch loss at step 4200: 0.256699\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 91.6%\n",
      "Minibatch loss at step 4250: 0.090643\n",
      "Minibatch accuracy: 98.4%\n",
      "Validation accuracy: 91.7%\n",
      "Minibatch loss at step 4300: 0.086243\n",
      "Minibatch accuracy: 96.1%\n",
      "Validation accuracy: 91.8%\n",
      "Minibatch loss at step 4350: 0.192194\n",
      "Minibatch accuracy: 95.3%\n",
      "Validation accuracy: 91.7%\n",
      "Minibatch loss at step 4400: 0.203618\n",
      "Minibatch accuracy: 94.5%\n",
      "Validation accuracy: 91.8%\n",
      "Minibatch loss at step 4450: 0.155121\n",
      "Minibatch accuracy: 95.3%\n",
      "Validation accuracy: 91.6%\n",
      "Minibatch loss at step 4500: 0.243829\n",
      "Minibatch accuracy: 90.6%\n",
      "Validation accuracy: 91.4%\n",
      "Minibatch loss at step 4550: 0.271476\n",
      "Minibatch accuracy: 91.4%\n",
      "Validation accuracy: 91.6%\n",
      "Minibatch loss at step 4600: 0.261680\n",
      "Minibatch accuracy: 91.4%\n",
      "Validation accuracy: 91.7%\n",
      "Minibatch loss at step 4650: 0.467452\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 91.6%\n",
      "Minibatch loss at step 4700: 0.287614\n",
      "Minibatch accuracy: 92.2%\n",
      "Validation accuracy: 91.7%\n",
      "Minibatch loss at step 4750: 0.203519\n",
      "Minibatch accuracy: 92.2%\n",
      "Validation accuracy: 91.7%\n",
      "Minibatch loss at step 4800: 0.244424\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 91.5%\n",
      "Minibatch loss at step 4850: 0.361022\n",
      "Minibatch accuracy: 85.2%\n",
      "Validation accuracy: 91.7%\n",
      "Minibatch loss at step 4900: 0.111017\n",
      "Minibatch accuracy: 96.9%\n",
      "Validation accuracy: 91.7%\n",
      "Minibatch loss at step 4950: 0.222256\n",
      "Minibatch accuracy: 92.2%\n",
      "Validation accuracy: 91.4%\n",
      "Minibatch loss at step 5000: 0.270189\n",
      "Minibatch accuracy: 94.5%\n",
      "Validation accuracy: 91.5%\n",
      "Minibatch loss at step 5050: 0.245997\n",
      "Minibatch accuracy: 94.5%\n",
      "Validation accuracy: 91.6%\n",
      "Minibatch loss at step 5100: 0.277927\n",
      "Minibatch accuracy: 90.6%\n",
      "Validation accuracy: 92.0%\n",
      "Minibatch loss at step 5150: 0.231664\n",
      "Minibatch accuracy: 91.4%\n",
      "Validation accuracy: 91.7%\n",
      "Minibatch loss at step 5200: 0.295593\n",
      "Minibatch accuracy: 89.1%\n",
      "Validation accuracy: 91.8%\n",
      "Minibatch loss at step 5250: 0.276260\n",
      "Minibatch accuracy: 91.4%\n",
      "Validation accuracy: 91.9%\n",
      "Minibatch loss at step 5300: 0.156666\n",
      "Minibatch accuracy: 95.3%\n",
      "Validation accuracy: 92.2%\n",
      "Minibatch loss at step 5350: 0.521214\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 91.6%\n",
      "Minibatch loss at step 5400: 0.249130\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 91.9%\n",
      "Minibatch loss at step 5450: 0.248185\n",
      "Minibatch accuracy: 91.4%\n",
      "Validation accuracy: 91.8%\n",
      "Minibatch loss at step 5500: 0.246688\n",
      "Minibatch accuracy: 90.6%\n",
      "Validation accuracy: 91.7%\n",
      "Minibatch loss at step 5550: 0.134279\n",
      "Minibatch accuracy: 95.3%\n",
      "Validation accuracy: 91.9%\n",
      "Minibatch loss at step 5600: 0.122131\n",
      "Minibatch accuracy: 96.1%\n",
      "Validation accuracy: 91.9%\n",
      "Minibatch loss at step 5650: 0.310148\n",
      "Minibatch accuracy: 90.6%\n",
      "Validation accuracy: 91.7%\n",
      "Minibatch loss at step 5700: 0.225900\n",
      "Minibatch accuracy: 93.0%\n",
      "Validation accuracy: 91.7%\n",
      "Minibatch loss at step 5750: 0.349955\n",
      "Minibatch accuracy: 89.1%\n",
      "Validation accuracy: 91.8%\n",
      "Minibatch loss at step 5800: 0.189067\n",
      "Minibatch accuracy: 94.5%\n",
      "Validation accuracy: 91.4%\n",
      "Minibatch loss at step 5850: 0.138651\n",
      "Minibatch accuracy: 95.3%\n",
      "Validation accuracy: 91.8%\n",
      "Minibatch loss at step 5900: 0.227839\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 91.8%\n",
      "Minibatch loss at step 5950: 0.242667\n",
      "Minibatch accuracy: 94.5%\n",
      "Validation accuracy: 91.8%\n",
      "Minibatch loss at step 6000: 0.381366\n",
      "Minibatch accuracy: 89.1%\n",
      "Validation accuracy: 91.8%\n",
      "Minibatch loss at step 6050: 0.229385\n",
      "Minibatch accuracy: 93.0%\n",
      "Validation accuracy: 91.9%\n",
      "Minibatch loss at step 6100: 0.168285\n",
      "Minibatch accuracy: 95.3%\n",
      "Validation accuracy: 91.9%\n",
      "Minibatch loss at step 6150: 0.276918\n",
      "Minibatch accuracy: 91.4%\n",
      "Validation accuracy: 91.8%\n",
      "Minibatch loss at step 6200: 0.221153\n",
      "Minibatch accuracy: 93.0%\n",
      "Validation accuracy: 91.8%\n",
      "Minibatch loss at step 6250: 0.138529\n",
      "Minibatch accuracy: 94.5%\n",
      "Validation accuracy: 91.8%\n",
      "Minibatch loss at step 6300: 0.287746\n",
      "Minibatch accuracy: 91.4%\n",
      "Validation accuracy: 92.1%\n",
      "Minibatch loss at step 6350: 0.104629\n",
      "Minibatch accuracy: 96.1%\n",
      "Validation accuracy: 92.0%\n",
      "Minibatch loss at step 6400: 0.186026\n",
      "Minibatch accuracy: 95.3%\n",
      "Validation accuracy: 91.9%\n",
      "Minibatch loss at step 6450: 0.222734\n",
      "Minibatch accuracy: 92.2%\n",
      "Validation accuracy: 92.0%\n",
      "Minibatch loss at step 6500: 0.153351\n",
      "Minibatch accuracy: 94.5%\n",
      "Validation accuracy: 91.8%\n",
      "Minibatch loss at step 6550: 0.240665\n",
      "Minibatch accuracy: 93.0%\n",
      "Validation accuracy: 91.7%\n",
      "Minibatch loss at step 6600: 0.178622\n",
      "Minibatch accuracy: 96.1%\n",
      "Validation accuracy: 92.1%\n",
      "Minibatch loss at step 6650: 0.276494\n",
      "Minibatch accuracy: 89.8%\n",
      "Validation accuracy: 92.3%\n",
      "Minibatch loss at step 6700: 0.269952\n",
      "Minibatch accuracy: 90.6%\n",
      "Validation accuracy: 91.5%\n",
      "Minibatch loss at step 6750: 0.191483\n",
      "Minibatch accuracy: 94.5%\n",
      "Validation accuracy: 91.9%\n",
      "Minibatch loss at step 6800: 0.213447\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 92.0%\n",
      "Minibatch loss at step 6850: 0.142884\n",
      "Minibatch accuracy: 95.3%\n",
      "Validation accuracy: 92.0%\n",
      "Minibatch loss at step 6900: 0.185364\n",
      "Minibatch accuracy: 93.0%\n",
      "Validation accuracy: 92.2%\n",
      "Minibatch loss at step 6950: 0.304099\n",
      "Minibatch accuracy: 91.4%\n",
      "Validation accuracy: 91.8%\n",
      "Minibatch loss at step 7000: 0.305533\n",
      "Minibatch accuracy: 90.6%\n",
      "Validation accuracy: 92.0%\n",
      "Minibatch loss at step 7050: 0.191311\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 92.3%\n",
      "Minibatch loss at step 7100: 0.149412\n",
      "Minibatch accuracy: 96.1%\n",
      "Validation accuracy: 91.9%\n",
      "Minibatch loss at step 7150: 0.230495\n",
      "Minibatch accuracy: 90.6%\n",
      "Validation accuracy: 91.9%\n",
      "Minibatch loss at step 7200: 0.315532\n",
      "Minibatch accuracy: 89.1%\n",
      "Validation accuracy: 92.4%\n",
      "Minibatch loss at step 7250: 0.254065\n",
      "Minibatch accuracy: 92.2%\n",
      "Validation accuracy: 91.8%\n",
      "Minibatch loss at step 7300: 0.168876\n",
      "Minibatch accuracy: 95.3%\n",
      "Validation accuracy: 92.0%\n",
      "Minibatch loss at step 7350: 0.145138\n",
      "Minibatch accuracy: 95.3%\n",
      "Validation accuracy: 92.0%\n",
      "Minibatch loss at step 7400: 0.223988\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 91.8%\n",
      "Minibatch loss at step 7450: 0.151666\n",
      "Minibatch accuracy: 96.1%\n",
      "Validation accuracy: 92.0%\n",
      "Minibatch loss at step 7500: 0.167461\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 91.8%\n",
      "Minibatch loss at step 7550: 0.234454\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 91.9%\n",
      "Minibatch loss at step 7600: 0.248691\n",
      "Minibatch accuracy: 93.0%\n",
      "Validation accuracy: 92.0%\n",
      "Minibatch loss at step 7650: 0.078536\n",
      "Minibatch accuracy: 96.9%\n",
      "Validation accuracy: 91.9%\n",
      "Minibatch loss at step 7700: 0.241590\n",
      "Minibatch accuracy: 92.2%\n",
      "Validation accuracy: 92.0%\n",
      "Minibatch loss at step 7750: 0.172815\n",
      "Minibatch accuracy: 94.5%\n",
      "Validation accuracy: 92.0%\n",
      "Minibatch loss at step 7800: 0.226860\n",
      "Minibatch accuracy: 92.2%\n",
      "Validation accuracy: 92.0%\n",
      "Minibatch loss at step 7850: 0.057843\n",
      "Minibatch accuracy: 99.2%\n",
      "Validation accuracy: 91.8%\n",
      "Minibatch loss at step 7900: 0.212484\n",
      "Minibatch accuracy: 92.2%\n",
      "Validation accuracy: 91.9%\n",
      "Minibatch loss at step 7950: 0.256773\n",
      "Minibatch accuracy: 90.6%\n",
      "Validation accuracy: 92.2%\n",
      "Minibatch loss at step 8000: 0.339404\n",
      "Minibatch accuracy: 86.7%\n",
      "Validation accuracy: 91.7%\n",
      "Minibatch loss at step 8050: 0.225849\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 91.7%\n",
      "Minibatch loss at step 8100: 0.120437\n",
      "Minibatch accuracy: 97.7%\n",
      "Validation accuracy: 92.0%\n",
      "Minibatch loss at step 8150: 0.247563\n",
      "Minibatch accuracy: 91.4%\n",
      "Validation accuracy: 92.1%\n",
      "Minibatch loss at step 8200: 0.073078\n",
      "Minibatch accuracy: 96.9%\n",
      "Validation accuracy: 92.2%\n",
      "Minibatch loss at step 8250: 0.329212\n",
      "Minibatch accuracy: 92.2%\n",
      "Validation accuracy: 92.1%\n",
      "Minibatch loss at step 8300: 0.210144\n",
      "Minibatch accuracy: 93.0%\n",
      "Validation accuracy: 92.2%\n",
      "Minibatch loss at step 8350: 0.220387\n",
      "Minibatch accuracy: 94.5%\n",
      "Validation accuracy: 92.1%\n",
      "Minibatch loss at step 8400: 0.172213\n",
      "Minibatch accuracy: 95.3%\n",
      "Validation accuracy: 92.3%\n",
      "Minibatch loss at step 8450: 0.267214\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 92.2%\n",
      "Minibatch loss at step 8500: 0.174414\n",
      "Minibatch accuracy: 96.1%\n",
      "Validation accuracy: 92.2%\n",
      "Minibatch loss at step 8550: 0.170788\n",
      "Minibatch accuracy: 94.5%\n",
      "Validation accuracy: 92.3%\n",
      "Minibatch loss at step 8600: 0.110845\n",
      "Minibatch accuracy: 95.3%\n",
      "Validation accuracy: 92.2%\n",
      "Minibatch loss at step 8650: 0.283298\n",
      "Minibatch accuracy: 89.1%\n",
      "Validation accuracy: 92.2%\n",
      "Minibatch loss at step 8700: 0.264425\n",
      "Minibatch accuracy: 94.5%\n",
      "Validation accuracy: 92.3%\n",
      "Minibatch loss at step 8750: 0.176159\n",
      "Minibatch accuracy: 94.5%\n",
      "Validation accuracy: 92.2%\n",
      "Minibatch loss at step 8800: 0.087391\n",
      "Minibatch accuracy: 97.7%\n",
      "Validation accuracy: 92.3%\n",
      "Minibatch loss at step 8850: 0.287500\n",
      "Minibatch accuracy: 91.4%\n",
      "Validation accuracy: 92.4%\n",
      "Minibatch loss at step 8900: 0.137393\n",
      "Minibatch accuracy: 95.3%\n",
      "Validation accuracy: 92.0%\n",
      "Minibatch loss at step 8950: 0.194668\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 91.9%\n",
      "Minibatch loss at step 9000: 0.203173\n",
      "Minibatch accuracy: 96.1%\n",
      "Validation accuracy: 91.9%\n",
      "Minibatch loss at step 9050: 0.140773\n",
      "Minibatch accuracy: 96.1%\n",
      "Validation accuracy: 92.2%\n",
      "Minibatch loss at step 9100: 0.075620\n",
      "Minibatch accuracy: 98.4%\n",
      "Validation accuracy: 92.2%\n",
      "Minibatch loss at step 9150: 0.196361\n",
      "Minibatch accuracy: 91.4%\n",
      "Validation accuracy: 92.3%\n",
      "Minibatch loss at step 9200: 0.135372\n",
      "Minibatch accuracy: 96.1%\n",
      "Validation accuracy: 92.0%\n",
      "Minibatch loss at step 9250: 0.150433\n",
      "Minibatch accuracy: 94.5%\n",
      "Validation accuracy: 92.2%\n",
      "Minibatch loss at step 9300: 0.166423\n",
      "Minibatch accuracy: 94.5%\n",
      "Validation accuracy: 92.1%\n",
      "Minibatch loss at step 9350: 0.134370\n",
      "Minibatch accuracy: 96.1%\n",
      "Validation accuracy: 92.2%\n",
      "Minibatch loss at step 9400: 0.163404\n",
      "Minibatch accuracy: 96.1%\n",
      "Validation accuracy: 92.1%\n",
      "Minibatch loss at step 9450: 0.183884\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 91.7%\n",
      "Minibatch loss at step 9500: 0.130864\n",
      "Minibatch accuracy: 96.9%\n",
      "Validation accuracy: 91.9%\n",
      "Minibatch loss at step 9550: 0.173423\n",
      "Minibatch accuracy: 93.0%\n",
      "Validation accuracy: 91.7%\n",
      "Minibatch loss at step 9600: 0.186958\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 91.9%\n",
      "Minibatch loss at step 9650: 0.074772\n",
      "Minibatch accuracy: 98.4%\n",
      "Validation accuracy: 92.0%\n",
      "Minibatch loss at step 9700: 0.105901\n",
      "Minibatch accuracy: 96.9%\n",
      "Validation accuracy: 92.1%\n",
      "Minibatch loss at step 9750: 0.096894\n",
      "Minibatch accuracy: 96.1%\n",
      "Validation accuracy: 92.3%\n",
      "Minibatch loss at step 9800: 0.137262\n",
      "Minibatch accuracy: 95.3%\n",
      "Validation accuracy: 92.0%\n",
      "Minibatch loss at step 9850: 0.176602\n",
      "Minibatch accuracy: 92.2%\n",
      "Validation accuracy: 92.2%\n",
      "Minibatch loss at step 9900: 0.317241\n",
      "Minibatch accuracy: 90.6%\n",
      "Validation accuracy: 91.9%\n",
      "Minibatch loss at step 9950: 0.117454\n",
      "Minibatch accuracy: 96.1%\n",
      "Validation accuracy: 91.7%\n",
      "Minibatch loss at step 10000: 0.174749\n",
      "Minibatch accuracy: 94.5%\n",
      "Validation accuracy: 92.2%\n",
      "Test accuracy: 96.8%\n"
     ]
    }
   ],
   "source": [
    "num_steps = 10001\n",
    "\n",
    "with tf.Session(graph=graph) as session:\n",
    "  tf.initialize_all_variables().run()\n",
    "  print('Initialized')\n",
    "  for step in range(num_steps):\n",
    "    offset = (step * batch_size) % (train_labels.shape[0] - batch_size)\n",
    "    batch_data = train_dataset[offset:(offset + batch_size), :, :, :]\n",
    "    batch_labels = train_labels[offset:(offset + batch_size), :]\n",
    "    feed_dict = {tf_train_dataset : batch_data, tf_train_labels : batch_labels}\n",
    "    _, l, predictions = session.run(\n",
    "      [optimizer, loss, train_prediction], feed_dict=feed_dict)\n",
    "    if (step % 50 == 0):\n",
    "      print('Minibatch loss at step %d: %f' % (step, l))\n",
    "      print('Minibatch accuracy: %.1f%%' % accuracy(predictions, batch_labels))\n",
    "      print('Validation accuracy: %.1f%%' % accuracy(\n",
    "        valid_prediction.eval(), valid_labels))\n",
    "  print('Test accuracy: %.1f%%' % accuracy(test_prediction.eval(), test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import math as math\n",
    "batch_size = 128\n",
    "patch_size = 4\n",
    "depth = 16\n",
    "l1_size = 705\n",
    "l2_size = 205\n",
    "\n",
    "\n",
    "graph = tf.Graph()\n",
    "\n",
    "with graph.as_default():\n",
    "\n",
    "  # Input data.\n",
    "  tf_train_dataset = tf.placeholder(tf.float32, shape=(batch_size, image_size, image_size, num_channels))\n",
    "  tf_train_labels = tf.placeholder(tf.float32, shape=(batch_size, num_labels))\n",
    "  tf_valid_dataset = tf.constant(valid_dataset)\n",
    "  tf_test_dataset = tf.constant(test_dataset)\n",
    "  \n",
    "  # Variables.\n",
    "  layerConv1_weights = tf.Variable(tf.truncated_normal(\n",
    "            [patch_size, patch_size, num_channels, depth], stddev=0.1))\n",
    "  layerConv1_biases = tf.Variable(tf.zeros([depth]))\n",
    "  layerConv2_weights = tf.Variable(tf.truncated_normal(\n",
    "            [patch_size, patch_size, depth, depth*2], stddev=math.sqrt(2.0/(patch_size*patch_size*depth))))\n",
    "  layerConv2_biases = tf.Variable(tf.zeros([depth*2]))\n",
    "  layerConv3_weights = tf.Variable(tf.truncated_normal(\n",
    "            [patch_size, patch_size, depth*2, depth*4], stddev=math.sqrt(2.0/(patch_size*patch_size*depth*2))))\n",
    "  layerConv3_biases = tf.Variable(tf.zeros([depth*4]))\n",
    "  layerConv4_weights = tf.Variable(tf.truncated_normal(\n",
    "            [patch_size, patch_size, depth*4, depth*4], stddev=math.sqrt(2.0/(patch_size*patch_size*depth*4))))\n",
    "  layerConv4_biases = tf.Variable(tf.zeros([depth*4]))\n",
    "  layerConv5_weights = tf.Variable(tf.truncated_normal(\n",
    "            [patch_size, patch_size, depth*4, depth*16], stddev=math.sqrt(2.0/(patch_size*patch_size*depth*4))))\n",
    "  layerConv5_biases = tf.Variable(tf.zeros([depth*16]))\n",
    "\n",
    "  layer1_weights = tf.Variable(tf.truncated_normal(\n",
    "            [image_size//7*image_size//7*(depth*4), l1_size], \n",
    "            stddev=math.sqrt(2.0/(image_size//7*image_size//7*(depth*4)))))\n",
    "  layer1_biases = tf.Variable(tf.zeros([l1_size]))\n",
    "  layer2_weights = tf.Variable(tf.truncated_normal(\n",
    "            [l1_size, l2_size], stddev=math.sqrt(2.0/(l1_size))))\n",
    "  layer2_biases = tf.Variable(tf.zeros([l2_size]))\n",
    "  layer3_weights = tf.Variable(tf.truncated_normal(\n",
    "            [l2_size, num_labels], stddev=math.sqrt(2.0/(l2_size))))\n",
    "  layer3_biases = tf.Variable(tf.zeros([num_labels]))\n",
    "  \n",
    "  # Model.\n",
    "  def model(data, use_dropout=False):\n",
    "    conv = tf.nn.conv2d(data, layerConv1_weights, [1, 1, 1, 1], padding='SAME')\n",
    "    hidden = tf.nn.elu(conv + layerConv1_biases)\n",
    "    pool = tf.nn.max_pool(hidden, [1, 2, 2, 1], [1, 2, 2, 1], padding='SAME')\n",
    "    \n",
    "    conv = tf.nn.conv2d(pool, layerConv2_weights, [1, 1, 1, 1], padding='SAME')\n",
    "    hidden = tf.nn.elu(conv + layerConv2_biases)\n",
    "\n",
    "    conv = tf.nn.conv2d(hidden, layerConv3_weights, [1, 1, 1, 1], padding='SAME')\n",
    "    hidden = tf.nn.elu(conv + layerConv3_biases)\n",
    "    pool = tf.nn.max_pool(hidden, [1, 2, 2, 1], [1, 2, 2, 1], padding='SAME')\n",
    "    \n",
    "    conv = tf.nn.conv2d(pool, layerConv4_weights, [1, 1, 1, 1], padding='SAME')\n",
    "    hidden = tf.nn.elu(conv + layerConv4_biases)\n",
    "    pool = tf.nn.max_pool(hidden, [1, 2, 2, 1], [1, 2, 2, 1], padding='SAME')\n",
    "   \n",
    "    conv = tf.nn.conv2d(pool, layerConv5_weights, [1, 1, 1, 1], padding='SAME')\n",
    "    hidden = tf.nn.elu(conv + layerConv5_biases)\n",
    "    pool = tf.nn.max_pool(hidden, [1, 2, 2, 1], [1, 2, 2, 1], padding='SAME')\n",
    "\n",
    "    shape = pool.get_shape().as_list()\n",
    "    reshape = tf.reshape(pool, [shape[0], shape[1] * shape[2] * shape[3]])\n",
    "    hidden = tf.nn.elu(tf.matmul(reshape, layer1_weights) + layer1_biases)\n",
    "    \n",
    "    if use_dropout:\n",
    "        hidden = tf.nn.dropout(hidden, 0.75)\n",
    "    \n",
    "    nn_hidden_layer = tf.matmul(hidden, layer2_weights) + layer2_biases\n",
    "    hidden = tf.nn.elu(nn_hidden_layer)\n",
    "    \n",
    "    if use_dropout:\n",
    "        hidden = tf.nn.dropout(hidden, 0.75)\n",
    "    return tf.matmul(hidden, layer3_weights) + layer3_biases\n",
    "  \n",
    "  # Training computation.\n",
    "  logits = model(tf_train_dataset, True)\n",
    "  loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits, tf_train_labels))\n",
    "    \n",
    "  global_step = tf.Variable(0)  # count the number of steps taken.\n",
    "  learning_rate = tf.train.exponential_decay(0.1, global_step, 1000, 0.9999, staircase=True)\n",
    "  \n",
    "  # Optimizer.\n",
    "  optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(loss, global_step=global_step)\n",
    "  \n",
    "  # Predictions for the training, validation, and test data.\n",
    "  train_prediction = tf.nn.softmax(logits)\n",
    "  valid_prediction = tf.nn.softmax(model(tf_valid_dataset))\n",
    "  test_prediction = tf.nn.softmax(model(tf_test_dataset))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized\n",
      "Minibatch loss at step 0: 2.376995\n",
      "Minibatch accuracy: 10.9%\n",
      "Validation accuracy: 10.1%\n",
      "Minibatch loss at step 50: 0.587227\n",
      "Minibatch accuracy: 82.0%\n",
      "Validation accuracy: 80.4%\n",
      "Minibatch loss at step 100: 0.623894\n",
      "Minibatch accuracy: 80.5%\n",
      "Validation accuracy: 83.3%\n",
      "Minibatch loss at step 150: 0.695412\n",
      "Minibatch accuracy: 79.7%\n",
      "Validation accuracy: 85.1%\n",
      "Minibatch loss at step 200: 0.590059\n",
      "Minibatch accuracy: 85.9%\n",
      "Validation accuracy: 85.6%\n",
      "Minibatch loss at step 250: 0.377872\n",
      "Minibatch accuracy: 90.6%\n",
      "Validation accuracy: 86.3%\n",
      "Minibatch loss at step 300: 0.592968\n",
      "Minibatch accuracy: 83.6%\n",
      "Validation accuracy: 85.8%\n",
      "Minibatch loss at step 350: 0.322172\n",
      "Minibatch accuracy: 91.4%\n",
      "Validation accuracy: 86.5%\n",
      "Minibatch loss at step 400: 0.464115\n",
      "Minibatch accuracy: 86.7%\n",
      "Validation accuracy: 87.2%\n",
      "Minibatch loss at step 450: 0.381428\n",
      "Minibatch accuracy: 91.4%\n",
      "Validation accuracy: 87.3%\n",
      "Minibatch loss at step 500: 0.324086\n",
      "Minibatch accuracy: 89.1%\n",
      "Validation accuracy: 87.9%\n",
      "Minibatch loss at step 550: 0.713126\n",
      "Minibatch accuracy: 80.5%\n",
      "Validation accuracy: 87.2%\n",
      "Minibatch loss at step 600: 0.502582\n",
      "Minibatch accuracy: 83.6%\n",
      "Validation accuracy: 87.8%\n",
      "Minibatch loss at step 650: 0.462456\n",
      "Minibatch accuracy: 85.2%\n",
      "Validation accuracy: 87.9%\n",
      "Minibatch loss at step 700: 0.442045\n",
      "Minibatch accuracy: 86.7%\n",
      "Validation accuracy: 88.3%\n",
      "Minibatch loss at step 750: 0.430678\n",
      "Minibatch accuracy: 85.2%\n",
      "Validation accuracy: 88.7%\n",
      "Minibatch loss at step 800: 0.268153\n",
      "Minibatch accuracy: 91.4%\n",
      "Validation accuracy: 89.0%\n",
      "Minibatch loss at step 850: 0.396881\n",
      "Minibatch accuracy: 88.3%\n",
      "Validation accuracy: 88.2%\n",
      "Minibatch loss at step 900: 0.418001\n",
      "Minibatch accuracy: 86.7%\n",
      "Validation accuracy: 89.0%\n",
      "Minibatch loss at step 950: 0.399111\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 89.2%\n",
      "Minibatch loss at step 1000: 0.563169\n",
      "Minibatch accuracy: 84.4%\n",
      "Validation accuracy: 89.5%\n",
      "Test accuracy: 95.1%\n"
     ]
    }
   ],
   "source": [
    "num_steps = 1001\n",
    "\n",
    "with tf.Session(graph=graph) as session:\n",
    "  tf.initialize_all_variables().run()\n",
    "  print('Initialized')\n",
    "  for step in range(num_steps):\n",
    "    offset = (step * batch_size) % (train_labels.shape[0] - batch_size)\n",
    "    batch_data = train_dataset[offset:(offset + batch_size), :, :, :]\n",
    "    batch_labels = train_labels[offset:(offset + batch_size), :]\n",
    "    feed_dict = {tf_train_dataset : batch_data, tf_train_labels : batch_labels}\n",
    "    _, l, predictions = session.run(\n",
    "      [optimizer, loss, train_prediction], feed_dict=feed_dict)\n",
    "    if (step % 50 == 0):\n",
    "      print('Minibatch loss at step %d: %f' % (step, l))\n",
    "      print('Minibatch accuracy: %.1f%%' % accuracy(predictions, batch_labels))\n",
    "      print('Validation accuracy: %.1f%%' % accuracy(\n",
    "        valid_prediction.eval(), valid_labels))\n",
    "  print('Test accuracy: %.1f%%' % accuracy(test_prediction.eval(), test_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use Relu and add L2 regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import math as math\n",
    "batch_size = 128\n",
    "patch_size = 4\n",
    "depth = 16\n",
    "l1_size = 705\n",
    "l2_size = 205\n",
    "\n",
    "\n",
    "graph = tf.Graph()\n",
    "\n",
    "with graph.as_default():\n",
    "\n",
    "  # Input data.\n",
    "  tf_train_dataset = tf.placeholder(tf.float32, shape=(batch_size, image_size, image_size, num_channels))\n",
    "  tf_train_labels = tf.placeholder(tf.float32, shape=(batch_size, num_labels))\n",
    "  tf_valid_dataset = tf.constant(valid_dataset)\n",
    "  tf_test_dataset = tf.constant(test_dataset)\n",
    "  \n",
    "  # Variables.\n",
    "  layerConv1_weights = tf.Variable(tf.truncated_normal(\n",
    "            [patch_size, patch_size, num_channels, depth], stddev=0.1))\n",
    "  layerConv1_biases = tf.Variable(tf.zeros([depth]))\n",
    "  layerConv2_weights = tf.Variable(tf.truncated_normal(\n",
    "            [patch_size, patch_size, depth, depth*2], stddev=math.sqrt(2.0/(patch_size*patch_size*depth))))\n",
    "  layerConv2_biases = tf.Variable(tf.zeros([depth*2]))\n",
    "  layerConv3_weights = tf.Variable(tf.truncated_normal(\n",
    "            [patch_size, patch_size, depth*2, depth*4], stddev=math.sqrt(2.0/(patch_size*patch_size*depth*2))))\n",
    "  layerConv3_biases = tf.Variable(tf.zeros([depth*4]))\n",
    "  layerConv4_weights = tf.Variable(tf.truncated_normal(\n",
    "            [patch_size, patch_size, depth*4, depth*4], stddev=math.sqrt(2.0/(patch_size*patch_size*depth*4))))\n",
    "  layerConv4_biases = tf.Variable(tf.zeros([depth*4]))\n",
    "  layerConv5_weights = tf.Variable(tf.truncated_normal(\n",
    "            [patch_size, patch_size, depth*4, depth*16], stddev=math.sqrt(2.0/(patch_size*patch_size*depth*4))))\n",
    "  layerConv5_biases = tf.Variable(tf.zeros([depth*16]))\n",
    "\n",
    "  layer1_weights = tf.Variable(tf.truncated_normal(\n",
    "            [image_size//7*image_size//7*(depth*4), l1_size], \n",
    "            stddev=math.sqrt(2.0/(image_size//7*image_size//7*(depth*4)))))\n",
    "  layer1_biases = tf.Variable(tf.zeros([l1_size]))\n",
    "  layer2_weights = tf.Variable(tf.truncated_normal(\n",
    "            [l1_size, l2_size], stddev=math.sqrt(2.0/(l1_size))))\n",
    "  layer2_biases = tf.Variable(tf.zeros([l2_size]))\n",
    "  layer3_weights = tf.Variable(tf.truncated_normal(\n",
    "            [l2_size, num_labels], stddev=math.sqrt(2.0/(l2_size))))\n",
    "  layer3_biases = tf.Variable(tf.zeros([num_labels]))\n",
    "  \n",
    "  # Model.\n",
    "  def model(data, use_dropout=False):\n",
    "    conv = tf.nn.conv2d(data, layerConv1_weights, [1, 1, 1, 1], padding='SAME')\n",
    "    hidden = tf.nn.relu(conv + layerConv1_biases)\n",
    "    pool = tf.nn.max_pool(hidden, [1, 2, 2, 1], [1, 2, 2, 1], padding='SAME')\n",
    "    \n",
    "    conv = tf.nn.conv2d(pool, layerConv2_weights, [1, 1, 1, 1], padding='SAME')\n",
    "    hidden = tf.nn.relu(conv + layerConv2_biases)\n",
    "\n",
    "    conv = tf.nn.conv2d(hidden, layerConv3_weights, [1, 1, 1, 1], padding='SAME')\n",
    "    hidden = tf.nn.relu(conv + layerConv3_biases)\n",
    "    pool = tf.nn.max_pool(hidden, [1, 2, 2, 1], [1, 2, 2, 1], padding='SAME')\n",
    "    \n",
    "    conv = tf.nn.conv2d(pool, layerConv4_weights, [1, 1, 1, 1], padding='SAME')\n",
    "    hidden = tf.nn.relu(conv + layerConv4_biases)\n",
    "    pool = tf.nn.max_pool(hidden, [1, 2, 2, 1], [1, 2, 2, 1], padding='SAME')\n",
    "   \n",
    "    conv = tf.nn.conv2d(pool, layerConv5_weights, [1, 1, 1, 1], padding='SAME')\n",
    "    hidden = tf.nn.relu(conv + layerConv5_biases)\n",
    "    pool = tf.nn.max_pool(hidden, [1, 2, 2, 1], [1, 2, 2, 1], padding='SAME')\n",
    "\n",
    "    shape = pool.get_shape().as_list()\n",
    "    reshape = tf.reshape(pool, [shape[0], shape[1] * shape[2] * shape[3]])\n",
    "    hidden = tf.nn.relu(tf.matmul(reshape, layer1_weights) + layer1_biases)\n",
    "    \n",
    "    if use_dropout:\n",
    "        hidden = tf.nn.dropout(hidden, 0.75)\n",
    "    \n",
    "    nn_hidden_layer = tf.matmul(hidden, layer2_weights) + layer2_biases\n",
    "    hidden = tf.nn.elu(nn_hidden_layer)\n",
    "    \n",
    "    if use_dropout:\n",
    "        hidden = tf.nn.dropout(hidden, 0.75)\n",
    "    return tf.matmul(hidden, layer3_weights) + layer3_biases\n",
    "  \n",
    "  # Training computation.\n",
    "  logits = model(tf_train_dataset, True)\n",
    "  loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits, tf_train_labels))\n",
    "\n",
    "  # L2 regularization for the fully connected parameters.\n",
    "  regularizers = (tf.nn.l2_loss(layerConv1_weights) + tf.nn.l2_loss(layerConv1_biases) +\n",
    "                  tf.nn.l2_loss(layerConv2_weights) + tf.nn.l2_loss(layerConv2_biases) +\n",
    "                  tf.nn.l2_loss(layerConv3_weights) + tf.nn.l2_loss(layerConv3_biases) +\n",
    "                  tf.nn.l2_loss(layerConv4_weights) + tf.nn.l2_loss(layerConv4_biases) +\n",
    "                  tf.nn.l2_loss(layerConv5_weights) + tf.nn.l2_loss(layerConv5_biases) +\n",
    "                  tf.nn.l2_loss(layer1_weights) + tf.nn.l2_loss(layer1_biases) +\n",
    "                  tf.nn.l2_loss(layer2_weights) + tf.nn.l2_loss(layer2_biases) +\n",
    "                  tf.nn.l2_loss(layer3_weights) + tf.nn.l2_loss(layer3_biases)) \n",
    "  # Add the regularization term to the loss.\n",
    "  loss += 1e-5 * regularizers\n",
    "    \n",
    "  global_step = tf.Variable(0)  # count the number of steps taken.\n",
    "  learning_rate = tf.train.exponential_decay(0.1, global_step, 100, 0.9999, staircase=True)\n",
    "  \n",
    "  # Optimizer.\n",
    "  optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(loss, global_step=global_step)\n",
    "  \n",
    "  # Predictions for the training, validation, and test data.\n",
    "  train_prediction = tf.nn.softmax(logits)\n",
    "  valid_prediction = tf.nn.softmax(model(tf_valid_dataset))\n",
    "  test_prediction = tf.nn.softmax(model(tf_test_dataset))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized\n",
      "Minibatch loss at step 0: 2.334960\n",
      "Minibatch accuracy: 7.8%\n",
      "Validation accuracy: 9.9%\n",
      "Minibatch loss at step 50: 1.007022\n",
      "Minibatch accuracy: 74.2%\n",
      "Validation accuracy: 59.5%\n",
      "Minibatch loss at step 100: 0.856069\n",
      "Minibatch accuracy: 76.6%\n",
      "Validation accuracy: 80.5%\n",
      "Minibatch loss at step 150: 0.718567\n",
      "Minibatch accuracy: 79.7%\n",
      "Validation accuracy: 83.2%\n",
      "Minibatch loss at step 200: 0.607941\n",
      "Minibatch accuracy: 83.6%\n",
      "Validation accuracy: 83.6%\n",
      "Minibatch loss at step 250: 0.387797\n",
      "Minibatch accuracy: 89.1%\n",
      "Validation accuracy: 84.8%\n",
      "Minibatch loss at step 300: 0.643311\n",
      "Minibatch accuracy: 78.9%\n",
      "Validation accuracy: 84.1%\n",
      "Minibatch loss at step 350: 0.367151\n",
      "Minibatch accuracy: 92.2%\n",
      "Validation accuracy: 85.9%\n",
      "Minibatch loss at step 400: 0.459973\n",
      "Minibatch accuracy: 85.2%\n",
      "Validation accuracy: 85.7%\n",
      "Minibatch loss at step 450: 0.409168\n",
      "Minibatch accuracy: 89.8%\n",
      "Validation accuracy: 86.7%\n",
      "Minibatch loss at step 500: 0.348739\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 87.1%\n",
      "Minibatch loss at step 550: 0.662957\n",
      "Minibatch accuracy: 82.0%\n",
      "Validation accuracy: 86.4%\n",
      "Minibatch loss at step 600: 0.494151\n",
      "Minibatch accuracy: 85.9%\n",
      "Validation accuracy: 87.2%\n",
      "Minibatch loss at step 650: 0.485447\n",
      "Minibatch accuracy: 85.2%\n",
      "Validation accuracy: 87.4%\n",
      "Minibatch loss at step 700: 0.454900\n",
      "Minibatch accuracy: 85.9%\n",
      "Validation accuracy: 88.1%\n",
      "Minibatch loss at step 750: 0.452741\n",
      "Minibatch accuracy: 85.2%\n",
      "Validation accuracy: 87.8%\n",
      "Minibatch loss at step 800: 0.279025\n",
      "Minibatch accuracy: 91.4%\n",
      "Validation accuracy: 88.1%\n",
      "Minibatch loss at step 850: 0.454351\n",
      "Minibatch accuracy: 85.9%\n",
      "Validation accuracy: 88.2%\n",
      "Minibatch loss at step 900: 0.404703\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 88.8%\n",
      "Minibatch loss at step 950: 0.433244\n",
      "Minibatch accuracy: 86.7%\n",
      "Validation accuracy: 88.6%\n",
      "Minibatch loss at step 1000: 0.543810\n",
      "Minibatch accuracy: 83.6%\n",
      "Validation accuracy: 88.9%\n",
      "Minibatch loss at step 1050: 0.246661\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 89.0%\n",
      "Minibatch loss at step 1100: 0.364895\n",
      "Minibatch accuracy: 90.6%\n",
      "Validation accuracy: 89.0%\n",
      "Minibatch loss at step 1150: 0.400836\n",
      "Minibatch accuracy: 88.3%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss at step 1200: 0.294750\n",
      "Minibatch accuracy: 92.2%\n",
      "Validation accuracy: 89.4%\n",
      "Minibatch loss at step 1250: 0.327695\n",
      "Minibatch accuracy: 90.6%\n",
      "Validation accuracy: 89.4%\n",
      "Minibatch loss at step 1300: 0.396947\n",
      "Minibatch accuracy: 90.6%\n",
      "Validation accuracy: 88.7%\n",
      "Minibatch loss at step 1350: 0.382349\n",
      "Minibatch accuracy: 85.9%\n",
      "Validation accuracy: 89.4%\n",
      "Minibatch loss at step 1400: 0.280494\n",
      "Minibatch accuracy: 92.2%\n",
      "Validation accuracy: 89.2%\n",
      "Minibatch loss at step 1450: 0.296619\n",
      "Minibatch accuracy: 92.2%\n",
      "Validation accuracy: 89.8%\n",
      "Minibatch loss at step 1500: 0.297218\n",
      "Minibatch accuracy: 93.0%\n",
      "Validation accuracy: 89.6%\n",
      "Minibatch loss at step 1550: 0.384514\n",
      "Minibatch accuracy: 89.8%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss at step 1600: 0.391306\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 89.6%\n",
      "Minibatch loss at step 1650: 0.317738\n",
      "Minibatch accuracy: 91.4%\n",
      "Validation accuracy: 89.8%\n",
      "Minibatch loss at step 1700: 0.278807\n",
      "Minibatch accuracy: 93.0%\n",
      "Validation accuracy: 90.2%\n",
      "Minibatch loss at step 1750: 0.329002\n",
      "Minibatch accuracy: 90.6%\n",
      "Validation accuracy: 90.1%\n",
      "Minibatch loss at step 1800: 0.390502\n",
      "Minibatch accuracy: 88.3%\n",
      "Validation accuracy: 90.2%\n",
      "Minibatch loss at step 1850: 0.440380\n",
      "Minibatch accuracy: 86.7%\n",
      "Validation accuracy: 90.1%\n",
      "Minibatch loss at step 1900: 0.429141\n",
      "Minibatch accuracy: 88.3%\n",
      "Validation accuracy: 89.9%\n",
      "Minibatch loss at step 1950: 0.224765\n",
      "Minibatch accuracy: 93.0%\n",
      "Validation accuracy: 90.5%\n",
      "Minibatch loss at step 2000: 0.253631\n",
      "Minibatch accuracy: 92.2%\n",
      "Validation accuracy: 90.1%\n",
      "Minibatch loss at step 2050: 0.294582\n",
      "Minibatch accuracy: 92.2%\n",
      "Validation accuracy: 90.3%\n",
      "Minibatch loss at step 2100: 0.279077\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 90.6%\n",
      "Minibatch loss at step 2150: 0.332289\n",
      "Minibatch accuracy: 91.4%\n",
      "Validation accuracy: 90.4%\n",
      "Minibatch loss at step 2200: 0.387854\n",
      "Minibatch accuracy: 88.3%\n",
      "Validation accuracy: 90.4%\n",
      "Minibatch loss at step 2250: 0.437850\n",
      "Minibatch accuracy: 86.7%\n",
      "Validation accuracy: 90.1%\n",
      "Minibatch loss at step 2300: 0.428042\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 90.3%\n",
      "Minibatch loss at step 2350: 0.306857\n",
      "Minibatch accuracy: 89.8%\n",
      "Validation accuracy: 90.8%\n",
      "Minibatch loss at step 2400: 0.259173\n",
      "Minibatch accuracy: 92.2%\n",
      "Validation accuracy: 90.7%\n",
      "Minibatch loss at step 2450: 0.222559\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 90.2%\n",
      "Minibatch loss at step 2500: 0.324612\n",
      "Minibatch accuracy: 89.8%\n",
      "Validation accuracy: 90.3%\n",
      "Minibatch loss at step 2550: 0.238185\n",
      "Minibatch accuracy: 93.0%\n",
      "Validation accuracy: 90.6%\n",
      "Minibatch loss at step 2600: 0.405128\n",
      "Minibatch accuracy: 89.1%\n",
      "Validation accuracy: 90.5%\n",
      "Minibatch loss at step 2650: 0.266854\n",
      "Minibatch accuracy: 89.8%\n",
      "Validation accuracy: 91.0%\n",
      "Minibatch loss at step 2700: 0.280905\n",
      "Minibatch accuracy: 93.0%\n",
      "Validation accuracy: 91.1%\n",
      "Minibatch loss at step 2750: 0.197168\n",
      "Minibatch accuracy: 94.5%\n",
      "Validation accuracy: 91.0%\n",
      "Minibatch loss at step 2800: 0.234902\n",
      "Minibatch accuracy: 93.0%\n",
      "Validation accuracy: 91.0%\n",
      "Minibatch loss at step 2850: 0.204130\n",
      "Minibatch accuracy: 94.5%\n",
      "Validation accuracy: 90.9%\n",
      "Minibatch loss at step 2900: 0.253577\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 90.9%\n",
      "Minibatch loss at step 2950: 0.290265\n",
      "Minibatch accuracy: 92.2%\n",
      "Validation accuracy: 90.7%\n",
      "Minibatch loss at step 3000: 0.338641\n",
      "Minibatch accuracy: 88.3%\n",
      "Validation accuracy: 90.8%\n",
      "Minibatch loss at step 3050: 0.364005\n",
      "Minibatch accuracy: 90.6%\n",
      "Validation accuracy: 90.9%\n",
      "Minibatch loss at step 3100: 0.268301\n",
      "Minibatch accuracy: 92.2%\n",
      "Validation accuracy: 90.8%\n",
      "Minibatch loss at step 3150: 0.281552\n",
      "Minibatch accuracy: 90.6%\n",
      "Validation accuracy: 90.9%\n",
      "Minibatch loss at step 3200: 0.259422\n",
      "Minibatch accuracy: 92.2%\n",
      "Validation accuracy: 90.5%\n",
      "Minibatch loss at step 3250: 0.311214\n",
      "Minibatch accuracy: 91.4%\n",
      "Validation accuracy: 91.0%\n",
      "Minibatch loss at step 3300: 0.274488\n",
      "Minibatch accuracy: 91.4%\n",
      "Validation accuracy: 91.2%\n",
      "Minibatch loss at step 3350: 0.396236\n",
      "Minibatch accuracy: 88.3%\n",
      "Validation accuracy: 91.0%\n",
      "Minibatch loss at step 3400: 0.221872\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 90.8%\n",
      "Minibatch loss at step 3450: 0.288799\n",
      "Minibatch accuracy: 92.2%\n",
      "Validation accuracy: 90.7%\n",
      "Minibatch loss at step 3500: 0.369103\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 91.3%\n",
      "Minibatch loss at step 3550: 0.134892\n",
      "Minibatch accuracy: 96.1%\n",
      "Validation accuracy: 91.2%\n",
      "Minibatch loss at step 3600: 0.368591\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 91.0%\n",
      "Minibatch loss at step 3650: 0.281609\n",
      "Minibatch accuracy: 91.4%\n",
      "Validation accuracy: 91.3%\n",
      "Minibatch loss at step 3700: 0.319076\n",
      "Minibatch accuracy: 89.1%\n",
      "Validation accuracy: 91.3%\n",
      "Minibatch loss at step 3750: 0.191052\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 91.2%\n",
      "Minibatch loss at step 3800: 0.179399\n",
      "Minibatch accuracy: 95.3%\n",
      "Validation accuracy: 91.2%\n",
      "Minibatch loss at step 3850: 0.107467\n",
      "Minibatch accuracy: 96.9%\n",
      "Validation accuracy: 91.5%\n",
      "Minibatch loss at step 3900: 0.260328\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 91.5%\n",
      "Minibatch loss at step 3950: 0.250489\n",
      "Minibatch accuracy: 95.3%\n",
      "Validation accuracy: 91.2%\n",
      "Minibatch loss at step 4000: 0.242498\n",
      "Minibatch accuracy: 94.5%\n",
      "Validation accuracy: 91.4%\n",
      "Minibatch loss at step 4050: 0.227718\n",
      "Minibatch accuracy: 92.2%\n",
      "Validation accuracy: 91.6%\n",
      "Minibatch loss at step 4100: 0.330866\n",
      "Minibatch accuracy: 88.3%\n",
      "Validation accuracy: 91.3%\n",
      "Minibatch loss at step 4150: 0.170728\n",
      "Minibatch accuracy: 94.5%\n",
      "Validation accuracy: 91.5%\n",
      "Minibatch loss at step 4200: 0.229288\n",
      "Minibatch accuracy: 94.5%\n",
      "Validation accuracy: 91.0%\n",
      "Minibatch loss at step 4250: 0.101597\n",
      "Minibatch accuracy: 97.7%\n",
      "Validation accuracy: 91.5%\n",
      "Minibatch loss at step 4300: 0.124077\n",
      "Minibatch accuracy: 96.9%\n",
      "Validation accuracy: 91.7%\n",
      "Minibatch loss at step 4350: 0.221576\n",
      "Minibatch accuracy: 92.2%\n",
      "Validation accuracy: 91.8%\n",
      "Minibatch loss at step 4400: 0.177852\n",
      "Minibatch accuracy: 96.1%\n",
      "Validation accuracy: 91.8%\n",
      "Minibatch loss at step 4450: 0.158193\n",
      "Minibatch accuracy: 96.1%\n",
      "Validation accuracy: 91.5%\n",
      "Minibatch loss at step 4500: 0.243750\n",
      "Minibatch accuracy: 93.0%\n",
      "Validation accuracy: 91.6%\n",
      "Minibatch loss at step 4550: 0.303325\n",
      "Minibatch accuracy: 90.6%\n",
      "Validation accuracy: 91.7%\n",
      "Minibatch loss at step 4600: 0.276861\n",
      "Minibatch accuracy: 91.4%\n",
      "Validation accuracy: 91.3%\n",
      "Minibatch loss at step 4650: 0.491005\n",
      "Minibatch accuracy: 86.7%\n",
      "Validation accuracy: 91.4%\n",
      "Minibatch loss at step 4700: 0.297032\n",
      "Minibatch accuracy: 89.8%\n",
      "Validation accuracy: 91.5%\n",
      "Minibatch loss at step 4750: 0.196993\n",
      "Minibatch accuracy: 92.2%\n",
      "Validation accuracy: 91.5%\n",
      "Minibatch loss at step 4800: 0.318238\n",
      "Minibatch accuracy: 91.4%\n",
      "Validation accuracy: 91.5%\n",
      "Minibatch loss at step 4850: 0.379383\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 91.8%\n",
      "Minibatch loss at step 4900: 0.158234\n",
      "Minibatch accuracy: 94.5%\n",
      "Validation accuracy: 91.5%\n",
      "Minibatch loss at step 4950: 0.271708\n",
      "Minibatch accuracy: 89.8%\n",
      "Validation accuracy: 91.6%\n",
      "Minibatch loss at step 5000: 0.286977\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 91.5%\n",
      "Minibatch loss at step 5050: 0.300979\n",
      "Minibatch accuracy: 92.2%\n",
      "Validation accuracy: 91.4%\n",
      "Minibatch loss at step 5100: 0.335763\n",
      "Minibatch accuracy: 92.2%\n",
      "Validation accuracy: 91.7%\n",
      "Minibatch loss at step 5150: 0.275446\n",
      "Minibatch accuracy: 92.2%\n",
      "Validation accuracy: 91.9%\n",
      "Minibatch loss at step 5200: 0.261358\n",
      "Minibatch accuracy: 92.2%\n",
      "Validation accuracy: 91.6%\n",
      "Minibatch loss at step 5250: 0.368991\n",
      "Minibatch accuracy: 86.7%\n",
      "Validation accuracy: 91.9%\n",
      "Minibatch loss at step 5300: 0.171913\n",
      "Minibatch accuracy: 95.3%\n",
      "Validation accuracy: 91.8%\n",
      "Minibatch loss at step 5350: 0.505746\n",
      "Minibatch accuracy: 85.2%\n",
      "Validation accuracy: 91.5%\n",
      "Minibatch loss at step 5400: 0.211345\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 91.7%\n",
      "Minibatch loss at step 5450: 0.291562\n",
      "Minibatch accuracy: 91.4%\n",
      "Validation accuracy: 91.9%\n",
      "Minibatch loss at step 5500: 0.244938\n",
      "Minibatch accuracy: 91.4%\n",
      "Validation accuracy: 92.0%\n",
      "Minibatch loss at step 5550: 0.172400\n",
      "Minibatch accuracy: 95.3%\n",
      "Validation accuracy: 92.1%\n",
      "Minibatch loss at step 5600: 0.144133\n",
      "Minibatch accuracy: 96.1%\n",
      "Validation accuracy: 92.1%\n",
      "Minibatch loss at step 5650: 0.331914\n",
      "Minibatch accuracy: 90.6%\n",
      "Validation accuracy: 91.9%\n",
      "Minibatch loss at step 5700: 0.223848\n",
      "Minibatch accuracy: 91.4%\n",
      "Validation accuracy: 91.8%\n",
      "Minibatch loss at step 5750: 0.351328\n",
      "Minibatch accuracy: 88.3%\n",
      "Validation accuracy: 92.1%\n",
      "Minibatch loss at step 5800: 0.233459\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 91.5%\n",
      "Minibatch loss at step 5850: 0.159504\n",
      "Minibatch accuracy: 96.1%\n",
      "Validation accuracy: 91.9%\n",
      "Minibatch loss at step 5900: 0.228463\n",
      "Minibatch accuracy: 92.2%\n",
      "Validation accuracy: 92.1%\n",
      "Minibatch loss at step 5950: 0.241061\n",
      "Minibatch accuracy: 95.3%\n",
      "Validation accuracy: 92.0%\n",
      "Minibatch loss at step 6000: 0.430867\n",
      "Minibatch accuracy: 89.8%\n",
      "Validation accuracy: 91.9%\n",
      "Minibatch loss at step 6050: 0.291958\n",
      "Minibatch accuracy: 89.1%\n",
      "Validation accuracy: 91.9%\n",
      "Minibatch loss at step 6100: 0.226648\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 92.1%\n",
      "Minibatch loss at step 6150: 0.274976\n",
      "Minibatch accuracy: 92.2%\n",
      "Validation accuracy: 92.0%\n",
      "Minibatch loss at step 6200: 0.183271\n",
      "Minibatch accuracy: 95.3%\n",
      "Validation accuracy: 92.1%\n",
      "Minibatch loss at step 6250: 0.192001\n",
      "Minibatch accuracy: 93.0%\n",
      "Validation accuracy: 91.8%\n",
      "Minibatch loss at step 6300: 0.283840\n",
      "Minibatch accuracy: 92.2%\n",
      "Validation accuracy: 91.8%\n",
      "Minibatch loss at step 6350: 0.109344\n",
      "Minibatch accuracy: 97.7%\n",
      "Validation accuracy: 91.7%\n",
      "Minibatch loss at step 6400: 0.204391\n",
      "Minibatch accuracy: 96.1%\n",
      "Validation accuracy: 91.9%\n",
      "Minibatch loss at step 6450: 0.251441\n",
      "Minibatch accuracy: 93.0%\n",
      "Validation accuracy: 91.9%\n",
      "Minibatch loss at step 6500: 0.213812\n",
      "Minibatch accuracy: 95.3%\n",
      "Validation accuracy: 91.5%\n",
      "Minibatch loss at step 6550: 0.237764\n",
      "Minibatch accuracy: 93.0%\n",
      "Validation accuracy: 91.8%\n",
      "Minibatch loss at step 6600: 0.243467\n",
      "Minibatch accuracy: 94.5%\n",
      "Validation accuracy: 92.1%\n",
      "Minibatch loss at step 6650: 0.278628\n",
      "Minibatch accuracy: 92.2%\n",
      "Validation accuracy: 92.2%\n",
      "Minibatch loss at step 6700: 0.301859\n",
      "Minibatch accuracy: 89.8%\n",
      "Validation accuracy: 91.6%\n",
      "Minibatch loss at step 6750: 0.206446\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 91.8%\n",
      "Minibatch loss at step 6800: 0.278014\n",
      "Minibatch accuracy: 94.5%\n",
      "Validation accuracy: 92.0%\n",
      "Minibatch loss at step 6850: 0.219714\n",
      "Minibatch accuracy: 92.2%\n",
      "Validation accuracy: 92.3%\n",
      "Minibatch loss at step 6900: 0.214638\n",
      "Minibatch accuracy: 92.2%\n",
      "Validation accuracy: 92.2%\n",
      "Minibatch loss at step 6950: 0.358525\n",
      "Minibatch accuracy: 88.3%\n",
      "Validation accuracy: 92.3%\n",
      "Minibatch loss at step 7000: 0.285095\n",
      "Minibatch accuracy: 92.2%\n",
      "Validation accuracy: 92.1%\n",
      "Minibatch loss at step 7050: 0.223451\n",
      "Minibatch accuracy: 94.5%\n",
      "Validation accuracy: 92.2%\n",
      "Minibatch loss at step 7100: 0.176397\n",
      "Minibatch accuracy: 96.1%\n",
      "Validation accuracy: 92.2%\n",
      "Minibatch loss at step 7150: 0.287628\n",
      "Minibatch accuracy: 90.6%\n",
      "Validation accuracy: 92.1%\n",
      "Minibatch loss at step 7200: 0.381531\n",
      "Minibatch accuracy: 88.3%\n",
      "Validation accuracy: 92.3%\n",
      "Minibatch loss at step 7250: 0.319260\n",
      "Minibatch accuracy: 90.6%\n",
      "Validation accuracy: 91.9%\n",
      "Minibatch loss at step 7300: 0.229956\n",
      "Minibatch accuracy: 93.0%\n",
      "Validation accuracy: 92.0%\n",
      "Minibatch loss at step 7350: 0.206849\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 92.2%\n",
      "Minibatch loss at step 7400: 0.225419\n",
      "Minibatch accuracy: 92.2%\n",
      "Validation accuracy: 92.0%\n",
      "Minibatch loss at step 7450: 0.212183\n",
      "Minibatch accuracy: 94.5%\n",
      "Validation accuracy: 92.5%\n",
      "Minibatch loss at step 7500: 0.242370\n",
      "Minibatch accuracy: 91.4%\n",
      "Validation accuracy: 92.0%\n",
      "Minibatch loss at step 7550: 0.281073\n",
      "Minibatch accuracy: 93.0%\n",
      "Validation accuracy: 92.2%\n",
      "Minibatch loss at step 7600: 0.204038\n",
      "Minibatch accuracy: 93.0%\n",
      "Validation accuracy: 92.0%\n",
      "Minibatch loss at step 7650: 0.135009\n",
      "Minibatch accuracy: 96.1%\n",
      "Validation accuracy: 92.2%\n",
      "Minibatch loss at step 7700: 0.279122\n",
      "Minibatch accuracy: 92.2%\n",
      "Validation accuracy: 92.0%\n",
      "Minibatch loss at step 7750: 0.254195\n",
      "Minibatch accuracy: 92.2%\n",
      "Validation accuracy: 92.0%\n",
      "Minibatch loss at step 7800: 0.203366\n",
      "Minibatch accuracy: 94.5%\n",
      "Validation accuracy: 92.1%\n",
      "Minibatch loss at step 7850: 0.113973\n",
      "Minibatch accuracy: 97.7%\n",
      "Validation accuracy: 91.9%\n",
      "Minibatch loss at step 7900: 0.176773\n",
      "Minibatch accuracy: 94.5%\n",
      "Validation accuracy: 92.0%\n",
      "Minibatch loss at step 7950: 0.269953\n",
      "Minibatch accuracy: 90.6%\n",
      "Validation accuracy: 92.1%\n",
      "Minibatch loss at step 8000: 0.345486\n",
      "Minibatch accuracy: 86.7%\n",
      "Validation accuracy: 91.9%\n",
      "Minibatch loss at step 8050: 0.311537\n",
      "Minibatch accuracy: 90.6%\n",
      "Validation accuracy: 91.8%\n",
      "Minibatch loss at step 8100: 0.146546\n",
      "Minibatch accuracy: 96.9%\n",
      "Validation accuracy: 92.1%\n",
      "Minibatch loss at step 8150: 0.256182\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 91.9%\n",
      "Minibatch loss at step 8200: 0.144927\n",
      "Minibatch accuracy: 94.5%\n",
      "Validation accuracy: 92.1%\n",
      "Minibatch loss at step 8250: 0.352995\n",
      "Minibatch accuracy: 90.6%\n",
      "Validation accuracy: 91.5%\n",
      "Minibatch loss at step 8300: 0.232417\n",
      "Minibatch accuracy: 91.4%\n",
      "Validation accuracy: 92.2%\n",
      "Minibatch loss at step 8350: 0.211556\n",
      "Minibatch accuracy: 94.5%\n",
      "Validation accuracy: 92.1%\n",
      "Minibatch loss at step 8400: 0.210538\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 92.0%\n",
      "Minibatch loss at step 8450: 0.365104\n",
      "Minibatch accuracy: 90.6%\n",
      "Validation accuracy: 91.7%\n",
      "Minibatch loss at step 8500: 0.204397\n",
      "Minibatch accuracy: 96.1%\n",
      "Validation accuracy: 92.3%\n",
      "Minibatch loss at step 8550: 0.140810\n",
      "Minibatch accuracy: 96.9%\n",
      "Validation accuracy: 92.2%\n",
      "Minibatch loss at step 8600: 0.106983\n",
      "Minibatch accuracy: 95.3%\n",
      "Validation accuracy: 92.4%\n",
      "Minibatch loss at step 8650: 0.286137\n",
      "Minibatch accuracy: 91.4%\n",
      "Validation accuracy: 92.1%\n",
      "Minibatch loss at step 8700: 0.255796\n",
      "Minibatch accuracy: 96.1%\n",
      "Validation accuracy: 92.3%\n",
      "Minibatch loss at step 8750: 0.220428\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 92.5%\n",
      "Minibatch loss at step 8800: 0.143843\n",
      "Minibatch accuracy: 95.3%\n",
      "Validation accuracy: 92.3%\n",
      "Minibatch loss at step 8850: 0.244676\n",
      "Minibatch accuracy: 93.0%\n",
      "Validation accuracy: 92.4%\n",
      "Minibatch loss at step 8900: 0.151839\n",
      "Minibatch accuracy: 96.1%\n",
      "Validation accuracy: 92.2%\n",
      "Minibatch loss at step 8950: 0.227803\n",
      "Minibatch accuracy: 93.0%\n",
      "Validation accuracy: 92.0%\n",
      "Minibatch loss at step 9000: 0.189610\n",
      "Minibatch accuracy: 94.5%\n",
      "Validation accuracy: 92.4%\n",
      "Minibatch loss at step 9050: 0.201903\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 92.5%\n",
      "Minibatch loss at step 9100: 0.124734\n",
      "Minibatch accuracy: 96.9%\n",
      "Validation accuracy: 92.3%\n",
      "Minibatch loss at step 9150: 0.226045\n",
      "Minibatch accuracy: 93.0%\n",
      "Validation accuracy: 92.3%\n",
      "Minibatch loss at step 9200: 0.217711\n",
      "Minibatch accuracy: 94.5%\n",
      "Validation accuracy: 92.3%\n",
      "Minibatch loss at step 9250: 0.168518\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 91.7%\n",
      "Minibatch loss at step 9300: 0.184331\n",
      "Minibatch accuracy: 96.1%\n",
      "Validation accuracy: 92.2%\n",
      "Minibatch loss at step 9350: 0.164685\n",
      "Minibatch accuracy: 95.3%\n",
      "Validation accuracy: 92.2%\n",
      "Minibatch loss at step 9400: 0.177691\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 92.0%\n",
      "Minibatch loss at step 9450: 0.226921\n",
      "Minibatch accuracy: 94.5%\n",
      "Validation accuracy: 92.0%\n",
      "Minibatch loss at step 9500: 0.165018\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 92.0%\n",
      "Minibatch loss at step 9550: 0.252944\n",
      "Minibatch accuracy: 93.0%\n",
      "Validation accuracy: 92.1%\n",
      "Minibatch loss at step 9600: 0.220006\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 92.0%\n",
      "Minibatch loss at step 9650: 0.149840\n",
      "Minibatch accuracy: 94.5%\n",
      "Validation accuracy: 92.3%\n",
      "Minibatch loss at step 9700: 0.174961\n",
      "Minibatch accuracy: 94.5%\n",
      "Validation accuracy: 92.3%\n",
      "Minibatch loss at step 9750: 0.117198\n",
      "Minibatch accuracy: 97.7%\n",
      "Validation accuracy: 92.5%\n",
      "Minibatch loss at step 9800: 0.160063\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 92.2%\n",
      "Minibatch loss at step 9850: 0.225213\n",
      "Minibatch accuracy: 92.2%\n",
      "Validation accuracy: 92.2%\n",
      "Minibatch loss at step 9900: 0.213886\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 92.2%\n",
      "Minibatch loss at step 9950: 0.161585\n",
      "Minibatch accuracy: 95.3%\n",
      "Validation accuracy: 92.1%\n",
      "Minibatch loss at step 10000: 0.221775\n",
      "Minibatch accuracy: 93.0%\n",
      "Validation accuracy: 92.3%\n",
      "Test accuracy: 96.9%\n"
     ]
    }
   ],
   "source": [
    "num_steps = 20001\n",
    "\n",
    "with tf.Session(graph=graph) as session:\n",
    "  tf.initialize_all_variables().run()\n",
    "  print('Initialized')\n",
    "  for step in range(num_steps):\n",
    "    offset = (step * batch_size) % (train_labels.shape[0] - batch_size)\n",
    "    batch_data = train_dataset[offset:(offset + batch_size), :, :, :]\n",
    "    batch_labels = train_labels[offset:(offset + batch_size), :]\n",
    "    feed_dict = {tf_train_dataset : batch_data, tf_train_labels : batch_labels}\n",
    "    _, l, lr, predictions = session.run(\n",
    "      [optimizer, loss, learning_rate,train_prediction], feed_dict=feed_dict)\n",
    "    if (step % 50 == 0):\n",
    "      print('Minibatch loss at step %d: %f' % (step, l))\n",
    "      print('Minibatch learning rate at step %d: %f' % (step, lr))\n",
    "      print('Minibatch accuracy: %.1f%%' % accuracy(predictions, batch_labels))\n",
    "      print('Validation accuracy: %.1f%%' % accuracy(\n",
    "        valid_prediction.eval(), valid_labels))\n",
    "  print('Test accuracy: %.1f%%' % accuracy(test_prediction.eval(), test_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Give best result so far"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import math as math\n",
    "batch_size = 128\n",
    "patch_size = 4\n",
    "depth = 16\n",
    "l1_size = 705\n",
    "l2_size = 205\n",
    "train_size = train_labels.shape[0]\n",
    "\n",
    "graph = tf.Graph()\n",
    "\n",
    "with graph.as_default():\n",
    "\n",
    "  # Input data.\n",
    "  tf_train_dataset = tf.placeholder(tf.float32, shape=(batch_size, image_size, image_size, num_channels))\n",
    "  tf_train_labels = tf.placeholder(tf.float32, shape=(batch_size, num_labels))\n",
    "  tf_valid_dataset = tf.constant(valid_dataset)\n",
    "  tf_test_dataset = tf.constant(test_dataset)\n",
    "  \n",
    "  # Variables.\n",
    "  layerConv1_weights = tf.Variable(tf.truncated_normal(\n",
    "            [patch_size, patch_size, num_channels, depth], stddev=0.1))\n",
    "  layerConv1_biases = tf.Variable(tf.zeros([depth]))\n",
    "  layerConv2_weights = tf.Variable(tf.truncated_normal(\n",
    "            [patch_size, patch_size, depth, depth*2], stddev=math.sqrt(2.0/(patch_size*patch_size*depth))))\n",
    "  layerConv2_biases = tf.Variable(tf.zeros([depth*2]))\n",
    "  layerConv3_weights = tf.Variable(tf.truncated_normal(\n",
    "            [patch_size, patch_size, depth*2, depth*4], stddev=math.sqrt(2.0/(patch_size*patch_size*depth*2))))\n",
    "  layerConv3_biases = tf.Variable(tf.zeros([depth*4]))\n",
    "  layerConv4_weights = tf.Variable(tf.truncated_normal(\n",
    "            [patch_size, patch_size, depth*4, depth*4], stddev=math.sqrt(2.0/(patch_size*patch_size*depth*4))))\n",
    "  layerConv4_biases = tf.Variable(tf.zeros([depth*4]))\n",
    "  layerConv5_weights = tf.Variable(tf.truncated_normal(\n",
    "            [patch_size, patch_size, depth*4, depth*16], stddev=math.sqrt(2.0/(patch_size*patch_size*depth*4))))\n",
    "  layerConv5_biases = tf.Variable(tf.zeros([depth*16]))\n",
    "\n",
    "  layer1_weights = tf.Variable(tf.truncated_normal(\n",
    "            [image_size//7*image_size//7*(depth*4), l1_size], \n",
    "            stddev=math.sqrt(2.0/(image_size//7*image_size//7*(depth*4)))))\n",
    "  layer1_biases = tf.Variable(tf.zeros([l1_size]))\n",
    "  layer2_weights = tf.Variable(tf.truncated_normal(\n",
    "            [l1_size, l2_size], stddev=math.sqrt(2.0/(l1_size))))\n",
    "  layer2_biases = tf.Variable(tf.zeros([l2_size]))\n",
    "  layer3_weights = tf.Variable(tf.truncated_normal(\n",
    "            [l2_size, num_labels], stddev=math.sqrt(2.0/(l2_size))))\n",
    "  layer3_biases = tf.Variable(tf.zeros([num_labels]))\n",
    "  \n",
    "  # Model.\n",
    "  def model(data, use_dropout=False):\n",
    "    conv = tf.nn.conv2d(data, layerConv1_weights, [1, 1, 1, 1], padding='SAME')\n",
    "    hidden = tf.nn.relu(conv + layerConv1_biases)\n",
    "    pool = tf.nn.max_pool(hidden, [1, 2, 2, 1], [1, 2, 2, 1], padding='SAME')\n",
    "    \n",
    "    conv = tf.nn.conv2d(pool, layerConv2_weights, [1, 1, 1, 1], padding='SAME')\n",
    "    hidden = tf.nn.relu(conv + layerConv2_biases)\n",
    "\n",
    "    conv = tf.nn.conv2d(hidden, layerConv3_weights, [1, 1, 1, 1], padding='SAME')\n",
    "    hidden = tf.nn.relu(conv + layerConv3_biases)\n",
    "    pool = tf.nn.max_pool(hidden, [1, 2, 2, 1], [1, 2, 2, 1], padding='SAME')\n",
    "    \n",
    "    conv = tf.nn.conv2d(pool, layerConv4_weights, [1, 1, 1, 1], padding='SAME')\n",
    "    hidden = tf.nn.relu(conv + layerConv4_biases)\n",
    "    pool = tf.nn.max_pool(hidden, [1, 2, 2, 1], [1, 2, 2, 1], padding='SAME')\n",
    "   \n",
    "    conv = tf.nn.conv2d(pool, layerConv5_weights, [1, 1, 1, 1], padding='SAME')\n",
    "    hidden = tf.nn.relu(conv + layerConv5_biases)\n",
    "    pool = tf.nn.max_pool(hidden, [1, 2, 2, 1], [1, 2, 2, 1], padding='SAME')\n",
    "\n",
    "    shape = pool.get_shape().as_list()\n",
    "    reshape = tf.reshape(pool, [shape[0], shape[1] * shape[2] * shape[3]])\n",
    "    hidden = tf.nn.relu(tf.matmul(reshape, layer1_weights) + layer1_biases)\n",
    "    \n",
    "    if use_dropout:\n",
    "        hidden = tf.nn.dropout(hidden, 0.5)\n",
    "    \n",
    "    nn_hidden_layer = tf.matmul(hidden, layer2_weights) + layer2_biases\n",
    "    hidden = tf.nn.elu(nn_hidden_layer)\n",
    "    \n",
    "    if use_dropout:\n",
    "        hidden = tf.nn.dropout(hidden, 0.5)\n",
    "    return tf.matmul(hidden, layer3_weights) + layer3_biases\n",
    "  \n",
    "  # Training computation.\n",
    "  logits = model(tf_train_dataset, True)\n",
    "  loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits, tf_train_labels))\n",
    "\n",
    "  # L2 regularization for the fully connected parameters.\n",
    "  regularizers = (tf.nn.l2_loss(layer1_weights) + tf.nn.l2_loss(layer1_biases) +\n",
    "                  tf.nn.l2_loss(layer2_weights) + tf.nn.l2_loss(layer2_biases) +\n",
    "                  tf.nn.l2_loss(layer3_weights) + tf.nn.l2_loss(layer3_biases)) \n",
    "  # Add the regularization term to the loss.\n",
    "  loss += 5e-4 * regularizers\n",
    "    \n",
    "  # Optimizer.\n",
    "  global_step = tf.Variable(0)  # count the number of steps taken.\n",
    "  learning_rate = tf.train.exponential_decay(0.5, global_step, 1000, 0.95)\n",
    "  optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(loss, global_step=global_step)\n",
    "\n",
    "  # Predictions for the training, validation, and test data.\n",
    "  train_prediction = tf.nn.softmax(logits)\n",
    "  valid_prediction = tf.nn.softmax(model(tf_valid_dataset))\n",
    "  test_prediction = tf.nn.softmax(model(tf_test_dataset))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized\n",
      "Minibatch loss at step 0: 2.700123\n",
      "Minibatch learning rate at step 0: 0.010000\n",
      "Minibatch accuracy: 11.7%\n",
      "Validation accuracy: 11.3%\n",
      "Minibatch loss at step 50: 2.616694\n",
      "Minibatch learning rate at step 50: 0.010000\n",
      "Minibatch accuracy: 13.3%\n",
      "Validation accuracy: 25.0%\n",
      "Minibatch loss at step 100: 2.624743\n",
      "Minibatch learning rate at step 100: 0.010000\n",
      "Minibatch accuracy: 10.2%\n",
      "Validation accuracy: 48.0%\n",
      "Minibatch loss at step 150: 2.535428\n",
      "Minibatch learning rate at step 150: 0.010000\n",
      "Minibatch accuracy: 18.8%\n",
      "Validation accuracy: 49.5%\n",
      "Minibatch loss at step 200: 2.363136\n",
      "Minibatch learning rate at step 200: 0.010000\n",
      "Minibatch accuracy: 29.7%\n",
      "Validation accuracy: 63.0%\n",
      "Minibatch loss at step 250: 1.907342\n",
      "Minibatch learning rate at step 250: 0.010000\n",
      "Minibatch accuracy: 50.8%\n",
      "Validation accuracy: 68.7%\n",
      "Minibatch loss at step 300: 1.656092\n",
      "Minibatch learning rate at step 300: 0.010000\n",
      "Minibatch accuracy: 58.6%\n",
      "Validation accuracy: 75.4%\n",
      "Minibatch loss at step 350: 1.366366\n",
      "Minibatch learning rate at step 350: 0.010000\n",
      "Minibatch accuracy: 70.3%\n",
      "Validation accuracy: 77.4%\n",
      "Minibatch loss at step 400: 1.304116\n",
      "Minibatch learning rate at step 400: 0.010000\n",
      "Minibatch accuracy: 73.4%\n",
      "Validation accuracy: 79.3%\n",
      "Minibatch loss at step 450: 1.178856\n",
      "Minibatch learning rate at step 450: 0.010000\n",
      "Minibatch accuracy: 72.7%\n",
      "Validation accuracy: 80.2%\n",
      "Minibatch loss at step 500: 1.045274\n",
      "Minibatch learning rate at step 500: 0.010000\n",
      "Minibatch accuracy: 81.2%\n",
      "Validation accuracy: 80.5%\n",
      "Minibatch loss at step 550: 1.340436\n",
      "Minibatch learning rate at step 550: 0.010000\n",
      "Minibatch accuracy: 72.7%\n",
      "Validation accuracy: 80.6%\n",
      "Minibatch loss at step 600: 1.141252\n",
      "Minibatch learning rate at step 600: 0.010000\n",
      "Minibatch accuracy: 75.0%\n",
      "Validation accuracy: 81.3%\n",
      "Minibatch loss at step 650: 1.161892\n",
      "Minibatch learning rate at step 650: 0.010000\n",
      "Minibatch accuracy: 78.1%\n",
      "Validation accuracy: 81.9%\n",
      "Minibatch loss at step 700: 1.150137\n",
      "Minibatch learning rate at step 700: 0.010000\n",
      "Minibatch accuracy: 77.3%\n",
      "Validation accuracy: 82.6%\n",
      "Minibatch loss at step 750: 1.071855\n",
      "Minibatch learning rate at step 750: 0.010000\n",
      "Minibatch accuracy: 80.5%\n",
      "Validation accuracy: 82.5%\n",
      "Minibatch loss at step 800: 0.877377\n",
      "Minibatch learning rate at step 800: 0.010000\n",
      "Minibatch accuracy: 85.9%\n",
      "Validation accuracy: 82.9%\n",
      "Minibatch loss at step 850: 1.037360\n",
      "Minibatch learning rate at step 850: 0.010000\n",
      "Minibatch accuracy: 83.6%\n",
      "Validation accuracy: 83.3%\n",
      "Minibatch loss at step 900: 1.024428\n",
      "Minibatch learning rate at step 900: 0.010000\n",
      "Minibatch accuracy: 81.2%\n",
      "Validation accuracy: 83.9%\n",
      "Minibatch loss at step 950: 1.045841\n",
      "Minibatch learning rate at step 950: 0.010000\n",
      "Minibatch accuracy: 79.7%\n",
      "Validation accuracy: 83.3%\n",
      "Minibatch loss at step 1000: 1.070228\n",
      "Minibatch learning rate at step 1000: 0.010000\n",
      "Minibatch accuracy: 75.8%\n",
      "Validation accuracy: 83.9%\n",
      "Minibatch loss at step 1050: 0.913894\n",
      "Minibatch learning rate at step 1050: 0.010000\n",
      "Minibatch accuracy: 81.2%\n",
      "Validation accuracy: 84.3%\n",
      "Minibatch loss at step 1100: 0.908697\n",
      "Minibatch learning rate at step 1100: 0.010000\n",
      "Minibatch accuracy: 84.4%\n",
      "Validation accuracy: 84.4%\n",
      "Minibatch loss at step 1150: 0.942372\n",
      "Minibatch learning rate at step 1150: 0.010000\n",
      "Minibatch accuracy: 82.8%\n",
      "Validation accuracy: 84.6%\n",
      "Minibatch loss at step 1200: 0.869779\n",
      "Minibatch learning rate at step 1200: 0.010000\n",
      "Minibatch accuracy: 85.2%\n",
      "Validation accuracy: 84.9%\n",
      "Minibatch loss at step 1250: 0.795587\n",
      "Minibatch learning rate at step 1250: 0.010000\n",
      "Minibatch accuracy: 85.9%\n",
      "Validation accuracy: 85.0%\n",
      "Minibatch loss at step 1300: 1.057192\n",
      "Minibatch learning rate at step 1300: 0.010000\n",
      "Minibatch accuracy: 81.2%\n",
      "Validation accuracy: 85.0%\n",
      "Minibatch loss at step 1350: 0.976294\n",
      "Minibatch learning rate at step 1350: 0.010000\n",
      "Minibatch accuracy: 83.6%\n",
      "Validation accuracy: 85.1%\n",
      "Minibatch loss at step 1400: 0.796739\n",
      "Minibatch learning rate at step 1400: 0.010000\n",
      "Minibatch accuracy: 86.7%\n",
      "Validation accuracy: 85.2%\n",
      "Minibatch loss at step 1450: 1.028727\n",
      "Minibatch learning rate at step 1450: 0.010000\n",
      "Minibatch accuracy: 79.7%\n",
      "Validation accuracy: 85.5%\n",
      "Minibatch loss at step 1500: 0.731067\n",
      "Minibatch learning rate at step 1500: 0.010000\n",
      "Minibatch accuracy: 89.1%\n",
      "Validation accuracy: 85.4%\n",
      "Minibatch loss at step 1550: 0.851026\n",
      "Minibatch learning rate at step 1550: 0.010000\n",
      "Minibatch accuracy: 86.7%\n",
      "Validation accuracy: 85.3%\n",
      "Minibatch loss at step 1600: 1.027053\n",
      "Minibatch learning rate at step 1600: 0.010000\n",
      "Minibatch accuracy: 79.7%\n",
      "Validation accuracy: 85.8%\n",
      "Minibatch loss at step 1650: 0.969781\n",
      "Minibatch learning rate at step 1650: 0.010000\n",
      "Minibatch accuracy: 85.2%\n",
      "Validation accuracy: 85.9%\n",
      "Minibatch loss at step 1700: 0.783160\n",
      "Minibatch learning rate at step 1700: 0.010000\n",
      "Minibatch accuracy: 89.8%\n",
      "Validation accuracy: 85.8%\n",
      "Minibatch loss at step 1750: 0.789819\n",
      "Minibatch learning rate at step 1750: 0.010000\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 86.1%\n",
      "Minibatch loss at step 1800: 0.944699\n",
      "Minibatch learning rate at step 1800: 0.010000\n",
      "Minibatch accuracy: 82.8%\n",
      "Validation accuracy: 86.1%\n",
      "Minibatch loss at step 1850: 0.990025\n",
      "Minibatch learning rate at step 1850: 0.010000\n",
      "Minibatch accuracy: 78.9%\n",
      "Validation accuracy: 85.9%\n",
      "Minibatch loss at step 1900: 0.911803\n",
      "Minibatch learning rate at step 1900: 0.010000\n",
      "Minibatch accuracy: 82.8%\n",
      "Validation accuracy: 85.8%\n",
      "Minibatch loss at step 1950: 0.740937\n",
      "Minibatch learning rate at step 1950: 0.010000\n",
      "Minibatch accuracy: 85.9%\n",
      "Validation accuracy: 86.1%\n",
      "Minibatch loss at step 2000: 0.776203\n",
      "Minibatch learning rate at step 2000: 0.010000\n",
      "Minibatch accuracy: 89.8%\n",
      "Validation accuracy: 86.4%\n",
      "Minibatch loss at step 2050: 0.835327\n",
      "Minibatch learning rate at step 2050: 0.010000\n",
      "Minibatch accuracy: 84.4%\n",
      "Validation accuracy: 86.3%\n",
      "Minibatch loss at step 2100: 0.800074\n",
      "Minibatch learning rate at step 2100: 0.010000\n",
      "Minibatch accuracy: 85.9%\n",
      "Validation accuracy: 86.6%\n",
      "Minibatch loss at step 2150: 0.844993\n",
      "Minibatch learning rate at step 2150: 0.010000\n",
      "Minibatch accuracy: 85.2%\n",
      "Validation accuracy: 86.3%\n",
      "Minibatch loss at step 2200: 0.837302\n",
      "Minibatch learning rate at step 2200: 0.010000\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 86.4%\n",
      "Minibatch loss at step 2250: 1.125484\n",
      "Minibatch learning rate at step 2250: 0.010000\n",
      "Minibatch accuracy: 78.1%\n",
      "Validation accuracy: 86.5%\n",
      "Minibatch loss at step 2300: 0.919050\n",
      "Minibatch learning rate at step 2300: 0.010000\n",
      "Minibatch accuracy: 83.6%\n",
      "Validation accuracy: 86.8%\n",
      "Minibatch loss at step 2350: 0.780053\n",
      "Minibatch learning rate at step 2350: 0.010000\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 86.6%\n",
      "Minibatch loss at step 2400: 0.881794\n",
      "Minibatch learning rate at step 2400: 0.010000\n",
      "Minibatch accuracy: 80.5%\n",
      "Validation accuracy: 86.7%\n",
      "Minibatch loss at step 2450: 0.806867\n",
      "Minibatch learning rate at step 2450: 0.010000\n",
      "Minibatch accuracy: 85.9%\n",
      "Validation accuracy: 86.1%\n",
      "Minibatch loss at step 2500: 0.789356\n",
      "Minibatch learning rate at step 2500: 0.010000\n",
      "Minibatch accuracy: 85.2%\n",
      "Validation accuracy: 86.6%\n",
      "Minibatch loss at step 2550: 0.664718\n",
      "Minibatch learning rate at step 2550: 0.010000\n",
      "Minibatch accuracy: 90.6%\n",
      "Validation accuracy: 86.8%\n",
      "Minibatch loss at step 2600: 0.859258\n",
      "Minibatch learning rate at step 2600: 0.010000\n",
      "Minibatch accuracy: 85.9%\n",
      "Validation accuracy: 86.9%\n",
      "Minibatch loss at step 2650: 0.759157\n",
      "Minibatch learning rate at step 2650: 0.010000\n",
      "Minibatch accuracy: 88.3%\n",
      "Validation accuracy: 87.0%\n",
      "Minibatch loss at step 2700: 0.860992\n",
      "Minibatch learning rate at step 2700: 0.010000\n",
      "Minibatch accuracy: 83.6%\n",
      "Validation accuracy: 87.0%\n",
      "Minibatch loss at step 2750: 0.639767\n",
      "Minibatch learning rate at step 2750: 0.010000\n",
      "Minibatch accuracy: 91.4%\n",
      "Validation accuracy: 87.1%\n",
      "Minibatch loss at step 2800: 0.799881\n",
      "Minibatch learning rate at step 2800: 0.010000\n",
      "Minibatch accuracy: 86.7%\n",
      "Validation accuracy: 87.0%\n",
      "Minibatch loss at step 2850: 0.659912\n",
      "Minibatch learning rate at step 2850: 0.010000\n",
      "Minibatch accuracy: 88.3%\n",
      "Validation accuracy: 87.1%\n",
      "Minibatch loss at step 2900: 0.733220\n",
      "Minibatch learning rate at step 2900: 0.010000\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 87.0%\n",
      "Minibatch loss at step 2950: 0.754408\n",
      "Minibatch learning rate at step 2950: 0.010000\n",
      "Minibatch accuracy: 89.8%\n",
      "Validation accuracy: 86.9%\n",
      "Minibatch loss at step 3000: 0.824089\n",
      "Minibatch learning rate at step 3000: 0.010000\n",
      "Minibatch accuracy: 84.4%\n",
      "Validation accuracy: 86.9%\n",
      "Minibatch loss at step 3050: 0.860570\n",
      "Minibatch learning rate at step 3050: 0.010000\n",
      "Minibatch accuracy: 85.9%\n",
      "Validation accuracy: 87.2%\n",
      "Minibatch loss at step 3100: 0.800667\n",
      "Minibatch learning rate at step 3100: 0.010000\n",
      "Minibatch accuracy: 84.4%\n",
      "Validation accuracy: 87.0%\n",
      "Minibatch loss at step 3150: 0.790351\n",
      "Minibatch learning rate at step 3150: 0.010000\n",
      "Minibatch accuracy: 85.9%\n",
      "Validation accuracy: 87.1%\n",
      "Minibatch loss at step 3200: 0.725978\n",
      "Minibatch learning rate at step 3200: 0.010000\n",
      "Minibatch accuracy: 89.1%\n",
      "Validation accuracy: 87.5%\n",
      "Minibatch loss at step 3250: 0.739417\n",
      "Minibatch learning rate at step 3250: 0.010000\n",
      "Minibatch accuracy: 88.3%\n",
      "Validation accuracy: 87.4%\n",
      "Minibatch loss at step 3300: 0.720346\n",
      "Minibatch learning rate at step 3300: 0.010000\n",
      "Minibatch accuracy: 90.6%\n",
      "Validation accuracy: 87.4%\n",
      "Minibatch loss at step 3350: 0.963303\n",
      "Minibatch learning rate at step 3350: 0.010000\n",
      "Minibatch accuracy: 80.5%\n",
      "Validation accuracy: 87.3%\n",
      "Minibatch loss at step 3400: 0.673521\n",
      "Minibatch learning rate at step 3400: 0.010000\n",
      "Minibatch accuracy: 92.2%\n",
      "Validation accuracy: 87.3%\n",
      "Minibatch loss at step 3450: 0.815852\n",
      "Minibatch learning rate at step 3450: 0.010000\n",
      "Minibatch accuracy: 85.9%\n",
      "Validation accuracy: 87.6%\n",
      "Minibatch loss at step 3500: 0.820164\n",
      "Minibatch learning rate at step 3500: 0.010000\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 87.6%\n",
      "Minibatch loss at step 3550: 0.552915\n",
      "Minibatch learning rate at step 3550: 0.010000\n",
      "Minibatch accuracy: 94.5%\n",
      "Validation accuracy: 87.5%\n",
      "Minibatch loss at step 3600: 0.938710\n",
      "Minibatch learning rate at step 3600: 0.010000\n",
      "Minibatch accuracy: 82.8%\n",
      "Validation accuracy: 87.7%\n",
      "Minibatch loss at step 3650: 0.787936\n",
      "Minibatch learning rate at step 3650: 0.010000\n",
      "Minibatch accuracy: 86.7%\n",
      "Validation accuracy: 87.7%\n",
      "Minibatch loss at step 3700: 0.918847\n",
      "Minibatch learning rate at step 3700: 0.010000\n",
      "Minibatch accuracy: 81.2%\n",
      "Validation accuracy: 87.6%\n",
      "Minibatch loss at step 3750: 0.693521\n",
      "Minibatch learning rate at step 3750: 0.010000\n",
      "Minibatch accuracy: 88.3%\n",
      "Validation accuracy: 87.8%\n",
      "Minibatch loss at step 3800: 0.648766\n",
      "Minibatch learning rate at step 3800: 0.010000\n",
      "Minibatch accuracy: 92.2%\n",
      "Validation accuracy: 87.8%\n",
      "Minibatch loss at step 3850: 0.530939\n",
      "Minibatch learning rate at step 3850: 0.010000\n",
      "Minibatch accuracy: 95.3%\n",
      "Validation accuracy: 87.7%\n",
      "Minibatch loss at step 3900: 0.806211\n",
      "Minibatch learning rate at step 3900: 0.010000\n",
      "Minibatch accuracy: 82.0%\n",
      "Validation accuracy: 87.9%\n",
      "Minibatch loss at step 3950: 0.690045\n",
      "Minibatch learning rate at step 3950: 0.010000\n",
      "Minibatch accuracy: 89.8%\n",
      "Validation accuracy: 87.7%\n",
      "Minibatch loss at step 4000: 0.740771\n",
      "Minibatch learning rate at step 4000: 0.010000\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 87.8%\n",
      "Minibatch loss at step 4050: 0.671569\n",
      "Minibatch learning rate at step 4050: 0.010000\n",
      "Minibatch accuracy: 92.2%\n",
      "Validation accuracy: 87.9%\n",
      "Minibatch loss at step 4100: 0.798540\n",
      "Minibatch learning rate at step 4100: 0.010000\n",
      "Minibatch accuracy: 85.2%\n",
      "Validation accuracy: 87.7%\n",
      "Minibatch loss at step 4150: 0.631119\n",
      "Minibatch learning rate at step 4150: 0.010000\n",
      "Minibatch accuracy: 91.4%\n",
      "Validation accuracy: 87.9%\n",
      "Minibatch loss at step 4200: 0.702750\n",
      "Minibatch learning rate at step 4200: 0.010000\n",
      "Minibatch accuracy: 90.6%\n",
      "Validation accuracy: 88.0%\n",
      "Minibatch loss at step 4250: 0.634471\n",
      "Minibatch learning rate at step 4250: 0.010000\n",
      "Minibatch accuracy: 90.6%\n",
      "Validation accuracy: 88.0%\n",
      "Minibatch loss at step 4300: 0.631351\n",
      "Minibatch learning rate at step 4300: 0.010000\n",
      "Minibatch accuracy: 93.0%\n",
      "Validation accuracy: 87.9%\n",
      "Minibatch loss at step 4350: 0.702568\n",
      "Minibatch learning rate at step 4350: 0.010000\n",
      "Minibatch accuracy: 89.8%\n",
      "Validation accuracy: 87.8%\n",
      "Minibatch loss at step 4400: 0.704385\n",
      "Minibatch learning rate at step 4400: 0.010000\n",
      "Minibatch accuracy: 89.1%\n",
      "Validation accuracy: 88.2%\n",
      "Minibatch loss at step 4450: 0.616993\n",
      "Minibatch learning rate at step 4450: 0.010000\n",
      "Minibatch accuracy: 94.5%\n",
      "Validation accuracy: 88.2%\n",
      "Minibatch loss at step 4500: 0.707111\n",
      "Minibatch learning rate at step 4500: 0.010000\n",
      "Minibatch accuracy: 89.1%\n",
      "Validation accuracy: 87.9%\n",
      "Minibatch loss at step 4550: 0.834281\n",
      "Minibatch learning rate at step 4550: 0.010000\n",
      "Minibatch accuracy: 85.2%\n",
      "Validation accuracy: 88.1%\n",
      "Minibatch loss at step 4600: 0.726256\n",
      "Minibatch learning rate at step 4600: 0.010000\n",
      "Minibatch accuracy: 85.9%\n",
      "Validation accuracy: 88.4%\n",
      "Minibatch loss at step 4650: 0.876924\n",
      "Minibatch learning rate at step 4650: 0.010000\n",
      "Minibatch accuracy: 84.4%\n",
      "Validation accuracy: 88.0%\n",
      "Minibatch loss at step 4700: 0.841345\n",
      "Minibatch learning rate at step 4700: 0.010000\n",
      "Minibatch accuracy: 83.6%\n",
      "Validation accuracy: 88.3%\n",
      "Minibatch loss at step 4750: 0.654449\n",
      "Minibatch learning rate at step 4750: 0.010000\n",
      "Minibatch accuracy: 90.6%\n",
      "Validation accuracy: 88.3%\n",
      "Minibatch loss at step 4800: 0.761160\n",
      "Minibatch learning rate at step 4800: 0.010000\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 88.3%\n",
      "Minibatch loss at step 4850: 0.878913\n",
      "Minibatch learning rate at step 4850: 0.010000\n",
      "Minibatch accuracy: 84.4%\n",
      "Validation accuracy: 88.3%\n",
      "Minibatch loss at step 4900: 0.628000\n",
      "Minibatch learning rate at step 4900: 0.010000\n",
      "Minibatch accuracy: 93.0%\n",
      "Validation accuracy: 88.5%\n",
      "Minibatch loss at step 4950: 0.762514\n",
      "Minibatch learning rate at step 4950: 0.010000\n",
      "Minibatch accuracy: 88.3%\n",
      "Validation accuracy: 88.2%\n",
      "Minibatch loss at step 5000: 0.754107\n",
      "Minibatch learning rate at step 5000: 0.010000\n",
      "Minibatch accuracy: 85.2%\n",
      "Validation accuracy: 88.5%\n",
      "Minibatch loss at step 5050: 0.788346\n",
      "Minibatch learning rate at step 5050: 0.010000\n",
      "Minibatch accuracy: 88.3%\n",
      "Validation accuracy: 88.4%\n",
      "Minibatch loss at step 5100: 0.731177\n",
      "Minibatch learning rate at step 5100: 0.010000\n",
      "Minibatch accuracy: 89.8%\n",
      "Validation accuracy: 88.5%\n",
      "Minibatch loss at step 5150: 0.747285\n",
      "Minibatch learning rate at step 5150: 0.010000\n",
      "Minibatch accuracy: 89.1%\n",
      "Validation accuracy: 88.6%\n",
      "Minibatch loss at step 5200: 0.740974\n",
      "Minibatch learning rate at step 5200: 0.010000\n",
      "Minibatch accuracy: 85.9%\n",
      "Validation accuracy: 88.6%\n",
      "Minibatch loss at step 5250: 0.827097\n",
      "Minibatch learning rate at step 5250: 0.010000\n",
      "Minibatch accuracy: 82.8%\n",
      "Validation accuracy: 88.6%\n",
      "Minibatch loss at step 5300: 0.639565\n",
      "Minibatch learning rate at step 5300: 0.010000\n",
      "Minibatch accuracy: 89.1%\n",
      "Validation accuracy: 88.4%\n",
      "Minibatch loss at step 5350: 1.085876\n",
      "Minibatch learning rate at step 5350: 0.010000\n",
      "Minibatch accuracy: 81.2%\n",
      "Validation accuracy: 88.5%\n",
      "Minibatch loss at step 5400: 0.789873\n",
      "Minibatch learning rate at step 5400: 0.010000\n",
      "Minibatch accuracy: 83.6%\n",
      "Validation accuracy: 88.5%\n",
      "Minibatch loss at step 5450: 0.735862\n",
      "Minibatch learning rate at step 5450: 0.010000\n",
      "Minibatch accuracy: 86.7%\n",
      "Validation accuracy: 88.7%\n",
      "Minibatch loss at step 5500: 0.816240\n",
      "Minibatch learning rate at step 5500: 0.010000\n",
      "Minibatch accuracy: 85.2%\n",
      "Validation accuracy: 88.7%\n",
      "Minibatch loss at step 5550: 0.697925\n",
      "Minibatch learning rate at step 5550: 0.010000\n",
      "Minibatch accuracy: 86.7%\n",
      "Validation accuracy: 88.8%\n",
      "Minibatch loss at step 5600: 0.630708\n",
      "Minibatch learning rate at step 5600: 0.010000\n",
      "Minibatch accuracy: 89.8%\n",
      "Validation accuracy: 88.9%\n",
      "Minibatch loss at step 5650: 0.826861\n",
      "Minibatch learning rate at step 5650: 0.010000\n",
      "Minibatch accuracy: 86.7%\n",
      "Validation accuracy: 88.6%\n",
      "Minibatch loss at step 5700: 0.650311\n",
      "Minibatch learning rate at step 5700: 0.010000\n",
      "Minibatch accuracy: 88.3%\n",
      "Validation accuracy: 88.3%\n",
      "Minibatch loss at step 5750: 0.756124\n",
      "Minibatch learning rate at step 5750: 0.010000\n",
      "Minibatch accuracy: 85.9%\n",
      "Validation accuracy: 88.8%\n",
      "Minibatch loss at step 5800: 0.675970\n",
      "Minibatch learning rate at step 5800: 0.010000\n",
      "Minibatch accuracy: 89.8%\n",
      "Validation accuracy: 88.5%\n",
      "Minibatch loss at step 5850: 0.780000\n",
      "Minibatch learning rate at step 5850: 0.010000\n",
      "Minibatch accuracy: 88.3%\n",
      "Validation accuracy: 88.9%\n",
      "Minibatch loss at step 5900: 0.711283\n",
      "Minibatch learning rate at step 5900: 0.010000\n",
      "Minibatch accuracy: 85.9%\n",
      "Validation accuracy: 88.8%\n",
      "Minibatch loss at step 5950: 0.777702\n",
      "Minibatch learning rate at step 5950: 0.010000\n",
      "Minibatch accuracy: 91.4%\n",
      "Validation accuracy: 88.8%\n",
      "Minibatch loss at step 6000: 0.836768\n",
      "Minibatch learning rate at step 6000: 0.010000\n",
      "Minibatch accuracy: 85.9%\n",
      "Validation accuracy: 89.0%\n",
      "Minibatch loss at step 6050: 0.736446\n",
      "Minibatch learning rate at step 6050: 0.010000\n",
      "Minibatch accuracy: 88.3%\n",
      "Validation accuracy: 89.0%\n",
      "Minibatch loss at step 6100: 0.701964\n",
      "Minibatch learning rate at step 6100: 0.010000\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 88.6%\n",
      "Minibatch loss at step 6150: 0.781778\n",
      "Minibatch learning rate at step 6150: 0.010000\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 88.7%\n",
      "Minibatch loss at step 6200: 0.657863\n",
      "Minibatch learning rate at step 6200: 0.010000\n",
      "Minibatch accuracy: 92.2%\n",
      "Validation accuracy: 88.7%\n",
      "Minibatch loss at step 6250: 0.720359\n",
      "Minibatch learning rate at step 6250: 0.010000\n",
      "Minibatch accuracy: 90.6%\n",
      "Validation accuracy: 88.6%\n",
      "Minibatch loss at step 6300: 0.736719\n",
      "Minibatch learning rate at step 6300: 0.010000\n",
      "Minibatch accuracy: 89.1%\n",
      "Validation accuracy: 88.8%\n",
      "Minibatch loss at step 6350: 0.615947\n",
      "Minibatch learning rate at step 6350: 0.010000\n",
      "Minibatch accuracy: 91.4%\n",
      "Validation accuracy: 88.8%\n",
      "Minibatch loss at step 6400: 0.705366\n",
      "Minibatch learning rate at step 6400: 0.010000\n",
      "Minibatch accuracy: 88.3%\n",
      "Validation accuracy: 89.0%\n",
      "Minibatch loss at step 6450: 0.662804\n",
      "Minibatch learning rate at step 6450: 0.010000\n",
      "Minibatch accuracy: 89.1%\n",
      "Validation accuracy: 88.9%\n",
      "Minibatch loss at step 6500: 0.645139\n",
      "Minibatch learning rate at step 6500: 0.010000\n",
      "Minibatch accuracy: 91.4%\n",
      "Validation accuracy: 88.9%\n",
      "Minibatch loss at step 6550: 0.807466\n",
      "Minibatch learning rate at step 6550: 0.010000\n",
      "Minibatch accuracy: 83.6%\n",
      "Validation accuracy: 89.0%\n",
      "Minibatch loss at step 6600: 0.680227\n",
      "Minibatch learning rate at step 6600: 0.010000\n",
      "Minibatch accuracy: 86.7%\n",
      "Validation accuracy: 89.1%\n",
      "Minibatch loss at step 6650: 0.834973\n",
      "Minibatch learning rate at step 6650: 0.010000\n",
      "Minibatch accuracy: 82.0%\n",
      "Validation accuracy: 88.8%\n",
      "Minibatch loss at step 6700: 0.827737\n",
      "Minibatch learning rate at step 6700: 0.010000\n",
      "Minibatch accuracy: 85.2%\n",
      "Validation accuracy: 89.0%\n",
      "Minibatch loss at step 6750: 0.701886\n",
      "Minibatch learning rate at step 6750: 0.010000\n",
      "Minibatch accuracy: 88.3%\n",
      "Validation accuracy: 89.0%\n",
      "Minibatch loss at step 6800: 0.661826\n",
      "Minibatch learning rate at step 6800: 0.010000\n",
      "Minibatch accuracy: 90.6%\n",
      "Validation accuracy: 88.9%\n",
      "Minibatch loss at step 6850: 0.658995\n",
      "Minibatch learning rate at step 6850: 0.010000\n",
      "Minibatch accuracy: 89.1%\n",
      "Validation accuracy: 89.1%\n",
      "Minibatch loss at step 6900: 0.763125\n",
      "Minibatch learning rate at step 6900: 0.010000\n",
      "Minibatch accuracy: 89.1%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss at step 6950: 0.811879\n",
      "Minibatch learning rate at step 6950: 0.010000\n",
      "Minibatch accuracy: 82.8%\n",
      "Validation accuracy: 89.2%\n",
      "Minibatch loss at step 7000: 0.754979\n",
      "Minibatch learning rate at step 7000: 0.010000\n",
      "Minibatch accuracy: 88.3%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss at step 7050: 0.698749\n",
      "Minibatch learning rate at step 7050: 0.010000\n",
      "Minibatch accuracy: 88.3%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss at step 7100: 0.660987\n",
      "Minibatch learning rate at step 7100: 0.010000\n",
      "Minibatch accuracy: 91.4%\n",
      "Validation accuracy: 89.1%\n",
      "Minibatch loss at step 7150: 0.777201\n",
      "Minibatch learning rate at step 7150: 0.010000\n",
      "Minibatch accuracy: 85.9%\n",
      "Validation accuracy: 89.0%\n",
      "Minibatch loss at step 7200: 0.796316\n",
      "Minibatch learning rate at step 7200: 0.010000\n",
      "Minibatch accuracy: 84.4%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss at step 7250: 0.708227\n",
      "Minibatch learning rate at step 7250: 0.010000\n",
      "Minibatch accuracy: 89.1%\n",
      "Validation accuracy: 89.1%\n",
      "Minibatch loss at step 7300: 0.737090\n",
      "Minibatch learning rate at step 7300: 0.010000\n",
      "Minibatch accuracy: 89.8%\n",
      "Validation accuracy: 89.2%\n",
      "Minibatch loss at step 7350: 0.710765\n",
      "Minibatch learning rate at step 7350: 0.010000\n",
      "Minibatch accuracy: 89.1%\n",
      "Validation accuracy: 89.2%\n",
      "Minibatch loss at step 7400: 0.665444\n",
      "Minibatch learning rate at step 7400: 0.010000\n",
      "Minibatch accuracy: 90.6%\n",
      "Validation accuracy: 89.2%\n",
      "Minibatch loss at step 7450: 0.664400\n",
      "Minibatch learning rate at step 7450: 0.010000\n",
      "Minibatch accuracy: 89.8%\n",
      "Validation accuracy: 89.2%\n",
      "Minibatch loss at step 7500: 0.737432\n",
      "Minibatch learning rate at step 7500: 0.010000\n",
      "Minibatch accuracy: 85.9%\n",
      "Validation accuracy: 89.1%\n",
      "Minibatch loss at step 7550: 0.732188\n",
      "Minibatch learning rate at step 7550: 0.010000\n",
      "Minibatch accuracy: 89.1%\n",
      "Validation accuracy: 89.4%\n",
      "Minibatch loss at step 7600: 0.633940\n",
      "Minibatch learning rate at step 7600: 0.010000\n",
      "Minibatch accuracy: 93.0%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss at step 7650: 0.657096\n",
      "Minibatch learning rate at step 7650: 0.010000\n",
      "Minibatch accuracy: 90.6%\n",
      "Validation accuracy: 89.1%\n",
      "Minibatch loss at step 7700: 0.767198\n",
      "Minibatch learning rate at step 7700: 0.010000\n",
      "Minibatch accuracy: 89.8%\n",
      "Validation accuracy: 89.4%\n",
      "Minibatch loss at step 7750: 0.705465\n",
      "Minibatch learning rate at step 7750: 0.010000\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 89.4%\n",
      "Minibatch loss at step 7800: 0.748425\n",
      "Minibatch learning rate at step 7800: 0.010000\n",
      "Minibatch accuracy: 86.7%\n",
      "Validation accuracy: 89.2%\n",
      "Minibatch loss at step 7850: 0.555833\n",
      "Minibatch learning rate at step 7850: 0.010000\n",
      "Minibatch accuracy: 93.0%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss at step 7900: 0.654723\n",
      "Minibatch learning rate at step 7900: 0.010000\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 89.5%\n",
      "Minibatch loss at step 7950: 0.896558\n",
      "Minibatch learning rate at step 7950: 0.010000\n",
      "Minibatch accuracy: 85.9%\n",
      "Validation accuracy: 89.5%\n",
      "Minibatch loss at step 8000: 0.877242\n",
      "Minibatch learning rate at step 8000: 0.010000\n",
      "Minibatch accuracy: 82.0%\n",
      "Validation accuracy: 89.2%\n",
      "Minibatch loss at step 8050: 0.727414\n",
      "Minibatch learning rate at step 8050: 0.010000\n",
      "Minibatch accuracy: 89.1%\n",
      "Validation accuracy: 89.4%\n",
      "Minibatch loss at step 8100: 0.532149\n",
      "Minibatch learning rate at step 8100: 0.010000\n",
      "Minibatch accuracy: 94.5%\n",
      "Validation accuracy: 89.6%\n",
      "Minibatch loss at step 8150: 0.784926\n",
      "Minibatch learning rate at step 8150: 0.010000\n",
      "Minibatch accuracy: 85.2%\n",
      "Validation accuracy: 89.4%\n",
      "Minibatch loss at step 8200: 0.605945\n",
      "Minibatch learning rate at step 8200: 0.010000\n",
      "Minibatch accuracy: 92.2%\n",
      "Validation accuracy: 89.4%\n",
      "Minibatch loss at step 8250: 0.793339\n",
      "Minibatch learning rate at step 8250: 0.010000\n",
      "Minibatch accuracy: 84.4%\n",
      "Validation accuracy: 89.4%\n",
      "Minibatch loss at step 8300: 0.697677\n",
      "Minibatch learning rate at step 8300: 0.010000\n",
      "Minibatch accuracy: 86.7%\n",
      "Validation accuracy: 89.2%\n",
      "Minibatch loss at step 8350: 0.723151\n",
      "Minibatch learning rate at step 8350: 0.010000\n",
      "Minibatch accuracy: 86.7%\n",
      "Validation accuracy: 89.6%\n",
      "Minibatch loss at step 8400: 0.615829\n",
      "Minibatch learning rate at step 8400: 0.010000\n",
      "Minibatch accuracy: 90.6%\n",
      "Validation accuracy: 89.4%\n",
      "Minibatch loss at step 8450: 0.732669\n",
      "Minibatch learning rate at step 8450: 0.010000\n",
      "Minibatch accuracy: 89.1%\n",
      "Validation accuracy: 88.8%\n",
      "Minibatch loss at step 8500: 0.689205\n",
      "Minibatch learning rate at step 8500: 0.010000\n",
      "Minibatch accuracy: 91.4%\n",
      "Validation accuracy: 89.5%\n",
      "Minibatch loss at step 8550: 0.697494\n",
      "Minibatch learning rate at step 8550: 0.010000\n",
      "Minibatch accuracy: 86.7%\n",
      "Validation accuracy: 89.4%\n",
      "Minibatch loss at step 8600: 0.617668\n",
      "Minibatch learning rate at step 8600: 0.010000\n",
      "Minibatch accuracy: 92.2%\n",
      "Validation accuracy: 89.6%\n",
      "Minibatch loss at step 8650: 0.796333\n",
      "Minibatch learning rate at step 8650: 0.010000\n",
      "Minibatch accuracy: 85.2%\n",
      "Validation accuracy: 89.4%\n",
      "Minibatch loss at step 8700: 0.741028\n",
      "Minibatch learning rate at step 8700: 0.010000\n",
      "Minibatch accuracy: 90.6%\n",
      "Validation accuracy: 89.7%\n",
      "Minibatch loss at step 8750: 0.780323\n",
      "Minibatch learning rate at step 8750: 0.010000\n",
      "Minibatch accuracy: 88.3%\n",
      "Validation accuracy: 89.5%\n",
      "Minibatch loss at step 8800: 0.592812\n",
      "Minibatch learning rate at step 8800: 0.010000\n",
      "Minibatch accuracy: 90.6%\n",
      "Validation accuracy: 89.5%\n",
      "Minibatch loss at step 8850: 0.759388\n",
      "Minibatch learning rate at step 8850: 0.010000\n",
      "Minibatch accuracy: 85.9%\n",
      "Validation accuracy: 89.6%\n",
      "Minibatch loss at step 8900: 0.610465\n",
      "Minibatch learning rate at step 8900: 0.010000\n",
      "Minibatch accuracy: 90.6%\n",
      "Validation accuracy: 89.6%\n",
      "Minibatch loss at step 8950: 0.773279\n",
      "Minibatch learning rate at step 8950: 0.010000\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 89.7%\n",
      "Minibatch loss at step 9000: 0.749077\n",
      "Minibatch learning rate at step 9000: 0.010000\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 89.7%\n",
      "Minibatch loss at step 9050: 0.591511\n",
      "Minibatch learning rate at step 9050: 0.010000\n",
      "Minibatch accuracy: 90.6%\n",
      "Validation accuracy: 89.8%\n",
      "Minibatch loss at step 9100: 0.589334\n",
      "Minibatch learning rate at step 9100: 0.010000\n",
      "Minibatch accuracy: 92.2%\n",
      "Validation accuracy: 89.7%\n",
      "Minibatch loss at step 9150: 0.804227\n",
      "Minibatch learning rate at step 9150: 0.010000\n",
      "Minibatch accuracy: 85.9%\n",
      "Validation accuracy: 89.6%\n",
      "Minibatch loss at step 9200: 0.693656\n",
      "Minibatch learning rate at step 9200: 0.010000\n",
      "Minibatch accuracy: 88.3%\n",
      "Validation accuracy: 89.8%\n",
      "Minibatch loss at step 9250: 0.709876\n",
      "Minibatch learning rate at step 9250: 0.010000\n",
      "Minibatch accuracy: 86.7%\n",
      "Validation accuracy: 89.5%\n",
      "Minibatch loss at step 9300: 0.680165\n",
      "Minibatch learning rate at step 9300: 0.010000\n",
      "Minibatch accuracy: 88.3%\n",
      "Validation accuracy: 89.8%\n",
      "Minibatch loss at step 9350: 0.579134\n",
      "Minibatch learning rate at step 9350: 0.010000\n",
      "Minibatch accuracy: 93.0%\n",
      "Validation accuracy: 89.8%\n",
      "Minibatch loss at step 9400: 0.673271\n",
      "Minibatch learning rate at step 9400: 0.010000\n",
      "Minibatch accuracy: 88.3%\n",
      "Validation accuracy: 89.8%\n",
      "Minibatch loss at step 9450: 0.647204\n",
      "Minibatch learning rate at step 9450: 0.010000\n",
      "Minibatch accuracy: 91.4%\n",
      "Validation accuracy: 89.7%\n",
      "Minibatch loss at step 9500: 0.740815\n",
      "Minibatch learning rate at step 9500: 0.010000\n",
      "Minibatch accuracy: 89.1%\n",
      "Validation accuracy: 89.6%\n",
      "Minibatch loss at step 9550: 0.619323\n",
      "Minibatch learning rate at step 9550: 0.010000\n",
      "Minibatch accuracy: 91.4%\n",
      "Validation accuracy: 89.7%\n",
      "Minibatch loss at step 9600: 0.638094\n",
      "Minibatch learning rate at step 9600: 0.010000\n",
      "Minibatch accuracy: 90.6%\n",
      "Validation accuracy: 89.8%\n",
      "Minibatch loss at step 9650: 0.555994\n",
      "Minibatch learning rate at step 9650: 0.010000\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 89.7%\n",
      "Minibatch loss at step 9700: 0.592269\n",
      "Minibatch learning rate at step 9700: 0.010000\n",
      "Minibatch accuracy: 92.2%\n",
      "Validation accuracy: 89.7%\n",
      "Minibatch loss at step 9750: 0.555515\n",
      "Minibatch learning rate at step 9750: 0.010000\n",
      "Minibatch accuracy: 94.5%\n",
      "Validation accuracy: 89.8%\n",
      "Minibatch loss at step 9800: 0.603507\n",
      "Minibatch learning rate at step 9800: 0.010000\n",
      "Minibatch accuracy: 90.6%\n",
      "Validation accuracy: 90.0%\n",
      "Minibatch loss at step 9850: 0.661731\n",
      "Minibatch learning rate at step 9850: 0.010000\n",
      "Minibatch accuracy: 89.8%\n",
      "Validation accuracy: 89.9%\n",
      "Minibatch loss at step 9900: 0.751266\n",
      "Minibatch learning rate at step 9900: 0.010000\n",
      "Minibatch accuracy: 86.7%\n",
      "Validation accuracy: 90.0%\n",
      "Minibatch loss at step 9950: 0.623703\n",
      "Minibatch learning rate at step 9950: 0.010000\n",
      "Minibatch accuracy: 89.1%\n",
      "Validation accuracy: 90.0%\n",
      "Minibatch loss at step 10000: 0.702974\n",
      "Minibatch learning rate at step 10000: 0.010000\n",
      "Minibatch accuracy: 85.9%\n",
      "Validation accuracy: 89.9%\n",
      "Minibatch loss at step 10050: 0.596160\n",
      "Minibatch learning rate at step 10050: 0.010000\n",
      "Minibatch accuracy: 89.8%\n",
      "Validation accuracy: 89.7%\n",
      "Minibatch loss at step 10100: 0.676543\n",
      "Minibatch learning rate at step 10100: 0.010000\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 89.9%\n",
      "Minibatch loss at step 10150: 0.685959\n",
      "Minibatch learning rate at step 10150: 0.010000\n",
      "Minibatch accuracy: 89.8%\n",
      "Validation accuracy: 89.9%\n",
      "Minibatch loss at step 10200: 0.759421\n",
      "Minibatch learning rate at step 10200: 0.010000\n",
      "Minibatch accuracy: 86.7%\n",
      "Validation accuracy: 89.9%\n",
      "Minibatch loss at step 10250: 0.615012\n",
      "Minibatch learning rate at step 10250: 0.010000\n",
      "Minibatch accuracy: 89.8%\n",
      "Validation accuracy: 89.9%\n",
      "Minibatch loss at step 10300: 0.769758\n",
      "Minibatch learning rate at step 10300: 0.010000\n",
      "Minibatch accuracy: 84.4%\n",
      "Validation accuracy: 90.1%\n",
      "Minibatch loss at step 10350: 0.626569\n",
      "Minibatch learning rate at step 10350: 0.010000\n",
      "Minibatch accuracy: 91.4%\n",
      "Validation accuracy: 89.7%\n",
      "Minibatch loss at step 10400: 0.649756\n",
      "Minibatch learning rate at step 10400: 0.010000\n",
      "Minibatch accuracy: 89.1%\n",
      "Validation accuracy: 89.8%\n",
      "Minibatch loss at step 10450: 0.651132\n",
      "Minibatch learning rate at step 10450: 0.010000\n",
      "Minibatch accuracy: 90.6%\n",
      "Validation accuracy: 89.9%\n",
      "Minibatch loss at step 10500: 0.601898\n",
      "Minibatch learning rate at step 10500: 0.010000\n",
      "Minibatch accuracy: 92.2%\n",
      "Validation accuracy: 89.9%\n",
      "Minibatch loss at step 10550: 0.601161\n",
      "Minibatch learning rate at step 10550: 0.010000\n",
      "Minibatch accuracy: 90.6%\n",
      "Validation accuracy: 90.2%\n",
      "Minibatch loss at step 10600: 0.615177\n",
      "Minibatch learning rate at step 10600: 0.010000\n",
      "Minibatch accuracy: 91.4%\n",
      "Validation accuracy: 89.8%\n",
      "Minibatch loss at step 10650: 0.770264\n",
      "Minibatch learning rate at step 10650: 0.010000\n",
      "Minibatch accuracy: 86.7%\n",
      "Validation accuracy: 90.0%\n",
      "Minibatch loss at step 10700: 0.722836\n",
      "Minibatch learning rate at step 10700: 0.010000\n",
      "Minibatch accuracy: 85.2%\n",
      "Validation accuracy: 89.8%\n",
      "Minibatch loss at step 10750: 0.636276\n",
      "Minibatch learning rate at step 10750: 0.010000\n",
      "Minibatch accuracy: 88.3%\n",
      "Validation accuracy: 89.8%\n",
      "Minibatch loss at step 10800: 0.571922\n",
      "Minibatch learning rate at step 10800: 0.010000\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 90.0%\n",
      "Minibatch loss at step 10850: 0.646527\n",
      "Minibatch learning rate at step 10850: 0.010000\n",
      "Minibatch accuracy: 89.8%\n",
      "Validation accuracy: 89.9%\n",
      "Minibatch loss at step 10900: 0.627955\n",
      "Minibatch learning rate at step 10900: 0.010000\n",
      "Minibatch accuracy: 92.2%\n",
      "Validation accuracy: 90.1%\n",
      "Minibatch loss at step 10950: 0.592384\n",
      "Minibatch learning rate at step 10950: 0.010000\n",
      "Minibatch accuracy: 92.2%\n",
      "Validation accuracy: 89.9%\n",
      "Minibatch loss at step 11000: 0.648370\n",
      "Minibatch learning rate at step 11000: 0.010000\n",
      "Minibatch accuracy: 92.2%\n",
      "Validation accuracy: 90.1%\n",
      "Minibatch loss at step 11050: 0.630148\n",
      "Minibatch learning rate at step 11050: 0.010000\n",
      "Minibatch accuracy: 89.1%\n",
      "Validation accuracy: 90.0%\n",
      "Minibatch loss at step 11100: 0.565652\n",
      "Minibatch learning rate at step 11100: 0.010000\n",
      "Minibatch accuracy: 93.0%\n",
      "Validation accuracy: 90.0%\n",
      "Minibatch loss at step 11150: 0.755190\n",
      "Minibatch learning rate at step 11150: 0.010000\n",
      "Minibatch accuracy: 89.8%\n",
      "Validation accuracy: 90.2%\n",
      "Minibatch loss at step 11200: 0.648386\n",
      "Minibatch learning rate at step 11200: 0.010000\n",
      "Minibatch accuracy: 89.1%\n",
      "Validation accuracy: 90.2%\n",
      "Minibatch loss at step 11250: 0.726709\n",
      "Minibatch learning rate at step 11250: 0.010000\n",
      "Minibatch accuracy: 85.2%\n",
      "Validation accuracy: 90.1%\n",
      "Minibatch loss at step 11300: 0.499602\n",
      "Minibatch learning rate at step 11300: 0.010000\n",
      "Minibatch accuracy: 95.3%\n",
      "Validation accuracy: 90.4%\n",
      "Minibatch loss at step 11350: 0.532555\n",
      "Minibatch learning rate at step 11350: 0.010000\n",
      "Minibatch accuracy: 92.2%\n",
      "Validation accuracy: 90.1%\n",
      "Minibatch loss at step 11400: 0.690743\n",
      "Minibatch learning rate at step 11400: 0.010000\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 90.0%\n",
      "Minibatch loss at step 11450: 0.726913\n",
      "Minibatch learning rate at step 11450: 0.010000\n",
      "Minibatch accuracy: 85.9%\n",
      "Validation accuracy: 90.1%\n",
      "Minibatch loss at step 11500: 0.652749\n",
      "Minibatch learning rate at step 11500: 0.010000\n",
      "Minibatch accuracy: 89.1%\n",
      "Validation accuracy: 90.2%\n",
      "Minibatch loss at step 11550: 0.736849\n",
      "Minibatch learning rate at step 11550: 0.010000\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 90.1%\n",
      "Minibatch loss at step 11600: 0.591893\n",
      "Minibatch learning rate at step 11600: 0.010000\n",
      "Minibatch accuracy: 91.4%\n",
      "Validation accuracy: 90.2%\n",
      "Minibatch loss at step 11650: 0.676017\n",
      "Minibatch learning rate at step 11650: 0.010000\n",
      "Minibatch accuracy: 88.3%\n",
      "Validation accuracy: 90.4%\n",
      "Minibatch loss at step 11700: 0.550366\n",
      "Minibatch learning rate at step 11700: 0.010000\n",
      "Minibatch accuracy: 94.5%\n",
      "Validation accuracy: 90.4%\n",
      "Minibatch loss at step 11750: 0.842487\n",
      "Minibatch learning rate at step 11750: 0.010000\n",
      "Minibatch accuracy: 83.6%\n",
      "Validation accuracy: 90.3%\n",
      "Minibatch loss at step 11800: 0.645291\n",
      "Minibatch learning rate at step 11800: 0.010000\n",
      "Minibatch accuracy: 90.6%\n",
      "Validation accuracy: 90.1%\n",
      "Minibatch loss at step 11850: 0.578485\n",
      "Minibatch learning rate at step 11850: 0.010000\n",
      "Minibatch accuracy: 89.8%\n",
      "Validation accuracy: 90.4%\n",
      "Minibatch loss at step 11900: 0.553785\n",
      "Minibatch learning rate at step 11900: 0.010000\n",
      "Minibatch accuracy: 91.4%\n",
      "Validation accuracy: 90.4%\n",
      "Minibatch loss at step 11950: 0.668674\n",
      "Minibatch learning rate at step 11950: 0.010000\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 90.1%\n",
      "Minibatch loss at step 12000: 0.767457\n",
      "Minibatch learning rate at step 12000: 0.010000\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 90.4%\n",
      "Minibatch loss at step 12050: 0.792815\n",
      "Minibatch learning rate at step 12050: 0.010000\n",
      "Minibatch accuracy: 84.4%\n",
      "Validation accuracy: 90.3%\n",
      "Minibatch loss at step 12100: 0.625728\n",
      "Minibatch learning rate at step 12100: 0.010000\n",
      "Minibatch accuracy: 88.3%\n",
      "Validation accuracy: 90.4%\n",
      "Minibatch loss at step 12150: 0.609477\n",
      "Minibatch learning rate at step 12150: 0.010000\n",
      "Minibatch accuracy: 94.5%\n",
      "Validation accuracy: 90.3%\n",
      "Minibatch loss at step 12200: 0.527544\n",
      "Minibatch learning rate at step 12200: 0.010000\n",
      "Minibatch accuracy: 93.0%\n",
      "Validation accuracy: 90.5%\n",
      "Minibatch loss at step 12250: 0.612450\n",
      "Minibatch learning rate at step 12250: 0.010000\n",
      "Minibatch accuracy: 89.8%\n",
      "Validation accuracy: 90.1%\n",
      "Minibatch loss at step 12300: 0.626211\n",
      "Minibatch learning rate at step 12300: 0.010000\n",
      "Minibatch accuracy: 90.6%\n",
      "Validation accuracy: 90.4%\n",
      "Minibatch loss at step 12350: 0.531274\n",
      "Minibatch learning rate at step 12350: 0.010000\n",
      "Minibatch accuracy: 93.0%\n",
      "Validation accuracy: 90.0%\n",
      "Minibatch loss at step 12400: 0.548777\n",
      "Minibatch learning rate at step 12400: 0.010000\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 90.3%\n",
      "Minibatch loss at step 12450: 0.655538\n",
      "Minibatch learning rate at step 12450: 0.010000\n",
      "Minibatch accuracy: 92.2%\n",
      "Validation accuracy: 90.3%\n",
      "Minibatch loss at step 12500: 0.591142\n",
      "Minibatch learning rate at step 12500: 0.010000\n",
      "Minibatch accuracy: 90.6%\n",
      "Validation accuracy: 90.1%\n",
      "Minibatch loss at step 12550: 0.729597\n",
      "Minibatch learning rate at step 12550: 0.010000\n",
      "Minibatch accuracy: 88.3%\n",
      "Validation accuracy: 90.2%\n",
      "Minibatch loss at step 12600: 0.670688\n",
      "Minibatch learning rate at step 12600: 0.010000\n",
      "Minibatch accuracy: 89.1%\n",
      "Validation accuracy: 90.0%\n",
      "Minibatch loss at step 12650: 0.683998\n",
      "Minibatch learning rate at step 12650: 0.010000\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 90.3%\n",
      "Minibatch loss at step 12700: 0.601748\n",
      "Minibatch learning rate at step 12700: 0.010000\n",
      "Minibatch accuracy: 90.6%\n",
      "Validation accuracy: 90.5%\n",
      "Minibatch loss at step 12750: 0.518685\n",
      "Minibatch learning rate at step 12750: 0.010000\n",
      "Minibatch accuracy: 93.0%\n",
      "Validation accuracy: 90.4%\n",
      "Minibatch loss at step 12800: 0.570080\n",
      "Minibatch learning rate at step 12800: 0.010000\n",
      "Minibatch accuracy: 94.5%\n",
      "Validation accuracy: 90.5%\n",
      "Minibatch loss at step 12850: 0.659064\n",
      "Minibatch learning rate at step 12850: 0.010000\n",
      "Minibatch accuracy: 91.4%\n",
      "Validation accuracy: 90.4%\n",
      "Minibatch loss at step 12900: 0.697763\n",
      "Minibatch learning rate at step 12900: 0.010000\n",
      "Minibatch accuracy: 89.8%\n",
      "Validation accuracy: 90.4%\n",
      "Minibatch loss at step 12950: 0.609521\n",
      "Minibatch learning rate at step 12950: 0.010000\n",
      "Minibatch accuracy: 91.4%\n",
      "Validation accuracy: 90.5%\n",
      "Minibatch loss at step 13000: 0.760030\n",
      "Minibatch learning rate at step 13000: 0.010000\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 90.6%\n",
      "Minibatch loss at step 13050: 0.697183\n",
      "Minibatch learning rate at step 13050: 0.010000\n",
      "Minibatch accuracy: 89.8%\n",
      "Validation accuracy: 90.6%\n",
      "Minibatch loss at step 13100: 0.695790\n",
      "Minibatch learning rate at step 13100: 0.010000\n",
      "Minibatch accuracy: 85.2%\n",
      "Validation accuracy: 90.7%\n",
      "Minibatch loss at step 13150: 0.665135\n",
      "Minibatch learning rate at step 13150: 0.010000\n",
      "Minibatch accuracy: 89.1%\n",
      "Validation accuracy: 90.4%\n",
      "Minibatch loss at step 13200: 0.526799\n",
      "Minibatch learning rate at step 13200: 0.010000\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 90.5%\n",
      "Minibatch loss at step 13250: 0.581691\n",
      "Minibatch learning rate at step 13250: 0.010000\n",
      "Minibatch accuracy: 91.4%\n",
      "Validation accuracy: 90.5%\n",
      "Minibatch loss at step 13300: 0.782677\n",
      "Minibatch learning rate at step 13300: 0.010000\n",
      "Minibatch accuracy: 86.7%\n",
      "Validation accuracy: 90.6%\n",
      "Minibatch loss at step 13350: 0.532144\n",
      "Minibatch learning rate at step 13350: 0.010000\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 90.4%\n",
      "Minibatch loss at step 13400: 0.478046\n",
      "Minibatch learning rate at step 13400: 0.010000\n",
      "Minibatch accuracy: 95.3%\n",
      "Validation accuracy: 90.5%\n",
      "Minibatch loss at step 13450: 0.533097\n",
      "Minibatch learning rate at step 13450: 0.010000\n",
      "Minibatch accuracy: 92.2%\n",
      "Validation accuracy: 90.6%\n",
      "Minibatch loss at step 13500: 0.689796\n",
      "Minibatch learning rate at step 13500: 0.010000\n",
      "Minibatch accuracy: 88.3%\n",
      "Validation accuracy: 90.4%\n",
      "Minibatch loss at step 13550: 0.758905\n",
      "Minibatch learning rate at step 13550: 0.010000\n",
      "Minibatch accuracy: 86.7%\n",
      "Validation accuracy: 90.4%\n",
      "Minibatch loss at step 13600: 0.644110\n",
      "Minibatch learning rate at step 13600: 0.010000\n",
      "Minibatch accuracy: 90.6%\n",
      "Validation accuracy: 90.6%\n",
      "Minibatch loss at step 13650: 0.568687\n",
      "Minibatch learning rate at step 13650: 0.010000\n",
      "Minibatch accuracy: 91.4%\n",
      "Validation accuracy: 90.6%\n",
      "Minibatch loss at step 13700: 0.695773\n",
      "Minibatch learning rate at step 13700: 0.010000\n",
      "Minibatch accuracy: 88.3%\n",
      "Validation accuracy: 90.7%\n",
      "Minibatch loss at step 13750: 0.696718\n",
      "Minibatch learning rate at step 13750: 0.010000\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 90.5%\n",
      "Minibatch loss at step 13800: 0.504255\n",
      "Minibatch learning rate at step 13800: 0.010000\n",
      "Minibatch accuracy: 92.2%\n",
      "Validation accuracy: 90.7%\n",
      "Minibatch loss at step 13850: 0.578502\n",
      "Minibatch learning rate at step 13850: 0.010000\n",
      "Minibatch accuracy: 90.6%\n",
      "Validation accuracy: 90.6%\n",
      "Minibatch loss at step 13900: 0.621843\n",
      "Minibatch learning rate at step 13900: 0.010000\n",
      "Minibatch accuracy: 92.2%\n",
      "Validation accuracy: 90.5%\n",
      "Minibatch loss at step 13950: 0.637585\n",
      "Minibatch learning rate at step 13950: 0.010000\n",
      "Minibatch accuracy: 89.1%\n",
      "Validation accuracy: 90.7%\n",
      "Minibatch loss at step 14000: 0.648497\n",
      "Minibatch learning rate at step 14000: 0.010000\n",
      "Minibatch accuracy: 88.3%\n",
      "Validation accuracy: 90.7%\n",
      "Minibatch loss at step 14050: 0.774316\n",
      "Minibatch learning rate at step 14050: 0.010000\n",
      "Minibatch accuracy: 85.9%\n",
      "Validation accuracy: 90.6%\n",
      "Minibatch loss at step 14100: 0.604977\n",
      "Minibatch learning rate at step 14100: 0.010000\n",
      "Minibatch accuracy: 91.4%\n",
      "Validation accuracy: 90.8%\n",
      "Minibatch loss at step 14150: 0.554671\n",
      "Minibatch learning rate at step 14150: 0.010000\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 90.5%\n",
      "Minibatch loss at step 14200: 0.639780\n",
      "Minibatch learning rate at step 14200: 0.010000\n",
      "Minibatch accuracy: 90.6%\n",
      "Validation accuracy: 90.7%\n",
      "Minibatch loss at step 14250: 0.541198\n",
      "Minibatch learning rate at step 14250: 0.010000\n",
      "Minibatch accuracy: 92.2%\n",
      "Validation accuracy: 90.7%\n",
      "Minibatch loss at step 14300: 0.527816\n",
      "Minibatch learning rate at step 14300: 0.010000\n",
      "Minibatch accuracy: 92.2%\n",
      "Validation accuracy: 90.6%\n",
      "Minibatch loss at step 14350: 0.579466\n",
      "Minibatch learning rate at step 14350: 0.010000\n",
      "Minibatch accuracy: 92.2%\n",
      "Validation accuracy: 90.6%\n",
      "Minibatch loss at step 14400: 0.673726\n",
      "Minibatch learning rate at step 14400: 0.010000\n",
      "Minibatch accuracy: 91.4%\n",
      "Validation accuracy: 90.5%\n",
      "Minibatch loss at step 14450: 0.582338\n",
      "Minibatch learning rate at step 14450: 0.010000\n",
      "Minibatch accuracy: 93.0%\n",
      "Validation accuracy: 90.6%\n",
      "Minibatch loss at step 14500: 0.728963\n",
      "Minibatch learning rate at step 14500: 0.010000\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 90.6%\n",
      "Minibatch loss at step 14550: 0.657692\n",
      "Minibatch learning rate at step 14550: 0.010000\n",
      "Minibatch accuracy: 88.3%\n",
      "Validation accuracy: 90.6%\n",
      "Minibatch loss at step 14600: 0.546974\n",
      "Minibatch learning rate at step 14600: 0.010000\n",
      "Minibatch accuracy: 93.0%\n",
      "Validation accuracy: 90.5%\n",
      "Minibatch loss at step 14650: 0.708311\n",
      "Minibatch learning rate at step 14650: 0.010000\n",
      "Minibatch accuracy: 89.1%\n",
      "Validation accuracy: 90.6%\n",
      "Minibatch loss at step 14700: 0.478441\n",
      "Minibatch learning rate at step 14700: 0.010000\n",
      "Minibatch accuracy: 95.3%\n",
      "Validation accuracy: 90.5%\n",
      "Minibatch loss at step 14750: 0.616705\n",
      "Minibatch learning rate at step 14750: 0.010000\n",
      "Minibatch accuracy: 88.3%\n",
      "Validation accuracy: 90.8%\n",
      "Minibatch loss at step 14800: 0.527647\n",
      "Minibatch learning rate at step 14800: 0.010000\n",
      "Minibatch accuracy: 96.1%\n",
      "Validation accuracy: 90.5%\n",
      "Minibatch loss at step 14850: 0.608266\n",
      "Minibatch learning rate at step 14850: 0.010000\n",
      "Minibatch accuracy: 89.8%\n",
      "Validation accuracy: 90.8%\n",
      "Minibatch loss at step 14900: 0.554631\n",
      "Minibatch learning rate at step 14900: 0.010000\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 90.7%\n",
      "Minibatch loss at step 14950: 0.746786\n",
      "Minibatch learning rate at step 14950: 0.010000\n",
      "Minibatch accuracy: 83.6%\n",
      "Validation accuracy: 90.7%\n",
      "Minibatch loss at step 15000: 0.607558\n",
      "Minibatch learning rate at step 15000: 0.010000\n",
      "Minibatch accuracy: 91.4%\n",
      "Validation accuracy: 90.8%\n",
      "Minibatch loss at step 15050: 0.604531\n",
      "Minibatch learning rate at step 15050: 0.010000\n",
      "Minibatch accuracy: 91.4%\n",
      "Validation accuracy: 90.7%\n",
      "Minibatch loss at step 15100: 0.743617\n",
      "Minibatch learning rate at step 15100: 0.010000\n",
      "Minibatch accuracy: 86.7%\n",
      "Validation accuracy: 90.7%\n",
      "Minibatch loss at step 15150: 0.609978\n",
      "Minibatch learning rate at step 15150: 0.010000\n",
      "Minibatch accuracy: 89.8%\n",
      "Validation accuracy: 90.8%\n",
      "Minibatch loss at step 15200: 0.687449\n",
      "Minibatch learning rate at step 15200: 0.010000\n",
      "Minibatch accuracy: 89.8%\n",
      "Validation accuracy: 90.8%\n",
      "Minibatch loss at step 15250: 0.577301\n",
      "Minibatch learning rate at step 15250: 0.010000\n",
      "Minibatch accuracy: 93.0%\n",
      "Validation accuracy: 90.9%\n",
      "Minibatch loss at step 15300: 0.644377\n",
      "Minibatch learning rate at step 15300: 0.010000\n",
      "Minibatch accuracy: 89.1%\n",
      "Validation accuracy: 90.6%\n",
      "Minibatch loss at step 15350: 0.644924\n",
      "Minibatch learning rate at step 15350: 0.010000\n",
      "Minibatch accuracy: 86.7%\n",
      "Validation accuracy: 90.7%\n",
      "Minibatch loss at step 15400: 0.658662\n",
      "Minibatch learning rate at step 15400: 0.010000\n",
      "Minibatch accuracy: 89.8%\n",
      "Validation accuracy: 90.9%\n",
      "Minibatch loss at step 15450: 0.643721\n",
      "Minibatch learning rate at step 15450: 0.010000\n",
      "Minibatch accuracy: 92.2%\n",
      "Validation accuracy: 90.7%\n",
      "Minibatch loss at step 15500: 0.682571\n",
      "Minibatch learning rate at step 15500: 0.010000\n",
      "Minibatch accuracy: 89.1%\n",
      "Validation accuracy: 90.9%\n",
      "Minibatch loss at step 15550: 0.697816\n",
      "Minibatch learning rate at step 15550: 0.010000\n",
      "Minibatch accuracy: 90.6%\n",
      "Validation accuracy: 90.8%\n",
      "Minibatch loss at step 15600: 0.577836\n",
      "Minibatch learning rate at step 15600: 0.010000\n",
      "Minibatch accuracy: 91.4%\n",
      "Validation accuracy: 90.9%\n",
      "Minibatch loss at step 15650: 0.592368\n",
      "Minibatch learning rate at step 15650: 0.010000\n",
      "Minibatch accuracy: 91.4%\n",
      "Validation accuracy: 90.8%\n",
      "Minibatch loss at step 15700: 0.528669\n",
      "Minibatch learning rate at step 15700: 0.010000\n",
      "Minibatch accuracy: 92.2%\n",
      "Validation accuracy: 90.8%\n",
      "Minibatch loss at step 15750: 0.728251\n",
      "Minibatch learning rate at step 15750: 0.010000\n",
      "Minibatch accuracy: 85.2%\n",
      "Validation accuracy: 90.8%\n",
      "Minibatch loss at step 15800: 0.526405\n",
      "Minibatch learning rate at step 15800: 0.010000\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 90.8%\n",
      "Minibatch loss at step 15850: 0.596998\n",
      "Minibatch learning rate at step 15850: 0.010000\n",
      "Minibatch accuracy: 92.2%\n",
      "Validation accuracy: 90.9%\n",
      "Minibatch loss at step 15900: 0.599594\n",
      "Minibatch learning rate at step 15900: 0.010000\n",
      "Minibatch accuracy: 89.8%\n",
      "Validation accuracy: 90.7%\n",
      "Minibatch loss at step 15950: 0.595150\n",
      "Minibatch learning rate at step 15950: 0.010000\n",
      "Minibatch accuracy: 90.6%\n",
      "Validation accuracy: 90.8%\n",
      "Minibatch loss at step 16000: 0.519620\n",
      "Minibatch learning rate at step 16000: 0.010000\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 90.8%\n",
      "Minibatch loss at step 16050: 0.672667\n",
      "Minibatch learning rate at step 16050: 0.010000\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 90.8%\n",
      "Minibatch loss at step 16100: 0.523374\n",
      "Minibatch learning rate at step 16100: 0.010000\n",
      "Minibatch accuracy: 92.2%\n",
      "Validation accuracy: 90.9%\n",
      "Minibatch loss at step 16150: 0.633305\n",
      "Minibatch learning rate at step 16150: 0.010000\n",
      "Minibatch accuracy: 90.6%\n",
      "Validation accuracy: 90.8%\n",
      "Minibatch loss at step 16200: 0.529710\n",
      "Minibatch learning rate at step 16200: 0.010000\n",
      "Minibatch accuracy: 94.5%\n",
      "Validation accuracy: 90.9%\n",
      "Minibatch loss at step 16250: 0.709019\n",
      "Minibatch learning rate at step 16250: 0.010000\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 90.8%\n",
      "Minibatch loss at step 16300: 0.674594\n",
      "Minibatch learning rate at step 16300: 0.010000\n",
      "Minibatch accuracy: 88.3%\n",
      "Validation accuracy: 90.8%\n",
      "Minibatch loss at step 16350: 0.622396\n",
      "Minibatch learning rate at step 16350: 0.010000\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 90.9%\n",
      "Minibatch loss at step 16400: 0.620710\n",
      "Minibatch learning rate at step 16400: 0.010000\n",
      "Minibatch accuracy: 89.1%\n",
      "Validation accuracy: 90.9%\n",
      "Minibatch loss at step 16450: 0.691708\n",
      "Minibatch learning rate at step 16450: 0.010000\n",
      "Minibatch accuracy: 86.7%\n",
      "Validation accuracy: 91.0%\n",
      "Minibatch loss at step 16500: 0.541196\n",
      "Minibatch learning rate at step 16500: 0.010000\n",
      "Minibatch accuracy: 93.0%\n",
      "Validation accuracy: 91.0%\n",
      "Minibatch loss at step 16550: 0.583935\n",
      "Minibatch learning rate at step 16550: 0.010000\n",
      "Minibatch accuracy: 89.8%\n",
      "Validation accuracy: 90.9%\n",
      "Minibatch loss at step 16600: 0.640108\n",
      "Minibatch learning rate at step 16600: 0.010000\n",
      "Minibatch accuracy: 88.3%\n",
      "Validation accuracy: 90.8%\n",
      "Minibatch loss at step 16650: 0.614312\n",
      "Minibatch learning rate at step 16650: 0.010000\n",
      "Minibatch accuracy: 90.6%\n",
      "Validation accuracy: 90.9%\n",
      "Minibatch loss at step 16700: 0.635633\n",
      "Minibatch learning rate at step 16700: 0.010000\n",
      "Minibatch accuracy: 89.8%\n",
      "Validation accuracy: 91.0%\n",
      "Minibatch loss at step 16750: 0.543758\n",
      "Minibatch learning rate at step 16750: 0.010000\n",
      "Minibatch accuracy: 90.6%\n",
      "Validation accuracy: 90.9%\n",
      "Minibatch loss at step 16800: 0.770398\n",
      "Minibatch learning rate at step 16800: 0.010000\n",
      "Minibatch accuracy: 85.9%\n",
      "Validation accuracy: 91.0%\n",
      "Minibatch loss at step 16850: 0.618578\n",
      "Minibatch learning rate at step 16850: 0.010000\n",
      "Minibatch accuracy: 92.2%\n",
      "Validation accuracy: 90.9%\n",
      "Minibatch loss at step 16900: 0.517761\n",
      "Minibatch learning rate at step 16900: 0.010000\n",
      "Minibatch accuracy: 95.3%\n",
      "Validation accuracy: 90.9%\n",
      "Minibatch loss at step 16950: 0.609867\n",
      "Minibatch learning rate at step 16950: 0.010000\n",
      "Minibatch accuracy: 90.6%\n",
      "Validation accuracy: 91.1%\n",
      "Minibatch loss at step 17000: 0.529677\n",
      "Minibatch learning rate at step 17000: 0.010000\n",
      "Minibatch accuracy: 94.5%\n",
      "Validation accuracy: 90.9%\n",
      "Minibatch loss at step 17050: 0.692445\n",
      "Minibatch learning rate at step 17050: 0.010000\n",
      "Minibatch accuracy: 88.3%\n",
      "Validation accuracy: 90.7%\n",
      "Minibatch loss at step 17100: 0.570727\n",
      "Minibatch learning rate at step 17100: 0.010000\n",
      "Minibatch accuracy: 92.2%\n",
      "Validation accuracy: 90.9%\n",
      "Minibatch loss at step 17150: 0.609409\n",
      "Minibatch learning rate at step 17150: 0.010000\n",
      "Minibatch accuracy: 92.2%\n",
      "Validation accuracy: 91.0%\n",
      "Minibatch loss at step 17200: 0.551282\n",
      "Minibatch learning rate at step 17200: 0.010000\n",
      "Minibatch accuracy: 92.2%\n",
      "Validation accuracy: 90.9%\n",
      "Minibatch loss at step 17250: 0.594432\n",
      "Minibatch learning rate at step 17250: 0.010000\n",
      "Minibatch accuracy: 89.8%\n",
      "Validation accuracy: 90.8%\n",
      "Minibatch loss at step 17300: 0.655944\n",
      "Minibatch learning rate at step 17300: 0.010000\n",
      "Minibatch accuracy: 89.1%\n",
      "Validation accuracy: 90.9%\n",
      "Minibatch loss at step 17350: 0.727573\n",
      "Minibatch learning rate at step 17350: 0.010000\n",
      "Minibatch accuracy: 89.1%\n",
      "Validation accuracy: 91.2%\n",
      "Minibatch loss at step 17400: 0.514145\n",
      "Minibatch learning rate at step 17400: 0.010000\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 90.9%\n",
      "Minibatch loss at step 17450: 0.553185\n",
      "Minibatch learning rate at step 17450: 0.010000\n",
      "Minibatch accuracy: 93.0%\n",
      "Validation accuracy: 90.8%\n",
      "Minibatch loss at step 17500: 0.409035\n",
      "Minibatch learning rate at step 17500: 0.010000\n",
      "Minibatch accuracy: 97.7%\n",
      "Validation accuracy: 91.0%\n",
      "Minibatch loss at step 17550: 0.541081\n",
      "Minibatch learning rate at step 17550: 0.010000\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 91.0%\n",
      "Minibatch loss at step 17600: 0.571625\n",
      "Minibatch learning rate at step 17600: 0.010000\n",
      "Minibatch accuracy: 92.2%\n",
      "Validation accuracy: 90.9%\n",
      "Minibatch loss at step 17650: 0.600082\n",
      "Minibatch learning rate at step 17650: 0.010000\n",
      "Minibatch accuracy: 90.6%\n",
      "Validation accuracy: 91.0%\n",
      "Minibatch loss at step 17700: 0.526420\n",
      "Minibatch learning rate at step 17700: 0.010000\n",
      "Minibatch accuracy: 93.0%\n",
      "Validation accuracy: 91.2%\n",
      "Minibatch loss at step 17750: 0.508319\n",
      "Minibatch learning rate at step 17750: 0.010000\n",
      "Minibatch accuracy: 93.0%\n",
      "Validation accuracy: 91.0%\n",
      "Minibatch loss at step 17800: 0.677728\n",
      "Minibatch learning rate at step 17800: 0.010000\n",
      "Minibatch accuracy: 85.9%\n",
      "Validation accuracy: 90.9%\n",
      "Minibatch loss at step 17850: 0.589478\n",
      "Minibatch learning rate at step 17850: 0.010000\n",
      "Minibatch accuracy: 91.4%\n",
      "Validation accuracy: 91.1%\n",
      "Minibatch loss at step 17900: 0.594544\n",
      "Minibatch learning rate at step 17900: 0.010000\n",
      "Minibatch accuracy: 89.8%\n",
      "Validation accuracy: 91.2%\n",
      "Minibatch loss at step 17950: 0.539121\n",
      "Minibatch learning rate at step 17950: 0.010000\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 90.9%\n",
      "Minibatch loss at step 18000: 0.487198\n",
      "Minibatch learning rate at step 18000: 0.010000\n",
      "Minibatch accuracy: 95.3%\n",
      "Validation accuracy: 91.0%\n",
      "Minibatch loss at step 18050: 0.498882\n",
      "Minibatch learning rate at step 18050: 0.010000\n",
      "Minibatch accuracy: 93.0%\n",
      "Validation accuracy: 91.1%\n",
      "Minibatch loss at step 18100: 0.595065\n",
      "Minibatch learning rate at step 18100: 0.010000\n",
      "Minibatch accuracy: 92.2%\n",
      "Validation accuracy: 91.0%\n",
      "Minibatch loss at step 18150: 0.643043\n",
      "Minibatch learning rate at step 18150: 0.010000\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 91.1%\n",
      "Minibatch loss at step 18200: 0.679572\n",
      "Minibatch learning rate at step 18200: 0.010000\n",
      "Minibatch accuracy: 85.9%\n",
      "Validation accuracy: 90.9%\n",
      "Minibatch loss at step 18250: 0.663212\n",
      "Minibatch learning rate at step 18250: 0.010000\n",
      "Minibatch accuracy: 89.1%\n",
      "Validation accuracy: 91.0%\n",
      "Minibatch loss at step 18300: 0.517077\n",
      "Minibatch learning rate at step 18300: 0.010000\n",
      "Minibatch accuracy: 94.5%\n",
      "Validation accuracy: 91.2%\n",
      "Minibatch loss at step 18350: 0.668927\n",
      "Minibatch learning rate at step 18350: 0.010000\n",
      "Minibatch accuracy: 89.1%\n",
      "Validation accuracy: 91.2%\n",
      "Minibatch loss at step 18400: 0.562797\n",
      "Minibatch learning rate at step 18400: 0.010000\n",
      "Minibatch accuracy: 93.0%\n",
      "Validation accuracy: 91.0%\n",
      "Minibatch loss at step 18450: 0.667054\n",
      "Minibatch learning rate at step 18450: 0.010000\n",
      "Minibatch accuracy: 89.8%\n",
      "Validation accuracy: 91.0%\n",
      "Minibatch loss at step 18500: 0.561446\n",
      "Minibatch learning rate at step 18500: 0.010000\n",
      "Minibatch accuracy: 92.2%\n",
      "Validation accuracy: 91.1%\n",
      "Minibatch loss at step 18550: 0.477698\n",
      "Minibatch learning rate at step 18550: 0.010000\n",
      "Minibatch accuracy: 96.1%\n",
      "Validation accuracy: 91.2%\n",
      "Minibatch loss at step 18600: 0.614181\n",
      "Minibatch learning rate at step 18600: 0.010000\n",
      "Minibatch accuracy: 93.0%\n",
      "Validation accuracy: 91.1%\n",
      "Minibatch loss at step 18650: 0.549218\n",
      "Minibatch learning rate at step 18650: 0.010000\n",
      "Minibatch accuracy: 92.2%\n",
      "Validation accuracy: 91.0%\n",
      "Minibatch loss at step 18700: 0.639624\n",
      "Minibatch learning rate at step 18700: 0.010000\n",
      "Minibatch accuracy: 90.6%\n",
      "Validation accuracy: 91.1%\n",
      "Minibatch loss at step 18750: 0.553792\n",
      "Minibatch learning rate at step 18750: 0.010000\n",
      "Minibatch accuracy: 91.4%\n",
      "Validation accuracy: 91.1%\n",
      "Minibatch loss at step 18800: 0.636288\n",
      "Minibatch learning rate at step 18800: 0.010000\n",
      "Minibatch accuracy: 91.4%\n",
      "Validation accuracy: 91.1%\n",
      "Minibatch loss at step 18850: 0.532664\n",
      "Minibatch learning rate at step 18850: 0.010000\n",
      "Minibatch accuracy: 94.5%\n",
      "Validation accuracy: 91.1%\n",
      "Minibatch loss at step 18900: 0.676706\n",
      "Minibatch learning rate at step 18900: 0.010000\n",
      "Minibatch accuracy: 89.1%\n",
      "Validation accuracy: 91.3%\n",
      "Minibatch loss at step 18950: 0.438160\n",
      "Minibatch learning rate at step 18950: 0.010000\n",
      "Minibatch accuracy: 96.1%\n",
      "Validation accuracy: 91.1%\n",
      "Minibatch loss at step 19000: 0.472490\n",
      "Minibatch learning rate at step 19000: 0.010000\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 91.1%\n",
      "Minibatch loss at step 19050: 0.666635\n",
      "Minibatch learning rate at step 19050: 0.010000\n",
      "Minibatch accuracy: 86.7%\n",
      "Validation accuracy: 91.2%\n",
      "Minibatch loss at step 19100: 0.547691\n",
      "Minibatch learning rate at step 19100: 0.010000\n",
      "Minibatch accuracy: 91.4%\n",
      "Validation accuracy: 91.2%\n",
      "Minibatch loss at step 19150: 0.578442\n",
      "Minibatch learning rate at step 19150: 0.010000\n",
      "Minibatch accuracy: 89.8%\n",
      "Validation accuracy: 91.3%\n",
      "Minibatch loss at step 19200: 0.690834\n",
      "Minibatch learning rate at step 19200: 0.010000\n",
      "Minibatch accuracy: 90.6%\n",
      "Validation accuracy: 91.1%\n",
      "Minibatch loss at step 19250: 0.438868\n",
      "Minibatch learning rate at step 19250: 0.010000\n",
      "Minibatch accuracy: 94.5%\n",
      "Validation accuracy: 91.1%\n",
      "Minibatch loss at step 19300: 0.588731\n",
      "Minibatch learning rate at step 19300: 0.010000\n",
      "Minibatch accuracy: 89.8%\n",
      "Validation accuracy: 91.1%\n",
      "Minibatch loss at step 19350: 0.587731\n",
      "Minibatch learning rate at step 19350: 0.010000\n",
      "Minibatch accuracy: 89.8%\n",
      "Validation accuracy: 91.1%\n",
      "Minibatch loss at step 19400: 0.594801\n",
      "Minibatch learning rate at step 19400: 0.010000\n",
      "Minibatch accuracy: 91.4%\n",
      "Validation accuracy: 91.1%\n",
      "Minibatch loss at step 19450: 0.572244\n",
      "Minibatch learning rate at step 19450: 0.010000\n",
      "Minibatch accuracy: 92.2%\n",
      "Validation accuracy: 91.3%\n",
      "Minibatch loss at step 19500: 0.551963\n",
      "Minibatch learning rate at step 19500: 0.010000\n",
      "Minibatch accuracy: 92.2%\n",
      "Validation accuracy: 91.1%\n",
      "Minibatch loss at step 19550: 0.602988\n",
      "Minibatch learning rate at step 19550: 0.010000\n",
      "Minibatch accuracy: 89.1%\n",
      "Validation accuracy: 91.2%\n",
      "Minibatch loss at step 19600: 0.554364\n",
      "Minibatch learning rate at step 19600: 0.010000\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 91.2%\n",
      "Minibatch loss at step 19650: 0.587680\n",
      "Minibatch learning rate at step 19650: 0.010000\n",
      "Minibatch accuracy: 89.8%\n",
      "Validation accuracy: 91.2%\n",
      "Minibatch loss at step 19700: 0.589477\n",
      "Minibatch learning rate at step 19700: 0.010000\n",
      "Minibatch accuracy: 90.6%\n",
      "Validation accuracy: 91.2%\n",
      "Minibatch loss at step 19750: 0.548276\n",
      "Minibatch learning rate at step 19750: 0.010000\n",
      "Minibatch accuracy: 93.0%\n",
      "Validation accuracy: 91.3%\n",
      "Minibatch loss at step 19800: 0.496534\n",
      "Minibatch learning rate at step 19800: 0.010000\n",
      "Minibatch accuracy: 93.0%\n",
      "Validation accuracy: 91.2%\n",
      "Minibatch loss at step 19850: 0.675464\n",
      "Minibatch learning rate at step 19850: 0.010000\n",
      "Minibatch accuracy: 89.1%\n",
      "Validation accuracy: 91.2%\n",
      "Minibatch loss at step 19900: 0.678102\n",
      "Minibatch learning rate at step 19900: 0.010000\n",
      "Minibatch accuracy: 92.2%\n",
      "Validation accuracy: 91.1%\n",
      "Minibatch loss at step 19950: 0.547409\n",
      "Minibatch learning rate at step 19950: 0.010000\n",
      "Minibatch accuracy: 93.0%\n",
      "Validation accuracy: 91.4%\n",
      "Minibatch loss at step 20000: 0.623098\n",
      "Minibatch learning rate at step 20000: 0.010000\n",
      "Minibatch accuracy: 90.6%\n",
      "Validation accuracy: 91.4%\n",
      "Minibatch loss at step 20050: 0.568193\n",
      "Minibatch learning rate at step 20050: 0.010000\n",
      "Minibatch accuracy: 91.4%\n",
      "Validation accuracy: 91.2%\n",
      "Minibatch loss at step 20100: 0.630414\n",
      "Minibatch learning rate at step 20100: 0.010000\n",
      "Minibatch accuracy: 89.8%\n",
      "Validation accuracy: 91.2%\n",
      "Minibatch loss at step 20150: 0.468850\n",
      "Minibatch learning rate at step 20150: 0.010000\n",
      "Minibatch accuracy: 94.5%\n",
      "Validation accuracy: 91.1%\n",
      "Minibatch loss at step 20200: 0.625699\n",
      "Minibatch learning rate at step 20200: 0.010000\n",
      "Minibatch accuracy: 88.3%\n",
      "Validation accuracy: 91.2%\n",
      "Minibatch loss at step 20250: 0.572650\n",
      "Minibatch learning rate at step 20250: 0.010000\n",
      "Minibatch accuracy: 92.2%\n",
      "Validation accuracy: 91.2%\n",
      "Minibatch loss at step 20300: 0.583229\n",
      "Minibatch learning rate at step 20300: 0.010000\n",
      "Minibatch accuracy: 91.4%\n",
      "Validation accuracy: 91.0%\n",
      "Minibatch loss at step 20350: 0.558986\n",
      "Minibatch learning rate at step 20350: 0.010000\n",
      "Minibatch accuracy: 89.1%\n",
      "Validation accuracy: 91.3%\n",
      "Minibatch loss at step 20400: 0.613663\n",
      "Minibatch learning rate at step 20400: 0.010000\n",
      "Minibatch accuracy: 89.8%\n",
      "Validation accuracy: 91.1%\n",
      "Minibatch loss at step 20450: 0.547814\n",
      "Minibatch learning rate at step 20450: 0.010000\n",
      "Minibatch accuracy: 90.6%\n",
      "Validation accuracy: 91.3%\n",
      "Minibatch loss at step 20500: 0.599801\n",
      "Minibatch learning rate at step 20500: 0.010000\n",
      "Minibatch accuracy: 91.4%\n",
      "Validation accuracy: 91.1%\n",
      "Minibatch loss at step 20550: 0.581590\n",
      "Minibatch learning rate at step 20550: 0.010000\n",
      "Minibatch accuracy: 92.2%\n",
      "Validation accuracy: 91.2%\n",
      "Minibatch loss at step 20600: 0.599933\n",
      "Minibatch learning rate at step 20600: 0.010000\n",
      "Minibatch accuracy: 89.8%\n",
      "Validation accuracy: 91.5%\n",
      "Minibatch loss at step 20650: 0.520268\n",
      "Minibatch learning rate at step 20650: 0.010000\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 91.3%\n",
      "Minibatch loss at step 20700: 0.496199\n",
      "Minibatch learning rate at step 20700: 0.010000\n",
      "Minibatch accuracy: 92.2%\n",
      "Validation accuracy: 91.4%\n",
      "Minibatch loss at step 20750: 0.626579\n",
      "Minibatch learning rate at step 20750: 0.010000\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 91.2%\n",
      "Minibatch loss at step 20800: 0.578431\n",
      "Minibatch learning rate at step 20800: 0.010000\n",
      "Minibatch accuracy: 91.4%\n",
      "Validation accuracy: 91.3%\n",
      "Minibatch loss at step 20850: 0.705073\n",
      "Minibatch learning rate at step 20850: 0.010000\n",
      "Minibatch accuracy: 86.7%\n",
      "Validation accuracy: 91.0%\n",
      "Minibatch loss at step 20900: 0.679033\n",
      "Minibatch learning rate at step 20900: 0.010000\n",
      "Minibatch accuracy: 89.1%\n",
      "Validation accuracy: 91.1%\n",
      "Minibatch loss at step 20950: 0.557330\n",
      "Minibatch learning rate at step 20950: 0.010000\n",
      "Minibatch accuracy: 91.4%\n",
      "Validation accuracy: 91.3%\n",
      "Minibatch loss at step 21000: 0.550936\n",
      "Minibatch learning rate at step 21000: 0.010000\n",
      "Minibatch accuracy: 93.0%\n",
      "Validation accuracy: 91.3%\n",
      "Minibatch loss at step 21050: 0.562143\n",
      "Minibatch learning rate at step 21050: 0.010000\n",
      "Minibatch accuracy: 91.4%\n",
      "Validation accuracy: 91.2%\n",
      "Minibatch loss at step 21100: 0.560832\n",
      "Minibatch learning rate at step 21100: 0.010000\n",
      "Minibatch accuracy: 93.0%\n",
      "Validation accuracy: 91.2%\n",
      "Minibatch loss at step 21150: 0.600893\n",
      "Minibatch learning rate at step 21150: 0.010000\n",
      "Minibatch accuracy: 88.3%\n",
      "Validation accuracy: 91.3%\n",
      "Minibatch loss at step 21200: 0.642124\n",
      "Minibatch learning rate at step 21200: 0.010000\n",
      "Minibatch accuracy: 89.8%\n",
      "Validation accuracy: 91.3%\n",
      "Minibatch loss at step 21250: 0.625451\n",
      "Minibatch learning rate at step 21250: 0.010000\n",
      "Minibatch accuracy: 89.8%\n",
      "Validation accuracy: 91.3%\n",
      "Minibatch loss at step 21300: 0.849022\n",
      "Minibatch learning rate at step 21300: 0.010000\n",
      "Minibatch accuracy: 84.4%\n",
      "Validation accuracy: 91.3%\n",
      "Minibatch loss at step 21350: 0.512566\n",
      "Minibatch learning rate at step 21350: 0.010000\n",
      "Minibatch accuracy: 93.0%\n",
      "Validation accuracy: 91.3%\n",
      "Minibatch loss at step 21400: 0.527727\n",
      "Minibatch learning rate at step 21400: 0.010000\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 91.4%\n",
      "Minibatch loss at step 21450: 0.462896\n",
      "Minibatch learning rate at step 21450: 0.010000\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 91.3%\n",
      "Minibatch loss at step 21500: 0.427883\n",
      "Minibatch learning rate at step 21500: 0.010000\n",
      "Minibatch accuracy: 95.3%\n",
      "Validation accuracy: 91.4%\n",
      "Minibatch loss at step 21550: 0.534937\n",
      "Minibatch learning rate at step 21550: 0.010000\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 91.4%\n",
      "Minibatch loss at step 21600: 0.613389\n",
      "Minibatch learning rate at step 21600: 0.010000\n",
      "Minibatch accuracy: 89.8%\n",
      "Validation accuracy: 91.3%\n",
      "Minibatch loss at step 21650: 0.553777\n",
      "Minibatch learning rate at step 21650: 0.010000\n",
      "Minibatch accuracy: 89.8%\n",
      "Validation accuracy: 91.4%\n",
      "Minibatch loss at step 21700: 0.454446\n",
      "Minibatch learning rate at step 21700: 0.010000\n",
      "Minibatch accuracy: 95.3%\n",
      "Validation accuracy: 91.2%\n",
      "Minibatch loss at step 21750: 0.469865\n",
      "Minibatch learning rate at step 21750: 0.010000\n",
      "Minibatch accuracy: 95.3%\n",
      "Validation accuracy: 91.3%\n",
      "Minibatch loss at step 21800: 0.591052\n",
      "Minibatch learning rate at step 21800: 0.010000\n",
      "Minibatch accuracy: 89.1%\n",
      "Validation accuracy: 91.3%\n",
      "Minibatch loss at step 21850: 0.566857\n",
      "Minibatch learning rate at step 21850: 0.010000\n",
      "Minibatch accuracy: 88.3%\n",
      "Validation accuracy: 91.4%\n",
      "Minibatch loss at step 21900: 0.562007\n",
      "Minibatch learning rate at step 21900: 0.010000\n",
      "Minibatch accuracy: 92.2%\n",
      "Validation accuracy: 91.4%\n",
      "Minibatch loss at step 21950: 0.541857\n",
      "Minibatch learning rate at step 21950: 0.010000\n",
      "Minibatch accuracy: 93.0%\n",
      "Validation accuracy: 91.3%\n",
      "Minibatch loss at step 22000: 0.456994\n",
      "Minibatch learning rate at step 22000: 0.010000\n",
      "Minibatch accuracy: 95.3%\n",
      "Validation accuracy: 91.5%\n",
      "Minibatch loss at step 22050: 0.672174\n",
      "Minibatch learning rate at step 22050: 0.010000\n",
      "Minibatch accuracy: 89.8%\n",
      "Validation accuracy: 91.3%\n",
      "Minibatch loss at step 22100: 0.682120\n",
      "Minibatch learning rate at step 22100: 0.010000\n",
      "Minibatch accuracy: 89.1%\n",
      "Validation accuracy: 91.2%\n",
      "Minibatch loss at step 22150: 0.639546\n",
      "Minibatch learning rate at step 22150: 0.010000\n",
      "Minibatch accuracy: 92.2%\n",
      "Validation accuracy: 91.3%\n",
      "Minibatch loss at step 22200: 0.619475\n",
      "Minibatch learning rate at step 22200: 0.010000\n",
      "Minibatch accuracy: 92.2%\n",
      "Validation accuracy: 91.4%\n",
      "Minibatch loss at step 22250: 0.470055\n",
      "Minibatch learning rate at step 22250: 0.010000\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 91.3%\n",
      "Minibatch loss at step 22300: 0.537812\n",
      "Minibatch learning rate at step 22300: 0.010000\n",
      "Minibatch accuracy: 89.8%\n",
      "Validation accuracy: 91.4%\n",
      "Minibatch loss at step 22350: 0.516691\n",
      "Minibatch learning rate at step 22350: 0.010000\n",
      "Minibatch accuracy: 91.4%\n",
      "Validation accuracy: 91.4%\n",
      "Minibatch loss at step 22400: 0.555594\n",
      "Minibatch learning rate at step 22400: 0.010000\n",
      "Minibatch accuracy: 88.3%\n",
      "Validation accuracy: 91.4%\n",
      "Minibatch loss at step 22450: 0.662254\n",
      "Minibatch learning rate at step 22450: 0.010000\n",
      "Minibatch accuracy: 89.1%\n",
      "Validation accuracy: 91.3%\n",
      "Minibatch loss at step 22500: 0.496569\n",
      "Minibatch learning rate at step 22500: 0.010000\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 91.5%\n",
      "Minibatch loss at step 22550: 0.547922\n",
      "Minibatch learning rate at step 22550: 0.010000\n",
      "Minibatch accuracy: 95.3%\n",
      "Validation accuracy: 91.4%\n",
      "Minibatch loss at step 22600: 0.674368\n",
      "Minibatch learning rate at step 22600: 0.010000\n",
      "Minibatch accuracy: 85.9%\n",
      "Validation accuracy: 91.4%\n",
      "Minibatch loss at step 22650: 0.538839\n",
      "Minibatch learning rate at step 22650: 0.010000\n",
      "Minibatch accuracy: 90.6%\n",
      "Validation accuracy: 91.5%\n",
      "Minibatch loss at step 22700: 0.512610\n",
      "Minibatch learning rate at step 22700: 0.010000\n",
      "Minibatch accuracy: 93.0%\n",
      "Validation accuracy: 91.2%\n",
      "Minibatch loss at step 22750: 0.438294\n",
      "Minibatch learning rate at step 22750: 0.010000\n",
      "Minibatch accuracy: 96.1%\n",
      "Validation accuracy: 91.4%\n",
      "Minibatch loss at step 22800: 0.579297\n",
      "Minibatch learning rate at step 22800: 0.010000\n",
      "Minibatch accuracy: 90.6%\n",
      "Validation accuracy: 91.4%\n",
      "Minibatch loss at step 22850: 0.585507\n",
      "Minibatch learning rate at step 22850: 0.010000\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 91.3%\n",
      "Minibatch loss at step 22900: 0.577138\n",
      "Minibatch learning rate at step 22900: 0.010000\n",
      "Minibatch accuracy: 92.2%\n",
      "Validation accuracy: 91.2%\n",
      "Minibatch loss at step 22950: 0.520783\n",
      "Minibatch learning rate at step 22950: 0.010000\n",
      "Minibatch accuracy: 90.6%\n",
      "Validation accuracy: 91.4%\n",
      "Minibatch loss at step 23000: 0.627779\n",
      "Minibatch learning rate at step 23000: 0.010000\n",
      "Minibatch accuracy: 89.1%\n",
      "Validation accuracy: 91.5%\n",
      "Minibatch loss at step 23050: 0.513209\n",
      "Minibatch learning rate at step 23050: 0.010000\n",
      "Minibatch accuracy: 94.5%\n",
      "Validation accuracy: 91.7%\n",
      "Minibatch loss at step 23100: 0.525155\n",
      "Minibatch learning rate at step 23100: 0.010000\n",
      "Minibatch accuracy: 92.2%\n",
      "Validation accuracy: 91.3%\n",
      "Minibatch loss at step 23150: 0.498423\n",
      "Minibatch learning rate at step 23150: 0.010000\n",
      "Minibatch accuracy: 93.0%\n",
      "Validation accuracy: 91.4%\n",
      "Minibatch loss at step 23200: 0.482139\n",
      "Minibatch learning rate at step 23200: 0.010000\n",
      "Minibatch accuracy: 92.2%\n",
      "Validation accuracy: 91.5%\n",
      "Minibatch loss at step 23250: 0.703514\n",
      "Minibatch learning rate at step 23250: 0.010000\n",
      "Minibatch accuracy: 86.7%\n",
      "Validation accuracy: 91.5%\n",
      "Minibatch loss at step 23300: 0.611153\n",
      "Minibatch learning rate at step 23300: 0.010000\n",
      "Minibatch accuracy: 89.8%\n",
      "Validation accuracy: 91.5%\n",
      "Minibatch loss at step 23350: 0.638143\n",
      "Minibatch learning rate at step 23350: 0.010000\n",
      "Minibatch accuracy: 89.8%\n",
      "Validation accuracy: 91.2%\n",
      "Minibatch loss at step 23400: 0.605585\n",
      "Minibatch learning rate at step 23400: 0.010000\n",
      "Minibatch accuracy: 92.2%\n",
      "Validation accuracy: 91.4%\n",
      "Minibatch loss at step 23450: 0.508013\n",
      "Minibatch learning rate at step 23450: 0.010000\n",
      "Minibatch accuracy: 91.4%\n",
      "Validation accuracy: 91.4%\n",
      "Minibatch loss at step 23500: 0.474771\n",
      "Minibatch learning rate at step 23500: 0.010000\n",
      "Minibatch accuracy: 93.0%\n",
      "Validation accuracy: 91.4%\n",
      "Minibatch loss at step 23550: 0.428875\n",
      "Minibatch learning rate at step 23550: 0.010000\n",
      "Minibatch accuracy: 96.1%\n",
      "Validation accuracy: 91.4%\n",
      "Minibatch loss at step 23600: 0.604379\n",
      "Minibatch learning rate at step 23600: 0.010000\n",
      "Minibatch accuracy: 89.8%\n",
      "Validation accuracy: 91.5%\n",
      "Minibatch loss at step 23650: 0.567530\n",
      "Minibatch learning rate at step 23650: 0.010000\n",
      "Minibatch accuracy: 89.8%\n",
      "Validation accuracy: 91.4%\n",
      "Minibatch loss at step 23700: 0.530020\n",
      "Minibatch learning rate at step 23700: 0.010000\n",
      "Minibatch accuracy: 93.0%\n",
      "Validation accuracy: 91.4%\n",
      "Minibatch loss at step 23750: 0.557465\n",
      "Minibatch learning rate at step 23750: 0.010000\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 91.2%\n",
      "Minibatch loss at step 23800: 0.555930\n",
      "Minibatch learning rate at step 23800: 0.010000\n",
      "Minibatch accuracy: 92.2%\n",
      "Validation accuracy: 91.5%\n",
      "Minibatch loss at step 23850: 0.419729\n",
      "Minibatch learning rate at step 23850: 0.010000\n",
      "Minibatch accuracy: 96.9%\n",
      "Validation accuracy: 91.3%\n",
      "Minibatch loss at step 23900: 0.691895\n",
      "Minibatch learning rate at step 23900: 0.010000\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 91.5%\n",
      "Minibatch loss at step 23950: 0.567285\n",
      "Minibatch learning rate at step 23950: 0.010000\n",
      "Minibatch accuracy: 90.6%\n",
      "Validation accuracy: 91.5%\n",
      "Minibatch loss at step 24000: 0.586644\n",
      "Minibatch learning rate at step 24000: 0.010000\n",
      "Minibatch accuracy: 89.1%\n",
      "Validation accuracy: 91.5%\n",
      "Minibatch loss at step 24050: 0.442609\n",
      "Minibatch learning rate at step 24050: 0.010000\n",
      "Minibatch accuracy: 96.1%\n",
      "Validation accuracy: 91.5%\n",
      "Minibatch loss at step 24100: 0.616502\n",
      "Minibatch learning rate at step 24100: 0.010000\n",
      "Minibatch accuracy: 92.2%\n",
      "Validation accuracy: 91.3%\n",
      "Minibatch loss at step 24150: 0.516572\n",
      "Minibatch learning rate at step 24150: 0.010000\n",
      "Minibatch accuracy: 92.2%\n",
      "Validation accuracy: 91.5%\n",
      "Minibatch loss at step 24200: 0.560137\n",
      "Minibatch learning rate at step 24200: 0.010000\n",
      "Minibatch accuracy: 91.4%\n",
      "Validation accuracy: 91.4%\n",
      "Minibatch loss at step 24250: 0.554634\n",
      "Minibatch learning rate at step 24250: 0.010000\n",
      "Minibatch accuracy: 91.4%\n",
      "Validation accuracy: 91.4%\n",
      "Minibatch loss at step 24300: 0.575379\n",
      "Minibatch learning rate at step 24300: 0.010000\n",
      "Minibatch accuracy: 90.6%\n",
      "Validation accuracy: 91.5%\n",
      "Minibatch loss at step 24350: 0.488957\n",
      "Minibatch learning rate at step 24350: 0.010000\n",
      "Minibatch accuracy: 94.5%\n",
      "Validation accuracy: 91.5%\n",
      "Minibatch loss at step 24400: 0.497112\n",
      "Minibatch learning rate at step 24400: 0.010000\n",
      "Minibatch accuracy: 93.0%\n",
      "Validation accuracy: 91.4%\n",
      "Minibatch loss at step 24450: 0.531807\n",
      "Minibatch learning rate at step 24450: 0.010000\n",
      "Minibatch accuracy: 93.0%\n",
      "Validation accuracy: 91.5%\n",
      "Minibatch loss at step 24500: 0.667920\n",
      "Minibatch learning rate at step 24500: 0.010000\n",
      "Minibatch accuracy: 89.8%\n",
      "Validation accuracy: 91.5%\n",
      "Minibatch loss at step 24550: 0.461307\n",
      "Minibatch learning rate at step 24550: 0.010000\n",
      "Minibatch accuracy: 96.1%\n",
      "Validation accuracy: 91.7%\n",
      "Minibatch loss at step 24600: 0.507348\n",
      "Minibatch learning rate at step 24600: 0.010000\n",
      "Minibatch accuracy: 91.4%\n",
      "Validation accuracy: 91.7%\n",
      "Minibatch loss at step 24650: 0.470258\n",
      "Minibatch learning rate at step 24650: 0.010000\n",
      "Minibatch accuracy: 96.1%\n",
      "Validation accuracy: 91.7%\n",
      "Minibatch loss at step 24700: 0.466850\n",
      "Minibatch learning rate at step 24700: 0.010000\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 91.7%\n",
      "Minibatch loss at step 24750: 0.527213\n",
      "Minibatch learning rate at step 24750: 0.010000\n",
      "Minibatch accuracy: 91.4%\n",
      "Validation accuracy: 91.6%\n",
      "Minibatch loss at step 24800: 0.532415\n",
      "Minibatch learning rate at step 24800: 0.010000\n",
      "Minibatch accuracy: 93.0%\n",
      "Validation accuracy: 91.5%\n",
      "Minibatch loss at step 24850: 0.562444\n",
      "Minibatch learning rate at step 24850: 0.010000\n",
      "Minibatch accuracy: 90.6%\n",
      "Validation accuracy: 91.6%\n",
      "Minibatch loss at step 24900: 0.560733\n",
      "Minibatch learning rate at step 24900: 0.010000\n",
      "Minibatch accuracy: 89.8%\n",
      "Validation accuracy: 91.6%\n",
      "Minibatch loss at step 24950: 0.748735\n",
      "Minibatch learning rate at step 24950: 0.010000\n",
      "Minibatch accuracy: 85.2%\n",
      "Validation accuracy: 91.4%\n",
      "Minibatch loss at step 25000: 0.497749\n",
      "Minibatch learning rate at step 25000: 0.010000\n",
      "Minibatch accuracy: 94.5%\n",
      "Validation accuracy: 91.5%\n",
      "Minibatch loss at step 25050: 0.422807\n",
      "Minibatch learning rate at step 25050: 0.010000\n",
      "Minibatch accuracy: 96.1%\n",
      "Validation accuracy: 91.5%\n",
      "Minibatch loss at step 25100: 0.610849\n",
      "Minibatch learning rate at step 25100: 0.010000\n",
      "Minibatch accuracy: 90.6%\n",
      "Validation accuracy: 91.6%\n",
      "Minibatch loss at step 25150: 0.664332\n",
      "Minibatch learning rate at step 25150: 0.010000\n",
      "Minibatch accuracy: 89.1%\n",
      "Validation accuracy: 91.4%\n",
      "Minibatch loss at step 25200: 0.434152\n",
      "Minibatch learning rate at step 25200: 0.010000\n",
      "Minibatch accuracy: 94.5%\n",
      "Validation accuracy: 91.4%\n",
      "Minibatch loss at step 25250: 0.628710\n",
      "Minibatch learning rate at step 25250: 0.010000\n",
      "Minibatch accuracy: 89.8%\n",
      "Validation accuracy: 91.5%\n",
      "Minibatch loss at step 25300: 0.464718\n",
      "Minibatch learning rate at step 25300: 0.010000\n",
      "Minibatch accuracy: 94.5%\n",
      "Validation accuracy: 91.5%\n",
      "Minibatch loss at step 25350: 0.613416\n",
      "Minibatch learning rate at step 25350: 0.010000\n",
      "Minibatch accuracy: 89.1%\n",
      "Validation accuracy: 91.7%\n",
      "Minibatch loss at step 25400: 0.645471\n",
      "Minibatch learning rate at step 25400: 0.010000\n",
      "Minibatch accuracy: 88.3%\n",
      "Validation accuracy: 91.6%\n",
      "Minibatch loss at step 25450: 0.455511\n",
      "Minibatch learning rate at step 25450: 0.010000\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 91.5%\n",
      "Minibatch loss at step 25500: 0.498066\n",
      "Minibatch learning rate at step 25500: 0.010000\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 91.8%\n",
      "Minibatch loss at step 25550: 0.584792\n",
      "Minibatch learning rate at step 25550: 0.010000\n",
      "Minibatch accuracy: 90.6%\n",
      "Validation accuracy: 91.8%\n",
      "Minibatch loss at step 25600: 0.491514\n",
      "Minibatch learning rate at step 25600: 0.010000\n",
      "Minibatch accuracy: 92.2%\n",
      "Validation accuracy: 91.5%\n",
      "Minibatch loss at step 25650: 0.830412\n",
      "Minibatch learning rate at step 25650: 0.010000\n",
      "Minibatch accuracy: 83.6%\n",
      "Validation accuracy: 91.3%\n",
      "Minibatch loss at step 25700: 0.527156\n",
      "Minibatch learning rate at step 25700: 0.010000\n",
      "Minibatch accuracy: 93.0%\n",
      "Validation accuracy: 91.5%\n",
      "Minibatch loss at step 25750: 0.578689\n",
      "Minibatch learning rate at step 25750: 0.010000\n",
      "Minibatch accuracy: 89.8%\n",
      "Validation accuracy: 91.6%\n",
      "Minibatch loss at step 25800: 0.489621\n",
      "Minibatch learning rate at step 25800: 0.010000\n",
      "Minibatch accuracy: 93.0%\n",
      "Validation accuracy: 91.5%\n",
      "Minibatch loss at step 25850: 0.499226\n",
      "Minibatch learning rate at step 25850: 0.010000\n",
      "Minibatch accuracy: 93.0%\n",
      "Validation accuracy: 91.5%\n",
      "Minibatch loss at step 25900: 0.480718\n",
      "Minibatch learning rate at step 25900: 0.010000\n",
      "Minibatch accuracy: 93.0%\n",
      "Validation accuracy: 91.7%\n",
      "Minibatch loss at step 25950: 0.535500\n",
      "Minibatch learning rate at step 25950: 0.010000\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 91.7%\n",
      "Minibatch loss at step 26000: 0.437213\n",
      "Minibatch learning rate at step 26000: 0.010000\n",
      "Minibatch accuracy: 95.3%\n",
      "Validation accuracy: 91.5%\n",
      "Minibatch loss at step 26050: 0.654763\n",
      "Minibatch learning rate at step 26050: 0.010000\n",
      "Minibatch accuracy: 86.7%\n",
      "Validation accuracy: 91.6%\n",
      "Minibatch loss at step 26100: 0.497579\n",
      "Minibatch learning rate at step 26100: 0.010000\n",
      "Minibatch accuracy: 96.1%\n",
      "Validation accuracy: 91.5%\n",
      "Minibatch loss at step 26150: 0.557511\n",
      "Minibatch learning rate at step 26150: 0.010000\n",
      "Minibatch accuracy: 91.4%\n",
      "Validation accuracy: 91.6%\n",
      "Minibatch loss at step 26200: 0.603466\n",
      "Minibatch learning rate at step 26200: 0.010000\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 91.8%\n",
      "Minibatch loss at step 26250: 0.530160\n",
      "Minibatch learning rate at step 26250: 0.010000\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 91.6%\n",
      "Minibatch loss at step 26300: 0.623629\n",
      "Minibatch learning rate at step 26300: 0.010000\n",
      "Minibatch accuracy: 91.4%\n",
      "Validation accuracy: 91.7%\n",
      "Minibatch loss at step 26350: 0.563857\n",
      "Minibatch learning rate at step 26350: 0.010000\n",
      "Minibatch accuracy: 92.2%\n",
      "Validation accuracy: 91.7%\n",
      "Minibatch loss at step 26400: 0.457001\n",
      "Minibatch learning rate at step 26400: 0.010000\n",
      "Minibatch accuracy: 97.7%\n",
      "Validation accuracy: 91.5%\n",
      "Minibatch loss at step 26450: 0.598724\n",
      "Minibatch learning rate at step 26450: 0.010000\n",
      "Minibatch accuracy: 92.2%\n",
      "Validation accuracy: 91.8%\n",
      "Minibatch loss at step 26500: 0.513480\n",
      "Minibatch learning rate at step 26500: 0.010000\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 91.5%\n",
      "Minibatch loss at step 26550: 0.394915\n",
      "Minibatch learning rate at step 26550: 0.010000\n",
      "Minibatch accuracy: 96.1%\n",
      "Validation accuracy: 91.5%\n",
      "Minibatch loss at step 26600: 0.630151\n",
      "Minibatch learning rate at step 26600: 0.010000\n",
      "Minibatch accuracy: 86.7%\n",
      "Validation accuracy: 91.6%\n",
      "Minibatch loss at step 26650: 0.493580\n",
      "Minibatch learning rate at step 26650: 0.010000\n",
      "Minibatch accuracy: 92.2%\n",
      "Validation accuracy: 91.6%\n",
      "Minibatch loss at step 26700: 0.523613\n",
      "Minibatch learning rate at step 26700: 0.010000\n",
      "Minibatch accuracy: 92.2%\n",
      "Validation accuracy: 91.7%\n",
      "Minibatch loss at step 26750: 0.490082\n",
      "Minibatch learning rate at step 26750: 0.010000\n",
      "Minibatch accuracy: 93.0%\n",
      "Validation accuracy: 91.6%\n",
      "Minibatch loss at step 26800: 0.502508\n",
      "Minibatch learning rate at step 26800: 0.010000\n",
      "Minibatch accuracy: 91.4%\n",
      "Validation accuracy: 91.5%\n",
      "Minibatch loss at step 26850: 0.650806\n",
      "Minibatch learning rate at step 26850: 0.010000\n",
      "Minibatch accuracy: 88.3%\n",
      "Validation accuracy: 91.6%\n",
      "Minibatch loss at step 26900: 0.583554\n",
      "Minibatch learning rate at step 26900: 0.010000\n",
      "Minibatch accuracy: 91.4%\n",
      "Validation accuracy: 91.6%\n",
      "Minibatch loss at step 26950: 0.550211\n",
      "Minibatch learning rate at step 26950: 0.010000\n",
      "Minibatch accuracy: 92.2%\n",
      "Validation accuracy: 91.7%\n",
      "Minibatch loss at step 27000: 0.646343\n",
      "Minibatch learning rate at step 27000: 0.010000\n",
      "Minibatch accuracy: 89.8%\n",
      "Validation accuracy: 91.5%\n",
      "Minibatch loss at step 27050: 0.499071\n",
      "Minibatch learning rate at step 27050: 0.010000\n",
      "Minibatch accuracy: 93.0%\n",
      "Validation accuracy: 91.4%\n",
      "Minibatch loss at step 27100: 0.552549\n",
      "Minibatch learning rate at step 27100: 0.010000\n",
      "Minibatch accuracy: 92.2%\n",
      "Validation accuracy: 91.6%\n",
      "Minibatch loss at step 27150: 0.566594\n",
      "Minibatch learning rate at step 27150: 0.010000\n",
      "Minibatch accuracy: 91.4%\n",
      "Validation accuracy: 91.8%\n",
      "Minibatch loss at step 27200: 0.391392\n",
      "Minibatch learning rate at step 27200: 0.010000\n",
      "Minibatch accuracy: 96.9%\n",
      "Validation accuracy: 91.7%\n",
      "Minibatch loss at step 27250: 0.648090\n",
      "Minibatch learning rate at step 27250: 0.010000\n",
      "Minibatch accuracy: 88.3%\n",
      "Validation accuracy: 91.8%\n",
      "Minibatch loss at step 27300: 0.521303\n",
      "Minibatch learning rate at step 27300: 0.010000\n",
      "Minibatch accuracy: 90.6%\n",
      "Validation accuracy: 91.8%\n",
      "Minibatch loss at step 27350: 0.540964\n",
      "Minibatch learning rate at step 27350: 0.010000\n",
      "Minibatch accuracy: 89.8%\n",
      "Validation accuracy: 91.6%\n",
      "Minibatch loss at step 27400: 0.615657\n",
      "Minibatch learning rate at step 27400: 0.010000\n",
      "Minibatch accuracy: 88.3%\n",
      "Validation accuracy: 91.5%\n",
      "Minibatch loss at step 27450: 0.590600\n",
      "Minibatch learning rate at step 27450: 0.010000\n",
      "Minibatch accuracy: 89.8%\n",
      "Validation accuracy: 91.5%\n",
      "Minibatch loss at step 27500: 0.647776\n",
      "Minibatch learning rate at step 27500: 0.010000\n",
      "Minibatch accuracy: 86.7%\n",
      "Validation accuracy: 91.7%\n",
      "Minibatch loss at step 27550: 0.527772\n",
      "Minibatch learning rate at step 27550: 0.010000\n",
      "Minibatch accuracy: 92.2%\n",
      "Validation accuracy: 91.8%\n",
      "Minibatch loss at step 27600: 0.496541\n",
      "Minibatch learning rate at step 27600: 0.010000\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 91.7%\n",
      "Minibatch loss at step 27650: 0.459933\n",
      "Minibatch learning rate at step 27650: 0.010000\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 91.6%\n",
      "Minibatch loss at step 27700: 0.615385\n",
      "Minibatch learning rate at step 27700: 0.010000\n",
      "Minibatch accuracy: 88.3%\n",
      "Validation accuracy: 91.5%\n",
      "Minibatch loss at step 27750: 0.485041\n",
      "Minibatch learning rate at step 27750: 0.010000\n",
      "Minibatch accuracy: 95.3%\n",
      "Validation accuracy: 91.7%\n",
      "Minibatch loss at step 27800: 0.573932\n",
      "Minibatch learning rate at step 27800: 0.010000\n",
      "Minibatch accuracy: 91.4%\n",
      "Validation accuracy: 91.5%\n",
      "Minibatch loss at step 27850: 0.630346\n",
      "Minibatch learning rate at step 27850: 0.010000\n",
      "Minibatch accuracy: 88.3%\n",
      "Validation accuracy: 91.6%\n",
      "Minibatch loss at step 27900: 0.474949\n",
      "Minibatch learning rate at step 27900: 0.010000\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 91.8%\n",
      "Minibatch loss at step 27950: 0.430696\n",
      "Minibatch learning rate at step 27950: 0.010000\n",
      "Minibatch accuracy: 95.3%\n",
      "Validation accuracy: 91.8%\n",
      "Minibatch loss at step 28000: 0.515939\n",
      "Minibatch learning rate at step 28000: 0.010000\n",
      "Minibatch accuracy: 92.2%\n",
      "Validation accuracy: 91.8%\n",
      "Minibatch loss at step 28050: 0.543692\n",
      "Minibatch learning rate at step 28050: 0.010000\n",
      "Minibatch accuracy: 91.4%\n",
      "Validation accuracy: 91.8%\n",
      "Minibatch loss at step 28100: 0.494960\n",
      "Minibatch learning rate at step 28100: 0.010000\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 91.7%\n",
      "Minibatch loss at step 28150: 0.390680\n",
      "Minibatch learning rate at step 28150: 0.010000\n",
      "Minibatch accuracy: 96.9%\n",
      "Validation accuracy: 91.8%\n",
      "Minibatch loss at step 28200: 0.462399\n",
      "Minibatch learning rate at step 28200: 0.010000\n",
      "Minibatch accuracy: 95.3%\n",
      "Validation accuracy: 91.7%\n",
      "Minibatch loss at step 28250: 0.641601\n",
      "Minibatch learning rate at step 28250: 0.010000\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 91.8%\n",
      "Minibatch loss at step 28300: 0.585098\n",
      "Minibatch learning rate at step 28300: 0.010000\n",
      "Minibatch accuracy: 88.3%\n",
      "Validation accuracy: 91.6%\n",
      "Minibatch loss at step 28350: 0.635469\n",
      "Minibatch learning rate at step 28350: 0.010000\n",
      "Minibatch accuracy: 89.8%\n",
      "Validation accuracy: 91.5%\n",
      "Minibatch loss at step 28400: 0.434670\n",
      "Minibatch learning rate at step 28400: 0.010000\n",
      "Minibatch accuracy: 94.5%\n",
      "Validation accuracy: 91.7%\n",
      "Minibatch loss at step 28450: 0.571902\n",
      "Minibatch learning rate at step 28450: 0.010000\n",
      "Minibatch accuracy: 90.6%\n",
      "Validation accuracy: 91.8%\n",
      "Minibatch loss at step 28500: 0.435109\n",
      "Minibatch learning rate at step 28500: 0.010000\n",
      "Minibatch accuracy: 94.5%\n",
      "Validation accuracy: 91.6%\n",
      "Minibatch loss at step 28550: 0.507149\n",
      "Minibatch learning rate at step 28550: 0.010000\n",
      "Minibatch accuracy: 92.2%\n",
      "Validation accuracy: 91.7%\n",
      "Minibatch loss at step 28600: 0.511393\n",
      "Minibatch learning rate at step 28600: 0.010000\n",
      "Minibatch accuracy: 93.0%\n",
      "Validation accuracy: 91.8%\n",
      "Minibatch loss at step 28650: 0.541203\n",
      "Minibatch learning rate at step 28650: 0.010000\n",
      "Minibatch accuracy: 92.2%\n",
      "Validation accuracy: 91.8%\n",
      "Minibatch loss at step 28700: 0.553383\n",
      "Minibatch learning rate at step 28700: 0.010000\n",
      "Minibatch accuracy: 92.2%\n",
      "Validation accuracy: 91.4%\n",
      "Minibatch loss at step 28750: 0.460302\n",
      "Minibatch learning rate at step 28750: 0.010000\n",
      "Minibatch accuracy: 93.0%\n",
      "Validation accuracy: 91.5%\n",
      "Minibatch loss at step 28800: 0.507554\n",
      "Minibatch learning rate at step 28800: 0.010000\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 91.6%\n",
      "Minibatch loss at step 28850: 0.501876\n",
      "Minibatch learning rate at step 28850: 0.010000\n",
      "Minibatch accuracy: 92.2%\n",
      "Validation accuracy: 91.8%\n",
      "Minibatch loss at step 28900: 0.441150\n",
      "Minibatch learning rate at step 28900: 0.010000\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 91.7%\n",
      "Minibatch loss at step 28950: 0.535172\n",
      "Minibatch learning rate at step 28950: 0.010000\n",
      "Minibatch accuracy: 91.4%\n",
      "Validation accuracy: 91.6%\n",
      "Minibatch loss at step 29000: 0.542233\n",
      "Minibatch learning rate at step 29000: 0.010000\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 91.7%\n",
      "Minibatch loss at step 29050: 0.576610\n",
      "Minibatch learning rate at step 29050: 0.010000\n",
      "Minibatch accuracy: 91.4%\n",
      "Validation accuracy: 91.7%\n",
      "Minibatch loss at step 29100: 0.510079\n",
      "Minibatch learning rate at step 29100: 0.010000\n",
      "Minibatch accuracy: 90.6%\n",
      "Validation accuracy: 91.7%\n",
      "Minibatch loss at step 29150: 0.538181\n",
      "Minibatch learning rate at step 29150: 0.010000\n",
      "Minibatch accuracy: 92.2%\n",
      "Validation accuracy: 91.8%\n",
      "Minibatch loss at step 29200: 0.475914\n",
      "Minibatch learning rate at step 29200: 0.010000\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 91.7%\n",
      "Minibatch loss at step 29250: 0.594350\n",
      "Minibatch learning rate at step 29250: 0.010000\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 91.7%\n",
      "Minibatch loss at step 29300: 0.551713\n",
      "Minibatch learning rate at step 29300: 0.010000\n",
      "Minibatch accuracy: 92.2%\n",
      "Validation accuracy: 91.8%\n",
      "Minibatch loss at step 29350: 0.535454\n",
      "Minibatch learning rate at step 29350: 0.010000\n",
      "Minibatch accuracy: 92.2%\n",
      "Validation accuracy: 91.8%\n",
      "Minibatch loss at step 29400: 0.539184\n",
      "Minibatch learning rate at step 29400: 0.010000\n",
      "Minibatch accuracy: 93.0%\n",
      "Validation accuracy: 91.7%\n",
      "Minibatch loss at step 29450: 0.624540\n",
      "Minibatch learning rate at step 29450: 0.010000\n",
      "Minibatch accuracy: 90.6%\n",
      "Validation accuracy: 91.8%\n",
      "Minibatch loss at step 29500: 0.516236\n",
      "Minibatch learning rate at step 29500: 0.010000\n",
      "Minibatch accuracy: 91.4%\n",
      "Validation accuracy: 91.7%\n",
      "Minibatch loss at step 29550: 0.506140\n",
      "Minibatch learning rate at step 29550: 0.010000\n",
      "Minibatch accuracy: 89.8%\n",
      "Validation accuracy: 91.5%\n",
      "Minibatch loss at step 29600: 0.464740\n",
      "Minibatch learning rate at step 29600: 0.010000\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 91.7%\n",
      "Minibatch loss at step 29650: 0.619418\n",
      "Minibatch learning rate at step 29650: 0.010000\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 91.6%\n",
      "Minibatch loss at step 29700: 0.476547\n",
      "Minibatch learning rate at step 29700: 0.010000\n",
      "Minibatch accuracy: 94.5%\n",
      "Validation accuracy: 91.7%\n",
      "Minibatch loss at step 29750: 0.494251\n",
      "Minibatch learning rate at step 29750: 0.010000\n",
      "Minibatch accuracy: 93.0%\n",
      "Validation accuracy: 91.9%\n",
      "Minibatch loss at step 29800: 0.507397\n",
      "Minibatch learning rate at step 29800: 0.010000\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 91.7%\n",
      "Minibatch loss at step 29850: 0.569076\n",
      "Minibatch learning rate at step 29850: 0.010000\n",
      "Minibatch accuracy: 90.6%\n",
      "Validation accuracy: 91.7%\n",
      "Minibatch loss at step 29900: 0.507987\n",
      "Minibatch learning rate at step 29900: 0.010000\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 91.8%\n",
      "Minibatch loss at step 29950: 0.403450\n",
      "Minibatch learning rate at step 29950: 0.010000\n",
      "Minibatch accuracy: 96.1%\n",
      "Validation accuracy: 91.8%\n",
      "Minibatch loss at step 30000: 0.450629\n",
      "Minibatch learning rate at step 30000: 0.010000\n",
      "Minibatch accuracy: 95.3%\n",
      "Validation accuracy: 91.7%\n",
      "Minibatch loss at step 30050: 0.577217\n",
      "Minibatch learning rate at step 30050: 0.010000\n",
      "Minibatch accuracy: 90.6%\n",
      "Validation accuracy: 91.7%\n",
      "Minibatch loss at step 30100: 0.517094\n",
      "Minibatch learning rate at step 30100: 0.010000\n",
      "Minibatch accuracy: 91.4%\n",
      "Validation accuracy: 91.9%\n",
      "Minibatch loss at step 30150: 0.448794\n",
      "Minibatch learning rate at step 30150: 0.010000\n",
      "Minibatch accuracy: 95.3%\n",
      "Validation accuracy: 91.7%\n",
      "Minibatch loss at step 30200: 0.638661\n",
      "Minibatch learning rate at step 30200: 0.010000\n",
      "Minibatch accuracy: 93.0%\n",
      "Validation accuracy: 91.7%\n",
      "Minibatch loss at step 30250: 0.454490\n",
      "Minibatch learning rate at step 30250: 0.010000\n",
      "Minibatch accuracy: 93.0%\n",
      "Validation accuracy: 91.7%\n",
      "Minibatch loss at step 30300: 0.562228\n",
      "Minibatch learning rate at step 30300: 0.010000\n",
      "Minibatch accuracy: 89.8%\n",
      "Validation accuracy: 91.8%\n",
      "Minibatch loss at step 30350: 0.493279\n",
      "Minibatch learning rate at step 30350: 0.010000\n",
      "Minibatch accuracy: 92.2%\n",
      "Validation accuracy: 91.8%\n",
      "Minibatch loss at step 30400: 0.400701\n",
      "Minibatch learning rate at step 30400: 0.010000\n",
      "Minibatch accuracy: 95.3%\n",
      "Validation accuracy: 91.9%\n",
      "Minibatch loss at step 30450: 0.470693\n",
      "Minibatch learning rate at step 30450: 0.010000\n",
      "Minibatch accuracy: 95.3%\n",
      "Validation accuracy: 91.5%\n",
      "Minibatch loss at step 30500: 0.444047\n",
      "Minibatch learning rate at step 30500: 0.010000\n",
      "Minibatch accuracy: 94.5%\n",
      "Validation accuracy: 91.8%\n",
      "Minibatch loss at step 30550: 0.494721\n",
      "Minibatch learning rate at step 30550: 0.010000\n",
      "Minibatch accuracy: 93.0%\n",
      "Validation accuracy: 91.8%\n",
      "Minibatch loss at step 30600: 0.706341\n",
      "Minibatch learning rate at step 30600: 0.010000\n",
      "Minibatch accuracy: 85.9%\n",
      "Validation accuracy: 91.7%\n",
      "Minibatch loss at step 30650: 0.476226\n",
      "Minibatch learning rate at step 30650: 0.010000\n",
      "Minibatch accuracy: 90.6%\n",
      "Validation accuracy: 91.8%\n",
      "Minibatch loss at step 30700: 0.505806\n",
      "Minibatch learning rate at step 30700: 0.010000\n",
      "Minibatch accuracy: 91.4%\n",
      "Validation accuracy: 91.8%\n",
      "Minibatch loss at step 30750: 0.434300\n",
      "Minibatch learning rate at step 30750: 0.010000\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 91.9%\n",
      "Minibatch loss at step 30800: 0.496211\n",
      "Minibatch learning rate at step 30800: 0.010000\n",
      "Minibatch accuracy: 91.4%\n",
      "Validation accuracy: 92.0%\n",
      "Minibatch loss at step 30850: 0.371461\n",
      "Minibatch learning rate at step 30850: 0.010000\n",
      "Minibatch accuracy: 96.9%\n",
      "Validation accuracy: 91.8%\n",
      "Minibatch loss at step 30900: 0.479186\n",
      "Minibatch learning rate at step 30900: 0.010000\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 91.9%\n",
      "Minibatch loss at step 30950: 0.640586\n",
      "Minibatch learning rate at step 30950: 0.010000\n",
      "Minibatch accuracy: 88.3%\n",
      "Validation accuracy: 91.8%\n",
      "Minibatch loss at step 31000: 0.523537\n",
      "Minibatch learning rate at step 31000: 0.010000\n",
      "Minibatch accuracy: 92.2%\n",
      "Validation accuracy: 91.8%\n",
      "Minibatch loss at step 31050: 0.512899\n",
      "Minibatch learning rate at step 31050: 0.010000\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 91.6%\n",
      "Minibatch loss at step 31100: 0.490356\n",
      "Minibatch learning rate at step 31100: 0.010000\n",
      "Minibatch accuracy: 93.0%\n",
      "Validation accuracy: 91.8%\n",
      "Minibatch loss at step 31150: 0.561929\n",
      "Minibatch learning rate at step 31150: 0.010000\n",
      "Minibatch accuracy: 91.4%\n",
      "Validation accuracy: 91.8%\n",
      "Minibatch loss at step 31200: 0.455942\n",
      "Minibatch learning rate at step 31200: 0.010000\n",
      "Minibatch accuracy: 96.1%\n",
      "Validation accuracy: 91.8%\n",
      "Minibatch loss at step 31250: 0.489868\n",
      "Minibatch learning rate at step 31250: 0.010000\n",
      "Minibatch accuracy: 92.2%\n",
      "Validation accuracy: 91.8%\n",
      "Minibatch loss at step 31300: 0.537638\n",
      "Minibatch learning rate at step 31300: 0.010000\n",
      "Minibatch accuracy: 93.0%\n",
      "Validation accuracy: 91.9%\n",
      "Minibatch loss at step 31350: 0.554871\n",
      "Minibatch learning rate at step 31350: 0.010000\n",
      "Minibatch accuracy: 89.8%\n",
      "Validation accuracy: 91.7%\n",
      "Minibatch loss at step 31400: 0.417491\n",
      "Minibatch learning rate at step 31400: 0.010000\n",
      "Minibatch accuracy: 96.1%\n",
      "Validation accuracy: 91.6%\n",
      "Minibatch loss at step 31450: 0.484016\n",
      "Minibatch learning rate at step 31450: 0.010000\n",
      "Minibatch accuracy: 93.0%\n",
      "Validation accuracy: 91.8%\n",
      "Minibatch loss at step 31500: 0.523791\n",
      "Minibatch learning rate at step 31500: 0.010000\n",
      "Minibatch accuracy: 92.2%\n",
      "Validation accuracy: 91.8%\n",
      "Minibatch loss at step 31550: 0.540581\n",
      "Minibatch learning rate at step 31550: 0.010000\n",
      "Minibatch accuracy: 91.4%\n",
      "Validation accuracy: 91.7%\n",
      "Minibatch loss at step 31600: 0.459245\n",
      "Minibatch learning rate at step 31600: 0.010000\n",
      "Minibatch accuracy: 95.3%\n",
      "Validation accuracy: 91.8%\n",
      "Minibatch loss at step 31650: 0.423770\n",
      "Minibatch learning rate at step 31650: 0.010000\n",
      "Minibatch accuracy: 96.1%\n",
      "Validation accuracy: 91.7%\n",
      "Minibatch loss at step 31700: 0.513224\n",
      "Minibatch learning rate at step 31700: 0.010000\n",
      "Minibatch accuracy: 93.0%\n",
      "Validation accuracy: 91.5%\n",
      "Minibatch loss at step 31750: 0.494523\n",
      "Minibatch learning rate at step 31750: 0.010000\n",
      "Minibatch accuracy: 92.2%\n",
      "Validation accuracy: 91.9%\n",
      "Minibatch loss at step 31800: 0.582946\n",
      "Minibatch learning rate at step 31800: 0.010000\n",
      "Minibatch accuracy: 89.1%\n",
      "Validation accuracy: 91.9%\n",
      "Minibatch loss at step 31850: 0.560418\n",
      "Minibatch learning rate at step 31850: 0.010000\n",
      "Minibatch accuracy: 90.6%\n",
      "Validation accuracy: 91.9%\n",
      "Minibatch loss at step 31900: 0.405809\n",
      "Minibatch learning rate at step 31900: 0.010000\n",
      "Minibatch accuracy: 95.3%\n",
      "Validation accuracy: 91.8%\n",
      "Minibatch loss at step 31950: 0.476248\n",
      "Minibatch learning rate at step 31950: 0.010000\n",
      "Minibatch accuracy: 94.5%\n",
      "Validation accuracy: 92.0%\n",
      "Minibatch loss at step 32000: 0.534696\n",
      "Minibatch learning rate at step 32000: 0.010000\n",
      "Minibatch accuracy: 91.4%\n",
      "Validation accuracy: 91.8%\n",
      "Minibatch loss at step 32050: 0.582409\n",
      "Minibatch learning rate at step 32050: 0.010000\n",
      "Minibatch accuracy: 89.8%\n",
      "Validation accuracy: 91.7%\n",
      "Minibatch loss at step 32100: 0.517478\n",
      "Minibatch learning rate at step 32100: 0.010000\n",
      "Minibatch accuracy: 92.2%\n",
      "Validation accuracy: 91.6%\n",
      "Minibatch loss at step 32150: 0.457154\n",
      "Minibatch learning rate at step 32150: 0.010000\n",
      "Minibatch accuracy: 94.5%\n",
      "Validation accuracy: 91.9%\n",
      "Minibatch loss at step 32200: 0.457242\n",
      "Minibatch learning rate at step 32200: 0.010000\n",
      "Minibatch accuracy: 92.2%\n",
      "Validation accuracy: 91.8%\n",
      "Minibatch loss at step 32250: 0.495835\n",
      "Minibatch learning rate at step 32250: 0.010000\n",
      "Minibatch accuracy: 93.0%\n",
      "Validation accuracy: 91.8%\n",
      "Minibatch loss at step 32300: 0.576514\n",
      "Minibatch learning rate at step 32300: 0.010000\n",
      "Minibatch accuracy: 91.4%\n",
      "Validation accuracy: 91.9%\n",
      "Minibatch loss at step 32350: 0.573847\n",
      "Minibatch learning rate at step 32350: 0.010000\n",
      "Minibatch accuracy: 89.1%\n",
      "Validation accuracy: 91.7%\n",
      "Minibatch loss at step 32400: 0.505494\n",
      "Minibatch learning rate at step 32400: 0.010000\n",
      "Minibatch accuracy: 94.5%\n",
      "Validation accuracy: 91.9%\n",
      "Minibatch loss at step 32450: 0.488554\n",
      "Minibatch learning rate at step 32450: 0.010000\n",
      "Minibatch accuracy: 93.0%\n",
      "Validation accuracy: 92.0%\n",
      "Minibatch loss at step 32500: 0.496733\n",
      "Minibatch learning rate at step 32500: 0.010000\n",
      "Minibatch accuracy: 94.5%\n",
      "Validation accuracy: 92.0%\n",
      "Minibatch loss at step 32550: 0.556894\n",
      "Minibatch learning rate at step 32550: 0.010000\n",
      "Minibatch accuracy: 90.6%\n",
      "Validation accuracy: 91.8%\n",
      "Minibatch loss at step 32600: 0.475580\n",
      "Minibatch learning rate at step 32600: 0.010000\n",
      "Minibatch accuracy: 94.5%\n",
      "Validation accuracy: 91.9%\n",
      "Minibatch loss at step 32650: 0.362186\n",
      "Minibatch learning rate at step 32650: 0.010000\n",
      "Minibatch accuracy: 97.7%\n",
      "Validation accuracy: 91.7%\n",
      "Minibatch loss at step 32700: 0.418765\n",
      "Minibatch learning rate at step 32700: 0.010000\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 91.8%\n",
      "Minibatch loss at step 32750: 0.469059\n",
      "Minibatch learning rate at step 32750: 0.010000\n",
      "Minibatch accuracy: 92.2%\n",
      "Validation accuracy: 91.9%\n",
      "Minibatch loss at step 32800: 0.330530\n",
      "Minibatch learning rate at step 32800: 0.010000\n",
      "Minibatch accuracy: 97.7%\n",
      "Validation accuracy: 91.8%\n",
      "Minibatch loss at step 32850: 0.570706\n",
      "Minibatch learning rate at step 32850: 0.010000\n",
      "Minibatch accuracy: 90.6%\n",
      "Validation accuracy: 91.7%\n",
      "Minibatch loss at step 32900: 0.438260\n",
      "Minibatch learning rate at step 32900: 0.010000\n",
      "Minibatch accuracy: 96.9%\n",
      "Validation accuracy: 92.0%\n",
      "Minibatch loss at step 32950: 0.519197\n",
      "Minibatch learning rate at step 32950: 0.010000\n",
      "Minibatch accuracy: 92.2%\n",
      "Validation accuracy: 92.0%\n",
      "Minibatch loss at step 33000: 0.493457\n",
      "Minibatch learning rate at step 33000: 0.010000\n",
      "Minibatch accuracy: 93.0%\n",
      "Validation accuracy: 91.7%\n",
      "Minibatch loss at step 33050: 0.405830\n",
      "Minibatch learning rate at step 33050: 0.010000\n",
      "Minibatch accuracy: 95.3%\n",
      "Validation accuracy: 91.8%\n",
      "Minibatch loss at step 33100: 0.379111\n",
      "Minibatch learning rate at step 33100: 0.010000\n",
      "Minibatch accuracy: 96.1%\n",
      "Validation accuracy: 91.8%\n",
      "Minibatch loss at step 33150: 0.499319\n",
      "Minibatch learning rate at step 33150: 0.010000\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 91.9%\n",
      "Minibatch loss at step 33200: 0.497738\n",
      "Minibatch learning rate at step 33200: 0.010000\n",
      "Minibatch accuracy: 92.2%\n",
      "Validation accuracy: 92.0%\n",
      "Minibatch loss at step 33250: 0.602165\n",
      "Minibatch learning rate at step 33250: 0.010000\n",
      "Minibatch accuracy: 89.8%\n",
      "Validation accuracy: 91.7%\n",
      "Minibatch loss at step 33300: 0.564193\n",
      "Minibatch learning rate at step 33300: 0.010000\n",
      "Minibatch accuracy: 93.0%\n",
      "Validation accuracy: 91.8%\n",
      "Minibatch loss at step 33350: 0.484115\n",
      "Minibatch learning rate at step 33350: 0.010000\n",
      "Minibatch accuracy: 89.8%\n",
      "Validation accuracy: 91.7%\n",
      "Minibatch loss at step 33400: 0.477606\n",
      "Minibatch learning rate at step 33400: 0.010000\n",
      "Minibatch accuracy: 93.0%\n",
      "Validation accuracy: 91.9%\n",
      "Minibatch loss at step 33450: 0.461991\n",
      "Minibatch learning rate at step 33450: 0.010000\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 91.7%\n",
      "Minibatch loss at step 33500: 0.394890\n",
      "Minibatch learning rate at step 33500: 0.010000\n",
      "Minibatch accuracy: 95.3%\n",
      "Validation accuracy: 91.7%\n",
      "Minibatch loss at step 33550: 0.523388\n",
      "Minibatch learning rate at step 33550: 0.010000\n",
      "Minibatch accuracy: 91.4%\n",
      "Validation accuracy: 92.0%\n",
      "Minibatch loss at step 33600: 0.545833\n",
      "Minibatch learning rate at step 33600: 0.010000\n",
      "Minibatch accuracy: 93.0%\n",
      "Validation accuracy: 91.9%\n",
      "Minibatch loss at step 33650: 0.485635\n",
      "Minibatch learning rate at step 33650: 0.010000\n",
      "Minibatch accuracy: 95.3%\n",
      "Validation accuracy: 91.8%\n",
      "Minibatch loss at step 33700: 0.391704\n",
      "Minibatch learning rate at step 33700: 0.010000\n",
      "Minibatch accuracy: 95.3%\n",
      "Validation accuracy: 92.0%\n",
      "Minibatch loss at step 33750: 0.526873\n",
      "Minibatch learning rate at step 33750: 0.010000\n",
      "Minibatch accuracy: 90.6%\n",
      "Validation accuracy: 92.0%\n",
      "Minibatch loss at step 33800: 0.418141\n",
      "Minibatch learning rate at step 33800: 0.010000\n",
      "Minibatch accuracy: 95.3%\n",
      "Validation accuracy: 91.9%\n",
      "Minibatch loss at step 33850: 0.526028\n",
      "Minibatch learning rate at step 33850: 0.010000\n",
      "Minibatch accuracy: 91.4%\n",
      "Validation accuracy: 91.8%\n",
      "Minibatch loss at step 33900: 0.422294\n",
      "Minibatch learning rate at step 33900: 0.010000\n",
      "Minibatch accuracy: 94.5%\n",
      "Validation accuracy: 91.8%\n",
      "Minibatch loss at step 33950: 0.514559\n",
      "Minibatch learning rate at step 33950: 0.010000\n",
      "Minibatch accuracy: 93.0%\n",
      "Validation accuracy: 91.8%\n",
      "Minibatch loss at step 34000: 0.646366\n",
      "Minibatch learning rate at step 34000: 0.010000\n",
      "Minibatch accuracy: 84.4%\n",
      "Validation accuracy: 92.0%\n",
      "Minibatch loss at step 34050: 0.537782\n",
      "Minibatch learning rate at step 34050: 0.010000\n",
      "Minibatch accuracy: 91.4%\n",
      "Validation accuracy: 91.8%\n",
      "Minibatch loss at step 34100: 0.396236\n",
      "Minibatch learning rate at step 34100: 0.010000\n",
      "Minibatch accuracy: 96.1%\n",
      "Validation accuracy: 92.0%\n",
      "Minibatch loss at step 34150: 0.517914\n",
      "Minibatch learning rate at step 34150: 0.010000\n",
      "Minibatch accuracy: 91.4%\n",
      "Validation accuracy: 92.0%\n",
      "Minibatch loss at step 34200: 0.604607\n",
      "Minibatch learning rate at step 34200: 0.010000\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 91.9%\n",
      "Minibatch loss at step 34250: 0.512213\n",
      "Minibatch learning rate at step 34250: 0.010000\n",
      "Minibatch accuracy: 90.6%\n",
      "Validation accuracy: 92.0%\n",
      "Minibatch loss at step 34300: 0.443634\n",
      "Minibatch learning rate at step 34300: 0.010000\n",
      "Minibatch accuracy: 95.3%\n",
      "Validation accuracy: 92.1%\n",
      "Minibatch loss at step 34350: 0.711418\n",
      "Minibatch learning rate at step 34350: 0.010000\n",
      "Minibatch accuracy: 86.7%\n",
      "Validation accuracy: 91.8%\n",
      "Minibatch loss at step 34400: 0.468299\n",
      "Minibatch learning rate at step 34400: 0.010000\n",
      "Minibatch accuracy: 95.3%\n",
      "Validation accuracy: 92.3%\n",
      "Minibatch loss at step 34450: 0.461730\n",
      "Minibatch learning rate at step 34450: 0.010000\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 92.0%\n",
      "Minibatch loss at step 34500: 0.601693\n",
      "Minibatch learning rate at step 34500: 0.010000\n",
      "Minibatch accuracy: 89.8%\n",
      "Validation accuracy: 91.9%\n",
      "Minibatch loss at step 34550: 0.459221\n",
      "Minibatch learning rate at step 34550: 0.010000\n",
      "Minibatch accuracy: 93.0%\n",
      "Validation accuracy: 92.1%\n",
      "Minibatch loss at step 34600: 0.442032\n",
      "Minibatch learning rate at step 34600: 0.010000\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 92.0%\n",
      "Minibatch loss at step 34650: 0.529673\n",
      "Minibatch learning rate at step 34650: 0.010000\n",
      "Minibatch accuracy: 92.2%\n",
      "Validation accuracy: 92.0%\n",
      "Minibatch loss at step 34700: 0.436810\n",
      "Minibatch learning rate at step 34700: 0.010000\n",
      "Minibatch accuracy: 95.3%\n",
      "Validation accuracy: 91.9%\n",
      "Minibatch loss at step 34750: 0.546149\n",
      "Minibatch learning rate at step 34750: 0.010000\n",
      "Minibatch accuracy: 93.0%\n",
      "Validation accuracy: 92.1%\n",
      "Minibatch loss at step 34800: 0.660957\n",
      "Minibatch learning rate at step 34800: 0.010000\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 92.1%\n",
      "Minibatch loss at step 34850: 0.433440\n",
      "Minibatch learning rate at step 34850: 0.010000\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 91.9%\n",
      "Minibatch loss at step 34900: 0.383841\n",
      "Minibatch learning rate at step 34900: 0.010000\n",
      "Minibatch accuracy: 96.9%\n",
      "Validation accuracy: 92.1%\n",
      "Minibatch loss at step 34950: 0.512563\n",
      "Minibatch learning rate at step 34950: 0.010000\n",
      "Minibatch accuracy: 91.4%\n",
      "Validation accuracy: 91.9%\n",
      "Minibatch loss at step 35000: 0.404830\n",
      "Minibatch learning rate at step 35000: 0.010000\n",
      "Minibatch accuracy: 96.1%\n",
      "Validation accuracy: 91.9%\n",
      "Minibatch loss at step 35050: 0.561400\n",
      "Minibatch learning rate at step 35050: 0.010000\n",
      "Minibatch accuracy: 89.1%\n",
      "Validation accuracy: 91.9%\n",
      "Minibatch loss at step 35100: 0.490404\n",
      "Minibatch learning rate at step 35100: 0.010000\n",
      "Minibatch accuracy: 92.2%\n",
      "Validation accuracy: 92.0%\n",
      "Minibatch loss at step 35150: 0.461121\n",
      "Minibatch learning rate at step 35150: 0.010000\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 91.9%\n",
      "Minibatch loss at step 35200: 0.523155\n",
      "Minibatch learning rate at step 35200: 0.010000\n",
      "Minibatch accuracy: 90.6%\n",
      "Validation accuracy: 91.9%\n",
      "Minibatch loss at step 35250: 0.536183\n",
      "Minibatch learning rate at step 35250: 0.010000\n",
      "Minibatch accuracy: 89.8%\n",
      "Validation accuracy: 91.9%\n",
      "Minibatch loss at step 35300: 0.336374\n",
      "Minibatch learning rate at step 35300: 0.010000\n",
      "Minibatch accuracy: 97.7%\n",
      "Validation accuracy: 92.1%\n",
      "Minibatch loss at step 35350: 0.456795\n",
      "Minibatch learning rate at step 35350: 0.010000\n",
      "Minibatch accuracy: 96.1%\n",
      "Validation accuracy: 91.8%\n",
      "Minibatch loss at step 35400: 0.532733\n",
      "Minibatch learning rate at step 35400: 0.010000\n",
      "Minibatch accuracy: 91.4%\n",
      "Validation accuracy: 91.9%\n",
      "Minibatch loss at step 35450: 0.507502\n",
      "Minibatch learning rate at step 35450: 0.010000\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 92.0%\n",
      "Minibatch loss at step 35500: 0.506821\n",
      "Minibatch learning rate at step 35500: 0.010000\n",
      "Minibatch accuracy: 94.5%\n",
      "Validation accuracy: 92.2%\n",
      "Minibatch loss at step 35550: 0.635729\n",
      "Minibatch learning rate at step 35550: 0.010000\n",
      "Minibatch accuracy: 88.3%\n",
      "Validation accuracy: 92.1%\n",
      "Minibatch loss at step 35600: 0.458287\n",
      "Minibatch learning rate at step 35600: 0.010000\n",
      "Minibatch accuracy: 93.0%\n",
      "Validation accuracy: 91.9%\n",
      "Minibatch loss at step 35650: 0.467818\n",
      "Minibatch learning rate at step 35650: 0.010000\n",
      "Minibatch accuracy: 92.2%\n",
      "Validation accuracy: 92.1%\n",
      "Minibatch loss at step 35700: 0.507318\n",
      "Minibatch learning rate at step 35700: 0.010000\n",
      "Minibatch accuracy: 92.2%\n",
      "Validation accuracy: 92.0%\n",
      "Minibatch loss at step 35750: 0.435659\n",
      "Minibatch learning rate at step 35750: 0.010000\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 91.9%\n",
      "Minibatch loss at step 35800: 0.474523\n",
      "Minibatch learning rate at step 35800: 0.010000\n",
      "Minibatch accuracy: 93.0%\n",
      "Validation accuracy: 92.0%\n",
      "Minibatch loss at step 35850: 0.568035\n",
      "Minibatch learning rate at step 35850: 0.010000\n",
      "Minibatch accuracy: 89.8%\n",
      "Validation accuracy: 91.7%\n",
      "Minibatch loss at step 35900: 0.490694\n",
      "Minibatch learning rate at step 35900: 0.010000\n",
      "Minibatch accuracy: 91.4%\n",
      "Validation accuracy: 92.0%\n",
      "Minibatch loss at step 35950: 0.555073\n",
      "Minibatch learning rate at step 35950: 0.010000\n",
      "Minibatch accuracy: 90.6%\n",
      "Validation accuracy: 91.9%\n",
      "Minibatch loss at step 36000: 0.446141\n",
      "Minibatch learning rate at step 36000: 0.010000\n",
      "Minibatch accuracy: 95.3%\n",
      "Validation accuracy: 92.1%\n",
      "Minibatch loss at step 36050: 0.529513\n",
      "Minibatch learning rate at step 36050: 0.010000\n",
      "Minibatch accuracy: 91.4%\n",
      "Validation accuracy: 91.9%\n",
      "Minibatch loss at step 36100: 0.470569\n",
      "Minibatch learning rate at step 36100: 0.010000\n",
      "Minibatch accuracy: 91.4%\n",
      "Validation accuracy: 92.0%\n",
      "Minibatch loss at step 36150: 0.581070\n",
      "Minibatch learning rate at step 36150: 0.010000\n",
      "Minibatch accuracy: 89.1%\n",
      "Validation accuracy: 92.1%\n",
      "Minibatch loss at step 36200: 0.398178\n",
      "Minibatch learning rate at step 36200: 0.010000\n",
      "Minibatch accuracy: 94.5%\n",
      "Validation accuracy: 92.0%\n",
      "Minibatch loss at step 36250: 0.448149\n",
      "Minibatch learning rate at step 36250: 0.010000\n",
      "Minibatch accuracy: 94.5%\n",
      "Validation accuracy: 92.0%\n",
      "Minibatch loss at step 36300: 0.455547\n",
      "Minibatch learning rate at step 36300: 0.010000\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 92.0%\n",
      "Minibatch loss at step 36350: 0.476142\n",
      "Minibatch learning rate at step 36350: 0.010000\n",
      "Minibatch accuracy: 93.0%\n",
      "Validation accuracy: 92.1%\n",
      "Minibatch loss at step 36400: 0.514358\n",
      "Minibatch learning rate at step 36400: 0.010000\n",
      "Minibatch accuracy: 92.2%\n",
      "Validation accuracy: 92.0%\n",
      "Minibatch loss at step 36450: 0.416465\n",
      "Minibatch learning rate at step 36450: 0.010000\n",
      "Minibatch accuracy: 95.3%\n",
      "Validation accuracy: 92.0%\n",
      "Minibatch loss at step 36500: 0.418635\n",
      "Minibatch learning rate at step 36500: 0.010000\n",
      "Minibatch accuracy: 94.5%\n",
      "Validation accuracy: 91.9%\n",
      "Minibatch loss at step 36550: 0.539816\n",
      "Minibatch learning rate at step 36550: 0.010000\n",
      "Minibatch accuracy: 89.1%\n",
      "Validation accuracy: 91.9%\n",
      "Minibatch loss at step 36600: 0.553779\n",
      "Minibatch learning rate at step 36600: 0.010000\n",
      "Minibatch accuracy: 90.6%\n",
      "Validation accuracy: 92.1%\n",
      "Minibatch loss at step 36650: 0.616449\n",
      "Minibatch learning rate at step 36650: 0.010000\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 91.8%\n",
      "Minibatch loss at step 36700: 0.454897\n",
      "Minibatch learning rate at step 36700: 0.010000\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 92.0%\n",
      "Minibatch loss at step 36750: 0.437665\n",
      "Minibatch learning rate at step 36750: 0.010000\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 92.0%\n",
      "Minibatch loss at step 36800: 0.425949\n",
      "Minibatch learning rate at step 36800: 0.010000\n",
      "Minibatch accuracy: 94.5%\n",
      "Validation accuracy: 92.0%\n",
      "Minibatch loss at step 36850: 0.444668\n",
      "Minibatch learning rate at step 36850: 0.010000\n",
      "Minibatch accuracy: 95.3%\n",
      "Validation accuracy: 92.0%\n",
      "Minibatch loss at step 36900: 0.503464\n",
      "Minibatch learning rate at step 36900: 0.010000\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 92.0%\n",
      "Minibatch loss at step 36950: 0.402666\n",
      "Minibatch learning rate at step 36950: 0.010000\n",
      "Minibatch accuracy: 96.1%\n",
      "Validation accuracy: 92.1%\n",
      "Minibatch loss at step 37000: 0.565554\n",
      "Minibatch learning rate at step 37000: 0.010000\n",
      "Minibatch accuracy: 89.8%\n",
      "Validation accuracy: 92.2%\n",
      "Minibatch loss at step 37050: 0.512313\n",
      "Minibatch learning rate at step 37050: 0.010000\n",
      "Minibatch accuracy: 91.4%\n",
      "Validation accuracy: 91.9%\n",
      "Minibatch loss at step 37100: 0.591616\n",
      "Minibatch learning rate at step 37100: 0.010000\n",
      "Minibatch accuracy: 89.8%\n",
      "Validation accuracy: 92.0%\n",
      "Minibatch loss at step 37150: 0.487416\n",
      "Minibatch learning rate at step 37150: 0.010000\n",
      "Minibatch accuracy: 92.2%\n",
      "Validation accuracy: 92.1%\n",
      "Minibatch loss at step 37200: 0.380908\n",
      "Minibatch learning rate at step 37200: 0.010000\n",
      "Minibatch accuracy: 96.9%\n",
      "Validation accuracy: 92.1%\n",
      "Minibatch loss at step 37250: 0.525102\n",
      "Minibatch learning rate at step 37250: 0.010000\n",
      "Minibatch accuracy: 89.8%\n",
      "Validation accuracy: 92.0%\n",
      "Minibatch loss at step 37300: 0.356550\n",
      "Minibatch learning rate at step 37300: 0.010000\n",
      "Minibatch accuracy: 96.1%\n",
      "Validation accuracy: 92.1%\n",
      "Minibatch loss at step 37350: 0.444823\n",
      "Minibatch learning rate at step 37350: 0.010000\n",
      "Minibatch accuracy: 94.5%\n",
      "Validation accuracy: 92.1%\n",
      "Minibatch loss at step 37400: 0.456044\n",
      "Minibatch learning rate at step 37400: 0.010000\n",
      "Minibatch accuracy: 93.0%\n",
      "Validation accuracy: 92.2%\n",
      "Minibatch loss at step 37450: 0.436069\n",
      "Minibatch learning rate at step 37450: 0.010000\n",
      "Minibatch accuracy: 93.0%\n",
      "Validation accuracy: 92.1%\n",
      "Minibatch loss at step 37500: 0.401286\n",
      "Minibatch learning rate at step 37500: 0.010000\n",
      "Minibatch accuracy: 96.9%\n",
      "Validation accuracy: 91.9%\n",
      "Minibatch loss at step 37550: 0.552067\n",
      "Minibatch learning rate at step 37550: 0.010000\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 92.0%\n",
      "Minibatch loss at step 37600: 0.430984\n",
      "Minibatch learning rate at step 37600: 0.010000\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 91.8%\n",
      "Minibatch loss at step 37650: 0.501529\n",
      "Minibatch learning rate at step 37650: 0.010000\n",
      "Minibatch accuracy: 91.4%\n",
      "Validation accuracy: 91.9%\n",
      "Minibatch loss at step 37700: 0.388965\n",
      "Minibatch learning rate at step 37700: 0.010000\n",
      "Minibatch accuracy: 95.3%\n",
      "Validation accuracy: 92.1%\n",
      "Minibatch loss at step 37750: 0.426992\n",
      "Minibatch learning rate at step 37750: 0.010000\n",
      "Minibatch accuracy: 93.0%\n",
      "Validation accuracy: 92.0%\n",
      "Minibatch loss at step 37800: 0.412385\n",
      "Minibatch learning rate at step 37800: 0.010000\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 92.0%\n",
      "Minibatch loss at step 37850: 0.490930\n",
      "Minibatch learning rate at step 37850: 0.010000\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 92.0%\n",
      "Minibatch loss at step 37900: 0.395680\n",
      "Minibatch learning rate at step 37900: 0.010000\n",
      "Minibatch accuracy: 94.5%\n",
      "Validation accuracy: 92.1%\n",
      "Minibatch loss at step 37950: 0.379740\n",
      "Minibatch learning rate at step 37950: 0.010000\n",
      "Minibatch accuracy: 95.3%\n",
      "Validation accuracy: 92.1%\n",
      "Minibatch loss at step 38000: 0.525540\n",
      "Minibatch learning rate at step 38000: 0.010000\n",
      "Minibatch accuracy: 92.2%\n",
      "Validation accuracy: 92.1%\n",
      "Minibatch loss at step 38050: 0.407198\n",
      "Minibatch learning rate at step 38050: 0.010000\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 92.1%\n",
      "Minibatch loss at step 38100: 0.505112\n",
      "Minibatch learning rate at step 38100: 0.010000\n",
      "Minibatch accuracy: 90.6%\n",
      "Validation accuracy: 92.0%\n",
      "Minibatch loss at step 38150: 0.497969\n",
      "Minibatch learning rate at step 38150: 0.010000\n",
      "Minibatch accuracy: 90.6%\n",
      "Validation accuracy: 91.9%\n",
      "Minibatch loss at step 38200: 0.445077\n",
      "Minibatch learning rate at step 38200: 0.010000\n",
      "Minibatch accuracy: 93.0%\n",
      "Validation accuracy: 91.9%\n",
      "Minibatch loss at step 38250: 0.400999\n",
      "Minibatch learning rate at step 38250: 0.010000\n",
      "Minibatch accuracy: 95.3%\n",
      "Validation accuracy: 92.0%\n",
      "Minibatch loss at step 38300: 0.450297\n",
      "Minibatch learning rate at step 38300: 0.010000\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 92.0%\n",
      "Minibatch loss at step 38350: 0.527545\n",
      "Minibatch learning rate at step 38350: 0.010000\n",
      "Minibatch accuracy: 91.4%\n",
      "Validation accuracy: 92.0%\n",
      "Minibatch loss at step 38400: 0.478364\n",
      "Minibatch learning rate at step 38400: 0.010000\n",
      "Minibatch accuracy: 93.0%\n",
      "Validation accuracy: 92.1%\n",
      "Minibatch loss at step 38450: 0.559668\n",
      "Minibatch learning rate at step 38450: 0.010000\n",
      "Minibatch accuracy: 89.8%\n",
      "Validation accuracy: 92.2%\n",
      "Minibatch loss at step 38500: 0.470905\n",
      "Minibatch learning rate at step 38500: 0.010000\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 92.1%\n",
      "Minibatch loss at step 38550: 0.409443\n",
      "Minibatch learning rate at step 38550: 0.010000\n",
      "Minibatch accuracy: 95.3%\n",
      "Validation accuracy: 92.0%\n",
      "Minibatch loss at step 38600: 0.439957\n",
      "Minibatch learning rate at step 38600: 0.010000\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 92.1%\n",
      "Minibatch loss at step 38650: 0.339930\n",
      "Minibatch learning rate at step 38650: 0.010000\n",
      "Minibatch accuracy: 98.4%\n",
      "Validation accuracy: 92.1%\n",
      "Minibatch loss at step 38700: 0.553168\n",
      "Minibatch learning rate at step 38700: 0.010000\n",
      "Minibatch accuracy: 91.4%\n",
      "Validation accuracy: 92.2%\n",
      "Minibatch loss at step 38750: 0.420085\n",
      "Minibatch learning rate at step 38750: 0.010000\n",
      "Minibatch accuracy: 94.5%\n",
      "Validation accuracy: 92.0%\n",
      "Minibatch loss at step 38800: 0.543720\n",
      "Minibatch learning rate at step 38800: 0.010000\n",
      "Minibatch accuracy: 89.1%\n",
      "Validation accuracy: 91.9%\n",
      "Minibatch loss at step 38850: 0.452743\n",
      "Minibatch learning rate at step 38850: 0.010000\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 92.3%\n",
      "Minibatch loss at step 38900: 0.399197\n",
      "Minibatch learning rate at step 38900: 0.010000\n",
      "Minibatch accuracy: 95.3%\n",
      "Validation accuracy: 92.1%\n",
      "Minibatch loss at step 38950: 0.574944\n",
      "Minibatch learning rate at step 38950: 0.010000\n",
      "Minibatch accuracy: 93.0%\n",
      "Validation accuracy: 92.0%\n",
      "Minibatch loss at step 39000: 0.473892\n",
      "Minibatch learning rate at step 39000: 0.010000\n",
      "Minibatch accuracy: 93.0%\n",
      "Validation accuracy: 92.1%\n",
      "Minibatch loss at step 39050: 0.422994\n",
      "Minibatch learning rate at step 39050: 0.010000\n",
      "Minibatch accuracy: 93.0%\n",
      "Validation accuracy: 91.9%\n",
      "Minibatch loss at step 39100: 0.474444\n",
      "Minibatch learning rate at step 39100: 0.010000\n",
      "Minibatch accuracy: 94.5%\n",
      "Validation accuracy: 92.1%\n",
      "Minibatch loss at step 39150: 0.537766\n",
      "Minibatch learning rate at step 39150: 0.010000\n",
      "Minibatch accuracy: 92.2%\n",
      "Validation accuracy: 91.9%\n",
      "Minibatch loss at step 39200: 0.427730\n",
      "Minibatch learning rate at step 39200: 0.010000\n",
      "Minibatch accuracy: 95.3%\n",
      "Validation accuracy: 92.0%\n",
      "Minibatch loss at step 39250: 0.373742\n",
      "Minibatch learning rate at step 39250: 0.010000\n",
      "Minibatch accuracy: 96.1%\n",
      "Validation accuracy: 92.1%\n",
      "Minibatch loss at step 39300: 0.379941\n",
      "Minibatch learning rate at step 39300: 0.010000\n",
      "Minibatch accuracy: 96.9%\n",
      "Validation accuracy: 91.9%\n",
      "Minibatch loss at step 39350: 0.536625\n",
      "Minibatch learning rate at step 39350: 0.010000\n",
      "Minibatch accuracy: 89.8%\n",
      "Validation accuracy: 92.0%\n",
      "Minibatch loss at step 39400: 0.502507\n",
      "Minibatch learning rate at step 39400: 0.010000\n",
      "Minibatch accuracy: 93.0%\n",
      "Validation accuracy: 92.2%\n",
      "Minibatch loss at step 39450: 0.449249\n",
      "Minibatch learning rate at step 39450: 0.010000\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 92.1%\n",
      "Minibatch loss at step 39500: 0.590011\n",
      "Minibatch learning rate at step 39500: 0.010000\n",
      "Minibatch accuracy: 90.6%\n",
      "Validation accuracy: 92.0%\n",
      "Minibatch loss at step 39550: 0.393188\n",
      "Minibatch learning rate at step 39550: 0.010000\n",
      "Minibatch accuracy: 94.5%\n",
      "Validation accuracy: 92.1%\n",
      "Minibatch loss at step 39600: 0.437665\n",
      "Minibatch learning rate at step 39600: 0.010000\n",
      "Minibatch accuracy: 94.5%\n",
      "Validation accuracy: 92.2%\n",
      "Minibatch loss at step 39650: 0.359475\n",
      "Minibatch learning rate at step 39650: 0.010000\n",
      "Minibatch accuracy: 96.9%\n",
      "Validation accuracy: 92.2%\n",
      "Minibatch loss at step 39700: 0.481644\n",
      "Minibatch learning rate at step 39700: 0.010000\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 92.1%\n",
      "Minibatch loss at step 39750: 0.477113\n",
      "Minibatch learning rate at step 39750: 0.010000\n",
      "Minibatch accuracy: 92.2%\n",
      "Validation accuracy: 92.0%\n",
      "Minibatch loss at step 39800: 0.417837\n",
      "Minibatch learning rate at step 39800: 0.010000\n",
      "Minibatch accuracy: 95.3%\n",
      "Validation accuracy: 92.1%\n",
      "Minibatch loss at step 39850: 0.496823\n",
      "Minibatch learning rate at step 39850: 0.010000\n",
      "Minibatch accuracy: 91.4%\n",
      "Validation accuracy: 92.2%\n",
      "Minibatch loss at step 39900: 0.433449\n",
      "Minibatch learning rate at step 39900: 0.010000\n",
      "Minibatch accuracy: 94.5%\n",
      "Validation accuracy: 92.1%\n",
      "Minibatch loss at step 39950: 0.477348\n",
      "Minibatch learning rate at step 39950: 0.010000\n",
      "Minibatch accuracy: 93.0%\n",
      "Validation accuracy: 92.3%\n",
      "Minibatch loss at step 40000: 0.452428\n",
      "Minibatch learning rate at step 40000: 0.010000\n",
      "Minibatch accuracy: 92.2%\n",
      "Validation accuracy: 92.1%\n",
      "Minibatch loss at step 40050: 0.516046\n",
      "Minibatch learning rate at step 40050: 0.010000\n",
      "Minibatch accuracy: 93.0%\n",
      "Validation accuracy: 92.2%\n",
      "Minibatch loss at step 40100: 0.399614\n",
      "Minibatch learning rate at step 40100: 0.010000\n",
      "Minibatch accuracy: 95.3%\n",
      "Validation accuracy: 92.1%\n",
      "Minibatch loss at step 40150: 0.415207\n",
      "Minibatch learning rate at step 40150: 0.010000\n",
      "Minibatch accuracy: 94.5%\n",
      "Validation accuracy: 92.0%\n",
      "Minibatch loss at step 40200: 0.589306\n",
      "Minibatch learning rate at step 40200: 0.010000\n",
      "Minibatch accuracy: 89.1%\n",
      "Validation accuracy: 92.0%\n",
      "Minibatch loss at step 40250: 0.408791\n",
      "Minibatch learning rate at step 40250: 0.010000\n",
      "Minibatch accuracy: 94.5%\n",
      "Validation accuracy: 92.3%\n",
      "Minibatch loss at step 40300: 0.571465\n",
      "Minibatch learning rate at step 40300: 0.010000\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 92.2%\n",
      "Minibatch loss at step 40350: 0.439345\n",
      "Minibatch learning rate at step 40350: 0.010000\n",
      "Minibatch accuracy: 95.3%\n",
      "Validation accuracy: 92.2%\n",
      "Minibatch loss at step 40400: 0.467272\n",
      "Minibatch learning rate at step 40400: 0.010000\n",
      "Minibatch accuracy: 93.0%\n",
      "Validation accuracy: 92.2%\n",
      "Minibatch loss at step 40450: 0.376999\n",
      "Minibatch learning rate at step 40450: 0.010000\n",
      "Minibatch accuracy: 94.5%\n",
      "Validation accuracy: 92.1%\n",
      "Minibatch loss at step 40500: 0.517318\n",
      "Minibatch learning rate at step 40500: 0.010000\n",
      "Minibatch accuracy: 90.6%\n",
      "Validation accuracy: 92.2%\n",
      "Minibatch loss at step 40550: 0.472490\n",
      "Minibatch learning rate at step 40550: 0.010000\n",
      "Minibatch accuracy: 93.0%\n",
      "Validation accuracy: 92.2%\n",
      "Minibatch loss at step 40600: 0.501148\n",
      "Minibatch learning rate at step 40600: 0.010000\n",
      "Minibatch accuracy: 92.2%\n",
      "Validation accuracy: 92.1%\n",
      "Minibatch loss at step 40650: 0.457459\n",
      "Minibatch learning rate at step 40650: 0.010000\n",
      "Minibatch accuracy: 91.4%\n",
      "Validation accuracy: 91.9%\n",
      "Minibatch loss at step 40700: 0.377215\n",
      "Minibatch learning rate at step 40700: 0.010000\n",
      "Minibatch accuracy: 96.1%\n",
      "Validation accuracy: 92.0%\n",
      "Minibatch loss at step 40750: 0.546147\n",
      "Minibatch learning rate at step 40750: 0.010000\n",
      "Minibatch accuracy: 91.4%\n",
      "Validation accuracy: 92.1%\n",
      "Minibatch loss at step 40800: 0.421788\n",
      "Minibatch learning rate at step 40800: 0.010000\n",
      "Minibatch accuracy: 94.5%\n",
      "Validation accuracy: 92.2%\n",
      "Minibatch loss at step 40850: 0.456972\n",
      "Minibatch learning rate at step 40850: 0.010000\n",
      "Minibatch accuracy: 93.0%\n",
      "Validation accuracy: 92.3%\n",
      "Minibatch loss at step 40900: 0.428553\n",
      "Minibatch learning rate at step 40900: 0.010000\n",
      "Minibatch accuracy: 95.3%\n",
      "Validation accuracy: 92.2%\n",
      "Minibatch loss at step 40950: 0.455573\n",
      "Minibatch learning rate at step 40950: 0.010000\n",
      "Minibatch accuracy: 93.0%\n",
      "Validation accuracy: 92.1%\n",
      "Minibatch loss at step 41000: 0.376465\n",
      "Minibatch learning rate at step 41000: 0.010000\n",
      "Minibatch accuracy: 94.5%\n",
      "Validation accuracy: 92.1%\n",
      "Minibatch loss at step 41050: 0.377989\n",
      "Minibatch learning rate at step 41050: 0.010000\n",
      "Minibatch accuracy: 95.3%\n",
      "Validation accuracy: 92.2%\n",
      "Minibatch loss at step 41100: 0.435116\n",
      "Minibatch learning rate at step 41100: 0.010000\n",
      "Minibatch accuracy: 93.0%\n",
      "Validation accuracy: 92.0%\n",
      "Minibatch loss at step 41150: 0.395353\n",
      "Minibatch learning rate at step 41150: 0.010000\n",
      "Minibatch accuracy: 94.5%\n",
      "Validation accuracy: 91.8%\n",
      "Minibatch loss at step 41200: 0.398111\n",
      "Minibatch learning rate at step 41200: 0.010000\n",
      "Minibatch accuracy: 96.1%\n",
      "Validation accuracy: 92.2%\n",
      "Minibatch loss at step 41250: 0.424250\n",
      "Minibatch learning rate at step 41250: 0.010000\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 92.2%\n",
      "Minibatch loss at step 41300: 0.457270\n",
      "Minibatch learning rate at step 41300: 0.010000\n",
      "Minibatch accuracy: 93.0%\n",
      "Validation accuracy: 92.1%\n",
      "Minibatch loss at step 41350: 0.373455\n",
      "Minibatch learning rate at step 41350: 0.010000\n",
      "Minibatch accuracy: 95.3%\n",
      "Validation accuracy: 92.0%\n",
      "Minibatch loss at step 41400: 0.491952\n",
      "Minibatch learning rate at step 41400: 0.010000\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 91.9%\n",
      "Minibatch loss at step 41450: 0.523670\n",
      "Minibatch learning rate at step 41450: 0.010000\n",
      "Minibatch accuracy: 89.1%\n",
      "Validation accuracy: 92.1%\n",
      "Minibatch loss at step 41500: 0.490386\n",
      "Minibatch learning rate at step 41500: 0.010000\n",
      "Minibatch accuracy: 92.2%\n",
      "Validation accuracy: 92.0%\n",
      "Minibatch loss at step 41550: 0.449535\n",
      "Minibatch learning rate at step 41550: 0.010000\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 92.3%\n",
      "Minibatch loss at step 41600: 0.523042\n",
      "Minibatch learning rate at step 41600: 0.010000\n",
      "Minibatch accuracy: 90.6%\n",
      "Validation accuracy: 92.0%\n",
      "Minibatch loss at step 41650: 0.390341\n",
      "Minibatch learning rate at step 41650: 0.010000\n",
      "Minibatch accuracy: 94.5%\n",
      "Validation accuracy: 92.1%\n",
      "Minibatch loss at step 41700: 0.434948\n",
      "Minibatch learning rate at step 41700: 0.010000\n",
      "Minibatch accuracy: 94.5%\n",
      "Validation accuracy: 92.3%\n",
      "Minibatch loss at step 41750: 0.347756\n",
      "Minibatch learning rate at step 41750: 0.010000\n",
      "Minibatch accuracy: 96.9%\n",
      "Validation accuracy: 92.3%\n",
      "Minibatch loss at step 41800: 0.387852\n",
      "Minibatch learning rate at step 41800: 0.010000\n",
      "Minibatch accuracy: 95.3%\n",
      "Validation accuracy: 92.2%\n",
      "Minibatch loss at step 41850: 0.438252\n",
      "Minibatch learning rate at step 41850: 0.010000\n",
      "Minibatch accuracy: 95.3%\n",
      "Validation accuracy: 92.1%\n",
      "Minibatch loss at step 41900: 0.376873\n",
      "Minibatch learning rate at step 41900: 0.010000\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 92.3%\n",
      "Minibatch loss at step 41950: 0.399347\n",
      "Minibatch learning rate at step 41950: 0.010000\n",
      "Minibatch accuracy: 94.5%\n",
      "Validation accuracy: 92.3%\n",
      "Minibatch loss at step 42000: 0.415869\n",
      "Minibatch learning rate at step 42000: 0.010000\n",
      "Minibatch accuracy: 95.3%\n",
      "Validation accuracy: 92.0%\n",
      "Minibatch loss at step 42050: 0.469771\n",
      "Minibatch learning rate at step 42050: 0.010000\n",
      "Minibatch accuracy: 92.2%\n",
      "Validation accuracy: 92.2%\n",
      "Minibatch loss at step 42100: 0.485959\n",
      "Minibatch learning rate at step 42100: 0.010000\n",
      "Minibatch accuracy: 92.2%\n",
      "Validation accuracy: 92.0%\n",
      "Minibatch loss at step 42150: 0.400839\n",
      "Minibatch learning rate at step 42150: 0.010000\n",
      "Minibatch accuracy: 94.5%\n",
      "Validation accuracy: 92.2%\n",
      "Minibatch loss at step 42200: 0.408151\n",
      "Minibatch learning rate at step 42200: 0.010000\n",
      "Minibatch accuracy: 95.3%\n",
      "Validation accuracy: 92.2%\n",
      "Minibatch loss at step 42250: 0.457751\n",
      "Minibatch learning rate at step 42250: 0.010000\n",
      "Minibatch accuracy: 92.2%\n",
      "Validation accuracy: 92.2%\n",
      "Minibatch loss at step 42300: 0.322863\n",
      "Minibatch learning rate at step 42300: 0.010000\n",
      "Minibatch accuracy: 96.9%\n",
      "Validation accuracy: 92.3%\n",
      "Minibatch loss at step 42350: 0.541381\n",
      "Minibatch learning rate at step 42350: 0.010000\n",
      "Minibatch accuracy: 88.3%\n",
      "Validation accuracy: 92.2%\n",
      "Minibatch loss at step 42400: 0.556740\n",
      "Minibatch learning rate at step 42400: 0.010000\n",
      "Minibatch accuracy: 91.4%\n",
      "Validation accuracy: 92.0%\n",
      "Minibatch loss at step 42450: 0.461584\n",
      "Minibatch learning rate at step 42450: 0.010000\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 92.1%\n",
      "Minibatch loss at step 42500: 0.443378\n",
      "Minibatch learning rate at step 42500: 0.010000\n",
      "Minibatch accuracy: 93.0%\n",
      "Validation accuracy: 92.2%\n",
      "Minibatch loss at step 42550: 0.353501\n",
      "Minibatch learning rate at step 42550: 0.010000\n",
      "Minibatch accuracy: 96.9%\n",
      "Validation accuracy: 92.0%\n",
      "Minibatch loss at step 42600: 0.499553\n",
      "Minibatch learning rate at step 42600: 0.010000\n",
      "Minibatch accuracy: 93.0%\n",
      "Validation accuracy: 92.3%\n",
      "Minibatch loss at step 42650: 0.485360\n",
      "Minibatch learning rate at step 42650: 0.010000\n",
      "Minibatch accuracy: 90.6%\n",
      "Validation accuracy: 92.2%\n",
      "Minibatch loss at step 42700: 0.517537\n",
      "Minibatch learning rate at step 42700: 0.010000\n",
      "Minibatch accuracy: 90.6%\n",
      "Validation accuracy: 92.2%\n",
      "Minibatch loss at step 42750: 0.606287\n",
      "Minibatch learning rate at step 42750: 0.010000\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 92.1%\n",
      "Minibatch loss at step 42800: 0.416838\n",
      "Minibatch learning rate at step 42800: 0.010000\n",
      "Minibatch accuracy: 93.0%\n",
      "Validation accuracy: 92.1%\n",
      "Minibatch loss at step 42850: 0.446004\n",
      "Minibatch learning rate at step 42850: 0.010000\n",
      "Minibatch accuracy: 90.6%\n",
      "Validation accuracy: 92.1%\n",
      "Minibatch loss at step 42900: 0.509495\n",
      "Minibatch learning rate at step 42900: 0.010000\n",
      "Minibatch accuracy: 89.8%\n",
      "Validation accuracy: 92.2%\n",
      "Minibatch loss at step 42950: 0.392771\n",
      "Minibatch learning rate at step 42950: 0.010000\n",
      "Minibatch accuracy: 95.3%\n",
      "Validation accuracy: 92.2%\n",
      "Minibatch loss at step 43000: 0.422762\n",
      "Minibatch learning rate at step 43000: 0.010000\n",
      "Minibatch accuracy: 94.5%\n",
      "Validation accuracy: 92.1%\n",
      "Minibatch loss at step 43050: 0.399618\n",
      "Minibatch learning rate at step 43050: 0.010000\n",
      "Minibatch accuracy: 94.5%\n",
      "Validation accuracy: 92.0%\n",
      "Minibatch loss at step 43100: 0.500744\n",
      "Minibatch learning rate at step 43100: 0.010000\n",
      "Minibatch accuracy: 93.0%\n",
      "Validation accuracy: 92.2%\n",
      "Minibatch loss at step 43150: 0.491029\n",
      "Minibatch learning rate at step 43150: 0.010000\n",
      "Minibatch accuracy: 93.0%\n",
      "Validation accuracy: 92.3%\n",
      "Minibatch loss at step 43200: 0.427241\n",
      "Minibatch learning rate at step 43200: 0.010000\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 92.2%\n",
      "Minibatch loss at step 43250: 0.455394\n",
      "Minibatch learning rate at step 43250: 0.010000\n",
      "Minibatch accuracy: 93.0%\n",
      "Validation accuracy: 92.2%\n",
      "Minibatch loss at step 43300: 0.467201\n",
      "Minibatch learning rate at step 43300: 0.010000\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 92.4%\n",
      "Minibatch loss at step 43350: 0.500324\n",
      "Minibatch learning rate at step 43350: 0.010000\n",
      "Minibatch accuracy: 92.2%\n",
      "Validation accuracy: 92.4%\n",
      "Minibatch loss at step 43400: 0.420167\n",
      "Minibatch learning rate at step 43400: 0.010000\n",
      "Minibatch accuracy: 94.5%\n",
      "Validation accuracy: 92.4%\n",
      "Minibatch loss at step 43450: 0.470970\n",
      "Minibatch learning rate at step 43450: 0.010000\n",
      "Minibatch accuracy: 92.2%\n",
      "Validation accuracy: 92.3%\n",
      "Minibatch loss at step 43500: 0.420270\n",
      "Minibatch learning rate at step 43500: 0.010000\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 92.4%\n",
      "Minibatch loss at step 43550: 0.483527\n",
      "Minibatch learning rate at step 43550: 0.010000\n",
      "Minibatch accuracy: 92.2%\n",
      "Validation accuracy: 92.2%\n",
      "Minibatch loss at step 43600: 0.411111\n",
      "Minibatch learning rate at step 43600: 0.010000\n",
      "Minibatch accuracy: 96.1%\n",
      "Validation accuracy: 92.3%\n",
      "Minibatch loss at step 43650: 0.479242\n",
      "Minibatch learning rate at step 43650: 0.010000\n",
      "Minibatch accuracy: 92.2%\n",
      "Validation accuracy: 92.1%\n",
      "Minibatch loss at step 43700: 0.442187\n",
      "Minibatch learning rate at step 43700: 0.010000\n",
      "Minibatch accuracy: 94.5%\n",
      "Validation accuracy: 92.2%\n",
      "Minibatch loss at step 43750: 0.453457\n",
      "Minibatch learning rate at step 43750: 0.010000\n",
      "Minibatch accuracy: 93.0%\n",
      "Validation accuracy: 91.8%\n",
      "Minibatch loss at step 43800: 0.467612\n",
      "Minibatch learning rate at step 43800: 0.010000\n",
      "Minibatch accuracy: 94.5%\n",
      "Validation accuracy: 92.1%\n",
      "Minibatch loss at step 43850: 0.390833\n",
      "Minibatch learning rate at step 43850: 0.010000\n",
      "Minibatch accuracy: 94.5%\n",
      "Validation accuracy: 92.2%\n",
      "Minibatch loss at step 43900: 0.552584\n",
      "Minibatch learning rate at step 43900: 0.010000\n",
      "Minibatch accuracy: 90.6%\n",
      "Validation accuracy: 92.2%\n",
      "Minibatch loss at step 43950: 0.406059\n",
      "Minibatch learning rate at step 43950: 0.010000\n",
      "Minibatch accuracy: 96.1%\n",
      "Validation accuracy: 92.2%\n",
      "Minibatch loss at step 44000: 0.433314\n",
      "Minibatch learning rate at step 44000: 0.010000\n",
      "Minibatch accuracy: 93.0%\n",
      "Validation accuracy: 92.2%\n",
      "Minibatch loss at step 44050: 0.449790\n",
      "Minibatch learning rate at step 44050: 0.010000\n",
      "Minibatch accuracy: 94.5%\n",
      "Validation accuracy: 92.2%\n",
      "Minibatch loss at step 44100: 0.403984\n",
      "Minibatch learning rate at step 44100: 0.010000\n",
      "Minibatch accuracy: 96.1%\n",
      "Validation accuracy: 92.2%\n",
      "Minibatch loss at step 44150: 0.414087\n",
      "Minibatch learning rate at step 44150: 0.010000\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 92.3%\n",
      "Minibatch loss at step 44200: 0.412892\n",
      "Minibatch learning rate at step 44200: 0.010000\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 92.1%\n",
      "Minibatch loss at step 44250: 0.397908\n",
      "Minibatch learning rate at step 44250: 0.010000\n",
      "Minibatch accuracy: 95.3%\n",
      "Validation accuracy: 92.3%\n",
      "Minibatch loss at step 44300: 0.379871\n",
      "Minibatch learning rate at step 44300: 0.010000\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 92.1%\n",
      "Minibatch loss at step 44350: 0.404019\n",
      "Minibatch learning rate at step 44350: 0.010000\n",
      "Minibatch accuracy: 95.3%\n",
      "Validation accuracy: 92.3%\n",
      "Minibatch loss at step 44400: 0.518196\n",
      "Minibatch learning rate at step 44400: 0.010000\n",
      "Minibatch accuracy: 94.5%\n",
      "Validation accuracy: 92.3%\n",
      "Minibatch loss at step 44450: 0.531011\n",
      "Minibatch learning rate at step 44450: 0.010000\n",
      "Minibatch accuracy: 92.2%\n",
      "Validation accuracy: 92.0%\n",
      "Minibatch loss at step 44500: 0.465160\n",
      "Minibatch learning rate at step 44500: 0.010000\n",
      "Minibatch accuracy: 92.2%\n",
      "Validation accuracy: 92.3%\n",
      "Minibatch loss at step 44550: 0.444481\n",
      "Minibatch learning rate at step 44550: 0.010000\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 92.2%\n",
      "Minibatch loss at step 44600: 0.373777\n",
      "Minibatch learning rate at step 44600: 0.010000\n",
      "Minibatch accuracy: 96.1%\n",
      "Validation accuracy: 92.4%\n",
      "Minibatch loss at step 44650: 0.370897\n",
      "Minibatch learning rate at step 44650: 0.010000\n",
      "Minibatch accuracy: 96.1%\n",
      "Validation accuracy: 92.3%\n",
      "Minibatch loss at step 44700: 0.397220\n",
      "Minibatch learning rate at step 44700: 0.010000\n",
      "Minibatch accuracy: 95.3%\n",
      "Validation accuracy: 92.2%\n",
      "Minibatch loss at step 44750: 0.446262\n",
      "Minibatch learning rate at step 44750: 0.010000\n",
      "Minibatch accuracy: 92.2%\n",
      "Validation accuracy: 92.2%\n",
      "Minibatch loss at step 44800: 0.389225\n",
      "Minibatch learning rate at step 44800: 0.010000\n",
      "Minibatch accuracy: 95.3%\n",
      "Validation accuracy: 92.3%\n",
      "Minibatch loss at step 44850: 0.471084\n",
      "Minibatch learning rate at step 44850: 0.010000\n",
      "Minibatch accuracy: 93.0%\n",
      "Validation accuracy: 92.3%\n",
      "Minibatch loss at step 44900: 0.463699\n",
      "Minibatch learning rate at step 44900: 0.010000\n",
      "Minibatch accuracy: 93.0%\n",
      "Validation accuracy: 92.2%\n",
      "Minibatch loss at step 44950: 0.444230\n",
      "Minibatch learning rate at step 44950: 0.010000\n",
      "Minibatch accuracy: 94.5%\n",
      "Validation accuracy: 92.3%\n",
      "Minibatch loss at step 45000: 0.456123\n",
      "Minibatch learning rate at step 45000: 0.010000\n",
      "Minibatch accuracy: 93.0%\n",
      "Validation accuracy: 92.4%\n",
      "Minibatch loss at step 45050: 0.465805\n",
      "Minibatch learning rate at step 45050: 0.010000\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 92.3%\n",
      "Minibatch loss at step 45100: 0.361514\n",
      "Minibatch learning rate at step 45100: 0.010000\n",
      "Minibatch accuracy: 97.7%\n",
      "Validation accuracy: 92.2%\n",
      "Minibatch loss at step 45150: 0.354271\n",
      "Minibatch learning rate at step 45150: 0.010000\n",
      "Minibatch accuracy: 96.1%\n",
      "Validation accuracy: 92.3%\n",
      "Minibatch loss at step 45200: 0.430375\n",
      "Minibatch learning rate at step 45200: 0.010000\n",
      "Minibatch accuracy: 95.3%\n",
      "Validation accuracy: 92.3%\n",
      "Minibatch loss at step 45250: 0.403330\n",
      "Minibatch learning rate at step 45250: 0.010000\n",
      "Minibatch accuracy: 94.5%\n",
      "Validation accuracy: 92.2%\n",
      "Minibatch loss at step 45300: 0.330731\n",
      "Minibatch learning rate at step 45300: 0.010000\n",
      "Minibatch accuracy: 96.9%\n",
      "Validation accuracy: 92.3%\n",
      "Minibatch loss at step 45350: 0.436540\n",
      "Minibatch learning rate at step 45350: 0.010000\n",
      "Minibatch accuracy: 94.5%\n",
      "Validation accuracy: 92.3%\n",
      "Minibatch loss at step 45400: 0.453137\n",
      "Minibatch learning rate at step 45400: 0.010000\n",
      "Minibatch accuracy: 91.4%\n",
      "Validation accuracy: 92.3%\n",
      "Minibatch loss at step 45450: 0.595896\n",
      "Minibatch learning rate at step 45450: 0.010000\n",
      "Minibatch accuracy: 91.4%\n",
      "Validation accuracy: 92.3%\n",
      "Minibatch loss at step 45500: 0.351787\n",
      "Minibatch learning rate at step 45500: 0.010000\n",
      "Minibatch accuracy: 96.9%\n",
      "Validation accuracy: 92.3%\n",
      "Minibatch loss at step 45550: 0.484682\n",
      "Minibatch learning rate at step 45550: 0.010000\n",
      "Minibatch accuracy: 90.6%\n",
      "Validation accuracy: 92.4%\n",
      "Minibatch loss at step 45600: 0.355612\n",
      "Minibatch learning rate at step 45600: 0.010000\n",
      "Minibatch accuracy: 95.3%\n",
      "Validation accuracy: 92.2%\n",
      "Minibatch loss at step 45650: 0.428372\n",
      "Minibatch learning rate at step 45650: 0.010000\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 92.3%\n",
      "Minibatch loss at step 45700: 0.426850\n",
      "Minibatch learning rate at step 45700: 0.010000\n",
      "Minibatch accuracy: 95.3%\n",
      "Validation accuracy: 91.9%\n",
      "Minibatch loss at step 45750: 0.414185\n",
      "Minibatch learning rate at step 45750: 0.010000\n",
      "Minibatch accuracy: 94.5%\n",
      "Validation accuracy: 92.2%\n",
      "Minibatch loss at step 45800: 0.437015\n",
      "Minibatch learning rate at step 45800: 0.010000\n",
      "Minibatch accuracy: 93.0%\n",
      "Validation accuracy: 92.3%\n",
      "Minibatch loss at step 45850: 0.350240\n",
      "Minibatch learning rate at step 45850: 0.010000\n",
      "Minibatch accuracy: 96.9%\n",
      "Validation accuracy: 92.4%\n",
      "Minibatch loss at step 45900: 0.542354\n",
      "Minibatch learning rate at step 45900: 0.010000\n",
      "Minibatch accuracy: 89.1%\n",
      "Validation accuracy: 92.4%\n",
      "Minibatch loss at step 45950: 0.467793\n",
      "Minibatch learning rate at step 45950: 0.010000\n",
      "Minibatch accuracy: 92.2%\n",
      "Validation accuracy: 92.0%\n",
      "Minibatch loss at step 46000: 0.454679\n",
      "Minibatch learning rate at step 46000: 0.010000\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 92.2%\n",
      "Minibatch loss at step 46050: 0.534676\n",
      "Minibatch learning rate at step 46050: 0.010000\n",
      "Minibatch accuracy: 91.4%\n",
      "Validation accuracy: 92.2%\n",
      "Minibatch loss at step 46100: 0.352667\n",
      "Minibatch learning rate at step 46100: 0.010000\n",
      "Minibatch accuracy: 96.9%\n",
      "Validation accuracy: 92.1%\n",
      "Minibatch loss at step 46150: 0.368797\n",
      "Minibatch learning rate at step 46150: 0.010000\n",
      "Minibatch accuracy: 96.9%\n",
      "Validation accuracy: 92.2%\n",
      "Minibatch loss at step 46200: 0.421581\n",
      "Minibatch learning rate at step 46200: 0.010000\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 92.2%\n",
      "Minibatch loss at step 46250: 0.479149\n",
      "Minibatch learning rate at step 46250: 0.010000\n",
      "Minibatch accuracy: 93.0%\n",
      "Validation accuracy: 92.3%\n",
      "Minibatch loss at step 46300: 0.364269\n",
      "Minibatch learning rate at step 46300: 0.010000\n",
      "Minibatch accuracy: 96.1%\n",
      "Validation accuracy: 92.2%\n",
      "Minibatch loss at step 46350: 0.389461\n",
      "Minibatch learning rate at step 46350: 0.010000\n",
      "Minibatch accuracy: 94.5%\n",
      "Validation accuracy: 92.2%\n",
      "Minibatch loss at step 46400: 0.489586\n",
      "Minibatch learning rate at step 46400: 0.010000\n",
      "Minibatch accuracy: 93.0%\n",
      "Validation accuracy: 92.2%\n",
      "Minibatch loss at step 46450: 0.444493\n",
      "Minibatch learning rate at step 46450: 0.010000\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 92.5%\n",
      "Minibatch loss at step 46500: 0.515122\n",
      "Minibatch learning rate at step 46500: 0.010000\n",
      "Minibatch accuracy: 91.4%\n",
      "Validation accuracy: 92.5%\n",
      "Minibatch loss at step 46550: 0.581871\n",
      "Minibatch learning rate at step 46550: 0.010000\n",
      "Minibatch accuracy: 89.8%\n",
      "Validation accuracy: 92.2%\n",
      "Minibatch loss at step 46600: 0.423807\n",
      "Minibatch learning rate at step 46600: 0.010000\n",
      "Minibatch accuracy: 94.5%\n",
      "Validation accuracy: 92.4%\n",
      "Minibatch loss at step 46650: 0.426482\n",
      "Minibatch learning rate at step 46650: 0.010000\n",
      "Minibatch accuracy: 93.0%\n",
      "Validation accuracy: 92.4%\n",
      "Minibatch loss at step 46700: 0.483921\n",
      "Minibatch learning rate at step 46700: 0.010000\n",
      "Minibatch accuracy: 93.0%\n",
      "Validation accuracy: 92.3%\n",
      "Minibatch loss at step 46750: 0.454910\n",
      "Minibatch learning rate at step 46750: 0.010000\n",
      "Minibatch accuracy: 93.0%\n",
      "Validation accuracy: 92.4%\n",
      "Minibatch loss at step 46800: 0.406411\n",
      "Minibatch learning rate at step 46800: 0.010000\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 92.4%\n",
      "Minibatch loss at step 46850: 0.401068\n",
      "Minibatch learning rate at step 46850: 0.010000\n",
      "Minibatch accuracy: 94.5%\n",
      "Validation accuracy: 92.2%\n",
      "Minibatch loss at step 46900: 0.458949\n",
      "Minibatch learning rate at step 46900: 0.010000\n",
      "Minibatch accuracy: 92.2%\n",
      "Validation accuracy: 92.3%\n",
      "Minibatch loss at step 46950: 0.345382\n",
      "Minibatch learning rate at step 46950: 0.010000\n",
      "Minibatch accuracy: 96.9%\n",
      "Validation accuracy: 92.2%\n",
      "Minibatch loss at step 47000: 0.433777\n",
      "Minibatch learning rate at step 47000: 0.010000\n",
      "Minibatch accuracy: 93.0%\n",
      "Validation accuracy: 92.5%\n",
      "Minibatch loss at step 47050: 0.469133\n",
      "Minibatch learning rate at step 47050: 0.010000\n",
      "Minibatch accuracy: 92.2%\n",
      "Validation accuracy: 92.4%\n",
      "Minibatch loss at step 47100: 0.390952\n",
      "Minibatch learning rate at step 47100: 0.010000\n",
      "Minibatch accuracy: 95.3%\n",
      "Validation accuracy: 92.2%\n",
      "Minibatch loss at step 47150: 0.453193\n",
      "Minibatch learning rate at step 47150: 0.010000\n",
      "Minibatch accuracy: 91.4%\n",
      "Validation accuracy: 92.2%\n",
      "Minibatch loss at step 47200: 0.375076\n",
      "Minibatch learning rate at step 47200: 0.010000\n",
      "Minibatch accuracy: 96.1%\n",
      "Validation accuracy: 92.3%\n",
      "Minibatch loss at step 47250: 0.426230\n",
      "Minibatch learning rate at step 47250: 0.010000\n",
      "Minibatch accuracy: 93.0%\n",
      "Validation accuracy: 92.2%\n",
      "Minibatch loss at step 47300: 0.467755\n",
      "Minibatch learning rate at step 47300: 0.010000\n",
      "Minibatch accuracy: 93.0%\n",
      "Validation accuracy: 92.2%\n",
      "Minibatch loss at step 47350: 0.389926\n",
      "Minibatch learning rate at step 47350: 0.010000\n",
      "Minibatch accuracy: 95.3%\n",
      "Validation accuracy: 92.1%\n",
      "Minibatch loss at step 47400: 0.408622\n",
      "Minibatch learning rate at step 47400: 0.010000\n",
      "Minibatch accuracy: 94.5%\n",
      "Validation accuracy: 92.2%\n",
      "Minibatch loss at step 47450: 0.450442\n",
      "Minibatch learning rate at step 47450: 0.010000\n",
      "Minibatch accuracy: 93.0%\n",
      "Validation accuracy: 92.3%\n",
      "Minibatch loss at step 47500: 0.420348\n",
      "Minibatch learning rate at step 47500: 0.010000\n",
      "Minibatch accuracy: 94.5%\n",
      "Validation accuracy: 92.3%\n",
      "Minibatch loss at step 47550: 0.446228\n",
      "Minibatch learning rate at step 47550: 0.010000\n",
      "Minibatch accuracy: 93.0%\n",
      "Validation accuracy: 92.3%\n",
      "Minibatch loss at step 47600: 0.453677\n",
      "Minibatch learning rate at step 47600: 0.010000\n",
      "Minibatch accuracy: 92.2%\n",
      "Validation accuracy: 92.2%\n",
      "Minibatch loss at step 47650: 0.373585\n",
      "Minibatch learning rate at step 47650: 0.010000\n",
      "Minibatch accuracy: 96.9%\n",
      "Validation accuracy: 92.4%\n",
      "Minibatch loss at step 47700: 0.505725\n",
      "Minibatch learning rate at step 47700: 0.010000\n",
      "Minibatch accuracy: 88.3%\n",
      "Validation accuracy: 92.2%\n",
      "Minibatch loss at step 47750: 0.491543\n",
      "Minibatch learning rate at step 47750: 0.010000\n",
      "Minibatch accuracy: 92.2%\n",
      "Validation accuracy: 92.3%\n",
      "Minibatch loss at step 47800: 0.466724\n",
      "Minibatch learning rate at step 47800: 0.010000\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 92.3%\n",
      "Minibatch loss at step 47850: 0.408495\n",
      "Minibatch learning rate at step 47850: 0.010000\n",
      "Minibatch accuracy: 95.3%\n",
      "Validation accuracy: 92.4%\n",
      "Minibatch loss at step 47900: 0.352579\n",
      "Minibatch learning rate at step 47900: 0.010000\n",
      "Minibatch accuracy: 96.1%\n",
      "Validation accuracy: 92.3%\n",
      "Minibatch loss at step 47950: 0.489868\n",
      "Minibatch learning rate at step 47950: 0.010000\n",
      "Minibatch accuracy: 91.4%\n",
      "Validation accuracy: 92.5%\n",
      "Minibatch loss at step 48000: 0.424905\n",
      "Minibatch learning rate at step 48000: 0.010000\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 92.3%\n",
      "Minibatch loss at step 48050: 0.409309\n",
      "Minibatch learning rate at step 48050: 0.010000\n",
      "Minibatch accuracy: 95.3%\n",
      "Validation accuracy: 92.4%\n",
      "Minibatch loss at step 48100: 0.494157\n",
      "Minibatch learning rate at step 48100: 0.010000\n",
      "Minibatch accuracy: 89.8%\n",
      "Validation accuracy: 92.3%\n",
      "Minibatch loss at step 48150: 0.459674\n",
      "Minibatch learning rate at step 48150: 0.010000\n",
      "Minibatch accuracy: 92.2%\n",
      "Validation accuracy: 92.3%\n",
      "Minibatch loss at step 48200: 0.342495\n",
      "Minibatch learning rate at step 48200: 0.010000\n",
      "Minibatch accuracy: 96.9%\n",
      "Validation accuracy: 92.4%\n",
      "Minibatch loss at step 48250: 0.393682\n",
      "Minibatch learning rate at step 48250: 0.010000\n",
      "Minibatch accuracy: 94.5%\n",
      "Validation accuracy: 92.5%\n",
      "Minibatch loss at step 48300: 0.495958\n",
      "Minibatch learning rate at step 48300: 0.010000\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 92.5%\n",
      "Minibatch loss at step 48350: 0.511459\n",
      "Minibatch learning rate at step 48350: 0.010000\n",
      "Minibatch accuracy: 91.4%\n",
      "Validation accuracy: 92.5%\n",
      "Minibatch loss at step 48400: 0.516732\n",
      "Minibatch learning rate at step 48400: 0.010000\n",
      "Minibatch accuracy: 91.4%\n",
      "Validation accuracy: 92.5%\n",
      "Minibatch loss at step 48450: 0.388609\n",
      "Minibatch learning rate at step 48450: 0.010000\n",
      "Minibatch accuracy: 95.3%\n",
      "Validation accuracy: 92.2%\n",
      "Minibatch loss at step 48500: 0.458585\n",
      "Minibatch learning rate at step 48500: 0.010000\n",
      "Minibatch accuracy: 92.2%\n",
      "Validation accuracy: 92.5%\n",
      "Minibatch loss at step 48550: 0.383673\n",
      "Minibatch learning rate at step 48550: 0.010000\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 92.3%\n",
      "Minibatch loss at step 48600: 0.447688\n",
      "Minibatch learning rate at step 48600: 0.010000\n",
      "Minibatch accuracy: 92.2%\n",
      "Validation accuracy: 92.3%\n",
      "Minibatch loss at step 48650: 0.389816\n",
      "Minibatch learning rate at step 48650: 0.010000\n",
      "Minibatch accuracy: 96.1%\n",
      "Validation accuracy: 92.4%\n",
      "Minibatch loss at step 48700: 0.407204\n",
      "Minibatch learning rate at step 48700: 0.010000\n",
      "Minibatch accuracy: 94.5%\n",
      "Validation accuracy: 92.3%\n",
      "Minibatch loss at step 48750: 0.471804\n",
      "Minibatch learning rate at step 48750: 0.010000\n",
      "Minibatch accuracy: 93.0%\n",
      "Validation accuracy: 92.4%\n",
      "Minibatch loss at step 48800: 0.570787\n",
      "Minibatch learning rate at step 48800: 0.010000\n",
      "Minibatch accuracy: 89.8%\n",
      "Validation accuracy: 92.1%\n",
      "Minibatch loss at step 48850: 0.515632\n",
      "Minibatch learning rate at step 48850: 0.010000\n",
      "Minibatch accuracy: 91.4%\n",
      "Validation accuracy: 92.4%\n",
      "Minibatch loss at step 48900: 0.408218\n",
      "Minibatch learning rate at step 48900: 0.010000\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 92.5%\n",
      "Minibatch loss at step 48950: 0.441227\n",
      "Minibatch learning rate at step 48950: 0.010000\n",
      "Minibatch accuracy: 92.2%\n",
      "Validation accuracy: 92.4%\n",
      "Minibatch loss at step 49000: 0.447531\n",
      "Minibatch learning rate at step 49000: 0.010000\n",
      "Minibatch accuracy: 93.0%\n",
      "Validation accuracy: 92.1%\n",
      "Minibatch loss at step 49050: 0.377496\n",
      "Minibatch learning rate at step 49050: 0.010000\n",
      "Minibatch accuracy: 96.1%\n",
      "Validation accuracy: 92.3%\n",
      "Minibatch loss at step 49100: 0.337470\n",
      "Minibatch learning rate at step 49100: 0.010000\n",
      "Minibatch accuracy: 96.9%\n",
      "Validation accuracy: 92.2%\n",
      "Minibatch loss at step 49150: 0.423279\n",
      "Minibatch learning rate at step 49150: 0.010000\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 92.4%\n",
      "Minibatch loss at step 49200: 0.420123\n",
      "Minibatch learning rate at step 49200: 0.010000\n",
      "Minibatch accuracy: 94.5%\n",
      "Validation accuracy: 92.4%\n",
      "Minibatch loss at step 49250: 0.317819\n",
      "Minibatch learning rate at step 49250: 0.010000\n",
      "Minibatch accuracy: 97.7%\n",
      "Validation accuracy: 92.4%\n",
      "Minibatch loss at step 49300: 0.422925\n",
      "Minibatch learning rate at step 49300: 0.010000\n",
      "Minibatch accuracy: 94.5%\n",
      "Validation accuracy: 92.2%\n",
      "Minibatch loss at step 49350: 0.442404\n",
      "Minibatch learning rate at step 49350: 0.010000\n",
      "Minibatch accuracy: 92.2%\n",
      "Validation accuracy: 92.4%\n",
      "Minibatch loss at step 49400: 0.404587\n",
      "Minibatch learning rate at step 49400: 0.010000\n",
      "Minibatch accuracy: 94.5%\n",
      "Validation accuracy: 92.4%\n",
      "Minibatch loss at step 49450: 0.455287\n",
      "Minibatch learning rate at step 49450: 0.010000\n",
      "Minibatch accuracy: 94.5%\n",
      "Validation accuracy: 92.3%\n",
      "Minibatch loss at step 49500: 0.414824\n",
      "Minibatch learning rate at step 49500: 0.010000\n",
      "Minibatch accuracy: 94.5%\n",
      "Validation accuracy: 92.5%\n",
      "Minibatch loss at step 49550: 0.461230\n",
      "Minibatch learning rate at step 49550: 0.010000\n",
      "Minibatch accuracy: 91.4%\n",
      "Validation accuracy: 92.3%\n",
      "Minibatch loss at step 49600: 0.341632\n",
      "Minibatch learning rate at step 49600: 0.010000\n",
      "Minibatch accuracy: 95.3%\n",
      "Validation accuracy: 92.4%\n",
      "Minibatch loss at step 49650: 0.435124\n",
      "Minibatch learning rate at step 49650: 0.010000\n",
      "Minibatch accuracy: 92.2%\n",
      "Validation accuracy: 92.5%\n",
      "Minibatch loss at step 49700: 0.383223\n",
      "Minibatch learning rate at step 49700: 0.010000\n",
      "Minibatch accuracy: 95.3%\n",
      "Validation accuracy: 92.3%\n",
      "Minibatch loss at step 49750: 0.424693\n",
      "Minibatch learning rate at step 49750: 0.010000\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 92.5%\n",
      "Minibatch loss at step 49800: 0.382035\n",
      "Minibatch learning rate at step 49800: 0.010000\n",
      "Minibatch accuracy: 97.7%\n",
      "Validation accuracy: 92.4%\n",
      "Minibatch loss at step 49850: 0.435938\n",
      "Minibatch learning rate at step 49850: 0.010000\n",
      "Minibatch accuracy: 93.0%\n",
      "Validation accuracy: 92.2%\n",
      "Minibatch loss at step 49900: 0.448099\n",
      "Minibatch learning rate at step 49900: 0.010000\n",
      "Minibatch accuracy: 93.0%\n",
      "Validation accuracy: 92.5%\n",
      "Minibatch loss at step 49950: 0.527296\n",
      "Minibatch learning rate at step 49950: 0.010000\n",
      "Minibatch accuracy: 90.6%\n",
      "Validation accuracy: 92.3%\n",
      "Minibatch loss at step 50000: 0.527878\n",
      "Minibatch learning rate at step 50000: 0.010000\n",
      "Minibatch accuracy: 90.6%\n",
      "Validation accuracy: 92.5%\n",
      "Test accuracy: 97.3%\n"
     ]
    }
   ],
   "source": [
    "num_steps = 95001\n",
    "\n",
    "with tf.Session(graph=graph) as session:\n",
    "  tf.initialize_all_variables().run()\n",
    "  lossVec = []\n",
    "  trainAcc = []\n",
    "  validAcc = []\n",
    "  lrVec = []\n",
    "  print('Initialized')\n",
    "  for step in range(num_steps):\n",
    "    offset = (step * batch_size) % (train_labels.shape[0] - batch_size)\n",
    "    batch_data = train_dataset[offset:(offset + batch_size), :, :, :]\n",
    "    batch_labels = train_labels[offset:(offset + batch_size), :]\n",
    "    feed_dict = {tf_train_dataset : batch_data, tf_train_labels : batch_labels}\n",
    "    _, l, lr, predictions = session.run([optimizer, loss, learning_rate, train_prediction], feed_dict=feed_dict)\n",
    "    lossVec.append(l)\n",
    "    lrVec.append(lr)\n",
    "    if (step % 200 == 0):\n",
    "      print(\"Minibatch loss at step %d: %f\" % (step, l))\n",
    "      print(\"Minibatch learning rate at step %d: %f\" % (step, lr))\n",
    "      trainAcc.append(accuracy(predictions, batch_labels))\n",
    "      validAcc.append(accuracy(valid_prediction.eval(), valid_labels))\n",
    "  print('Test accuracy: %.1f%%' % accuracy(test_prediction.eval(), test_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ex 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import math as math\n",
    "batch_size = 128\n",
    "patch_size = 4\n",
    "depth = 16\n",
    "l1_size = 1024\n",
    "l2_size = 205\n",
    "train_size = train_labels.shape[0]\n",
    "\n",
    "graph = tf.Graph()\n",
    "\n",
    "with graph.as_default():\n",
    "\n",
    "  # Input data.\n",
    "  tf_train_dataset = tf.placeholder(tf.float32, shape=(batch_size, image_size, image_size, num_channels))\n",
    "  tf_train_labels = tf.placeholder(tf.float32, shape=(batch_size, num_labels))\n",
    "  tf_valid_dataset = tf.constant(valid_dataset)\n",
    "  tf_test_dataset = tf.constant(test_dataset)\n",
    "  \n",
    "  # Variables.\n",
    "  layerConv1_weights = tf.Variable(tf.truncated_normal(\n",
    "            [patch_size, patch_size, num_channels, depth], stddev=0.1))\n",
    "  layerConv1_biases = tf.Variable(tf.zeros([depth]))\n",
    "  layerConv2_weights = tf.Variable(tf.truncated_normal(\n",
    "            [patch_size, patch_size, depth, depth*2], stddev=math.sqrt(2.0/(patch_size*patch_size*depth))))\n",
    "  layerConv2_biases = tf.Variable(tf.zeros([depth*2]))\n",
    "  layerConv3_weights = tf.Variable(tf.truncated_normal(\n",
    "            [patch_size, patch_size, depth*2, depth*4], stddev=math.sqrt(2.0/(patch_size*patch_size*depth*2))))\n",
    "  layerConv3_biases = tf.Variable(tf.zeros([depth*4]))\n",
    "  layerConv4_weights = tf.Variable(tf.truncated_normal(\n",
    "            [patch_size, patch_size, depth*4, depth*4], stddev=math.sqrt(2.0/(patch_size*patch_size*depth*4))))\n",
    "  layerConv4_biases = tf.Variable(tf.zeros([depth*4]))\n",
    "  layerConv5_weights = tf.Variable(tf.truncated_normal(\n",
    "            [patch_size, patch_size, depth*4, depth*16], stddev=math.sqrt(2.0/(patch_size*patch_size*depth*4))))\n",
    "  layerConv5_biases = tf.Variable(tf.zeros([depth*16]))\n",
    "\n",
    "  layer1_weights = tf.Variable(tf.truncated_normal(\n",
    "            [image_size//7*image_size//7*(depth*4), l1_size], \n",
    "            stddev=math.sqrt(2.0/(image_size//7*image_size//7*(depth*4)))))\n",
    "  layer1_biases = tf.Variable(tf.zeros([l1_size]))\n",
    "  layer2_weights = tf.Variable(tf.truncated_normal(\n",
    "            [l1_size, l2_size], stddev=math.sqrt(2.0/(l1_size))))\n",
    "  layer2_biases = tf.Variable(tf.zeros([l2_size]))\n",
    "  layer3_weights = tf.Variable(tf.truncated_normal(\n",
    "            [l2_size, num_labels], stddev=math.sqrt(2.0/(l2_size))))\n",
    "  layer3_biases = tf.Variable(tf.zeros([num_labels]))\n",
    "  \n",
    "  # Model.\n",
    "  def model(data, use_dropout=False):\n",
    "    conv = tf.nn.conv2d(data, layerConv1_weights, [1, 1, 1, 1], padding='SAME')\n",
    "    hidden = tf.nn.relu(conv + layerConv1_biases)\n",
    "    pool = tf.nn.max_pool(hidden, [1, 2, 2, 1], [1, 2, 2, 1], padding='SAME')\n",
    "    \n",
    "    conv = tf.nn.conv2d(pool, layerConv2_weights, [1, 1, 1, 1], padding='SAME')\n",
    "    hidden = tf.nn.relu(conv + layerConv2_biases)\n",
    "\n",
    "    conv = tf.nn.conv2d(hidden, layerConv3_weights, [1, 1, 1, 1], padding='SAME')\n",
    "    hidden = tf.nn.relu(conv + layerConv3_biases)\n",
    "    pool = tf.nn.max_pool(hidden, [1, 2, 2, 1], [1, 2, 2, 1], padding='SAME')\n",
    "    \n",
    "    conv = tf.nn.conv2d(pool, layerConv4_weights, [1, 1, 1, 1], padding='SAME')\n",
    "    hidden = tf.nn.relu(conv + layerConv4_biases)\n",
    "    pool = tf.nn.max_pool(hidden, [1, 2, 2, 1], [1, 2, 2, 1], padding='SAME')\n",
    "   \n",
    "    conv = tf.nn.conv2d(pool, layerConv5_weights, [1, 1, 1, 1], padding='SAME')\n",
    "    hidden = tf.nn.relu(conv + layerConv5_biases)\n",
    "    pool = tf.nn.max_pool(hidden, [1, 2, 2, 1], [1, 2, 2, 1], padding='SAME')\n",
    "\n",
    "    shape = pool.get_shape().as_list()\n",
    "    reshape = tf.reshape(pool, [shape[0], shape[1] * shape[2] * shape[3]])\n",
    "    hidden = tf.nn.relu(tf.matmul(reshape, layer1_weights) + layer1_biases)\n",
    "    \n",
    "    if use_dropout:\n",
    "        hidden = tf.nn.dropout(hidden, 0.5)\n",
    "    \n",
    "    nn_hidden_layer = tf.matmul(hidden, layer2_weights) + layer2_biases\n",
    "    hidden = tf.nn.elu(nn_hidden_layer)\n",
    "    \n",
    "    if use_dropout:\n",
    "        hidden = tf.nn.dropout(hidden, 0.5)\n",
    "    return tf.matmul(hidden, layer3_weights) + layer3_biases\n",
    "  \n",
    "  # Training computation.\n",
    "  logits = model(tf_train_dataset, True)\n",
    "  loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits, tf_train_labels))\n",
    "\n",
    "  # L2 regularization for the fully connected parameters.\n",
    "  regularizers = (tf.nn.l2_loss(layer1_weights) + tf.nn.l2_loss(layer1_biases) +\n",
    "                  tf.nn.l2_loss(layer2_weights) + tf.nn.l2_loss(layer2_biases) +\n",
    "                  tf.nn.l2_loss(layer3_weights) + tf.nn.l2_loss(layer3_biases)) \n",
    "  # Add the regularization term to the loss.\n",
    "  loss += 1e-5 * regularizers\n",
    "    \n",
    "  # Optimizer.\n",
    "  global_step = tf.Variable(0)  # count the number of steps taken.\n",
    "  learning_rate = tf.train.exponential_decay(0.1, global_step*batch_size, train_size, 0.95, staircase=True)\n",
    "  optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(loss, global_step=global_step)\n",
    "  \n",
    "  # Predictions for the training, validation, and test data.\n",
    "  train_prediction = tf.nn.softmax(logits)\n",
    "  valid_prediction = tf.nn.softmax(model(tf_valid_dataset))\n",
    "  test_prediction = tf.nn.softmax(model(tf_test_dataset))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized\n",
      "Minibatch loss at step 0: 2.385883\n",
      "Minibatch learning rate at step 0: 0.100000\n",
      "Minibatch loss at step 200: 0.623882\n",
      "Minibatch learning rate at step 200: 0.100000\n",
      "Minibatch loss at step 400: 0.514789\n",
      "Minibatch learning rate at step 400: 0.100000\n",
      "Minibatch loss at step 600: 0.575648\n",
      "Minibatch learning rate at step 600: 0.100000\n",
      "Minibatch loss at step 800: 0.262868\n",
      "Minibatch learning rate at step 800: 0.100000\n",
      "Minibatch loss at step 1000: 0.563584\n",
      "Minibatch learning rate at step 1000: 0.100000\n",
      "Minibatch loss at step 1200: 0.298674\n",
      "Minibatch learning rate at step 1200: 0.100000\n",
      "Minibatch loss at step 1400: 0.277529\n",
      "Minibatch learning rate at step 1400: 0.100000\n",
      "Minibatch loss at step 1600: 0.435356\n",
      "Minibatch learning rate at step 1600: 0.095000\n",
      "Minibatch loss at step 1800: 0.421341\n",
      "Minibatch learning rate at step 1800: 0.095000\n",
      "Minibatch loss at step 2000: 0.283905\n",
      "Minibatch learning rate at step 2000: 0.095000\n",
      "Minibatch loss at step 2200: 0.421573\n",
      "Minibatch learning rate at step 2200: 0.095000\n",
      "Minibatch loss at step 2400: 0.344635\n",
      "Minibatch learning rate at step 2400: 0.095000\n",
      "Minibatch loss at step 2600: 0.422028\n",
      "Minibatch learning rate at step 2600: 0.095000\n",
      "Minibatch loss at step 2800: 0.264505\n",
      "Minibatch learning rate at step 2800: 0.095000\n",
      "Minibatch loss at step 3000: 0.327099\n",
      "Minibatch learning rate at step 3000: 0.095000\n",
      "Minibatch loss at step 3200: 0.230882\n",
      "Minibatch learning rate at step 3200: 0.090250\n",
      "Minibatch loss at step 3400: 0.240860\n",
      "Minibatch learning rate at step 3400: 0.090250\n",
      "Minibatch loss at step 3600: 0.363149\n",
      "Minibatch learning rate at step 3600: 0.090250\n",
      "Minibatch loss at step 3800: 0.194375\n",
      "Minibatch learning rate at step 3800: 0.090250\n",
      "Minibatch loss at step 4000: 0.247635\n",
      "Minibatch learning rate at step 4000: 0.090250\n",
      "Minibatch loss at step 4200: 0.353403\n",
      "Minibatch learning rate at step 4200: 0.090250\n",
      "Minibatch loss at step 4400: 0.198198\n",
      "Minibatch learning rate at step 4400: 0.090250\n",
      "Minibatch loss at step 4600: 0.289999\n",
      "Minibatch learning rate at step 4600: 0.090250\n",
      "Minibatch loss at step 4800: 0.281875\n",
      "Minibatch learning rate at step 4800: 0.085737\n",
      "Minibatch loss at step 5000: 0.285535\n",
      "Minibatch learning rate at step 5000: 0.085737\n",
      "Minibatch loss at step 5200: 0.275604\n",
      "Minibatch learning rate at step 5200: 0.085737\n",
      "Minibatch loss at step 5400: 0.256401\n",
      "Minibatch learning rate at step 5400: 0.085737\n",
      "Minibatch loss at step 5600: 0.144867\n",
      "Minibatch learning rate at step 5600: 0.085737\n",
      "Minibatch loss at step 5800: 0.247770\n",
      "Minibatch learning rate at step 5800: 0.085737\n",
      "Minibatch loss at step 6000: 0.398687\n",
      "Minibatch learning rate at step 6000: 0.085737\n",
      "Minibatch loss at step 6200: 0.214099\n",
      "Minibatch learning rate at step 6200: 0.085737\n",
      "Minibatch loss at step 6400: 0.216820\n",
      "Minibatch learning rate at step 6400: 0.081451\n",
      "Minibatch loss at step 6600: 0.269416\n",
      "Minibatch learning rate at step 6600: 0.081451\n",
      "Minibatch loss at step 6800: 0.258550\n",
      "Minibatch learning rate at step 6800: 0.081451\n",
      "Minibatch loss at step 7000: 0.346605\n",
      "Minibatch learning rate at step 7000: 0.081451\n",
      "Minibatch loss at step 7200: 0.391389\n",
      "Minibatch learning rate at step 7200: 0.081451\n",
      "Minibatch loss at step 7400: 0.220336\n",
      "Minibatch learning rate at step 7400: 0.081451\n",
      "Minibatch loss at step 7600: 0.201483\n",
      "Minibatch learning rate at step 7600: 0.081451\n",
      "Minibatch loss at step 7800: 0.226254\n",
      "Minibatch learning rate at step 7800: 0.081451\n",
      "Minibatch loss at step 8000: 0.332469\n",
      "Minibatch learning rate at step 8000: 0.077378\n",
      "Minibatch loss at step 8200: 0.167355\n",
      "Minibatch learning rate at step 8200: 0.077378\n",
      "Minibatch loss at step 8400: 0.220909\n",
      "Minibatch learning rate at step 8400: 0.077378\n",
      "Minibatch loss at step 8600: 0.138981\n",
      "Minibatch learning rate at step 8600: 0.077378\n",
      "Minibatch loss at step 8800: 0.159072\n",
      "Minibatch learning rate at step 8800: 0.077378\n",
      "Minibatch loss at step 9000: 0.238317\n",
      "Minibatch learning rate at step 9000: 0.077378\n",
      "Minibatch loss at step 9200: 0.203042\n",
      "Minibatch learning rate at step 9200: 0.077378\n",
      "Minibatch loss at step 9400: 0.202358\n",
      "Minibatch learning rate at step 9400: 0.073509\n",
      "Minibatch loss at step 9600: 0.265168\n",
      "Minibatch learning rate at step 9600: 0.073509\n",
      "Minibatch loss at step 9800: 0.147621\n",
      "Minibatch learning rate at step 9800: 0.073509\n",
      "Minibatch loss at step 10000: 0.205107\n",
      "Minibatch learning rate at step 10000: 0.073509\n",
      "Minibatch loss at step 10200: 0.288160\n",
      "Minibatch learning rate at step 10200: 0.073509\n",
      "Minibatch loss at step 10400: 0.134615\n",
      "Minibatch learning rate at step 10400: 0.073509\n",
      "Minibatch loss at step 10600: 0.214550\n",
      "Minibatch learning rate at step 10600: 0.073509\n",
      "Minibatch loss at step 10800: 0.140385\n",
      "Minibatch learning rate at step 10800: 0.073509\n",
      "Minibatch loss at step 11000: 0.157659\n",
      "Minibatch learning rate at step 11000: 0.069834\n",
      "Minibatch loss at step 11200: 0.225715\n",
      "Minibatch learning rate at step 11200: 0.069834\n",
      "Minibatch loss at step 11400: 0.247150\n",
      "Minibatch learning rate at step 11400: 0.069834\n",
      "Minibatch loss at step 11600: 0.130475\n",
      "Minibatch learning rate at step 11600: 0.069834\n",
      "Minibatch loss at step 11800: 0.186041\n",
      "Minibatch learning rate at step 11800: 0.069834\n",
      "Minibatch loss at step 12000: 0.232107\n",
      "Minibatch learning rate at step 12000: 0.069834\n",
      "Minibatch loss at step 12200: 0.082065\n",
      "Minibatch learning rate at step 12200: 0.069834\n",
      "Minibatch loss at step 12400: 0.123814\n",
      "Minibatch learning rate at step 12400: 0.069834\n",
      "Minibatch loss at step 12600: 0.132848\n",
      "Minibatch learning rate at step 12600: 0.066342\n",
      "Minibatch loss at step 12800: 0.118287\n",
      "Minibatch learning rate at step 12800: 0.066342\n",
      "Minibatch loss at step 13000: 0.236444\n",
      "Minibatch learning rate at step 13000: 0.066342\n",
      "Minibatch loss at step 13200: 0.164531\n",
      "Minibatch learning rate at step 13200: 0.066342\n",
      "Minibatch loss at step 13400: 0.075548\n",
      "Minibatch learning rate at step 13400: 0.066342\n",
      "Minibatch loss at step 13600: 0.146995\n",
      "Minibatch learning rate at step 13600: 0.066342\n",
      "Minibatch loss at step 13800: 0.095930\n",
      "Minibatch learning rate at step 13800: 0.066342\n",
      "Minibatch loss at step 14000: 0.256279\n",
      "Minibatch learning rate at step 14000: 0.066342\n",
      "Minibatch loss at step 14200: 0.140133\n",
      "Minibatch learning rate at step 14200: 0.063025\n",
      "Minibatch loss at step 14400: 0.306229\n",
      "Minibatch learning rate at step 14400: 0.063025\n",
      "Minibatch loss at step 14600: 0.071681\n",
      "Minibatch learning rate at step 14600: 0.063025\n",
      "Minibatch loss at step 14800: 0.155283\n",
      "Minibatch learning rate at step 14800: 0.063025\n",
      "Minibatch loss at step 15000: 0.162142\n",
      "Minibatch learning rate at step 15000: 0.063025\n",
      "Minibatch loss at step 15200: 0.203889\n",
      "Minibatch learning rate at step 15200: 0.063025\n",
      "Minibatch loss at step 15400: 0.162508\n",
      "Minibatch learning rate at step 15400: 0.063025\n",
      "Minibatch loss at step 15600: 0.159858\n",
      "Minibatch learning rate at step 15600: 0.063025\n",
      "Minibatch loss at step 15800: 0.146738\n",
      "Minibatch learning rate at step 15800: 0.059874\n",
      "Minibatch loss at step 16000: 0.120760\n",
      "Minibatch learning rate at step 16000: 0.059874\n",
      "Minibatch loss at step 16200: 0.111973\n",
      "Minibatch learning rate at step 16200: 0.059874\n",
      "Minibatch loss at step 16400: 0.226542\n",
      "Minibatch learning rate at step 16400: 0.059874\n",
      "Minibatch loss at step 16600: 0.205527\n",
      "Minibatch learning rate at step 16600: 0.059874\n",
      "Minibatch loss at step 16800: 0.200091\n",
      "Minibatch learning rate at step 16800: 0.059874\n",
      "Minibatch loss at step 17000: 0.091516\n",
      "Minibatch learning rate at step 17000: 0.059874\n",
      "Minibatch loss at step 17200: 0.171545\n",
      "Minibatch learning rate at step 17200: 0.056880\n",
      "Minibatch loss at step 17400: 0.098776\n",
      "Minibatch learning rate at step 17400: 0.056880\n",
      "Minibatch loss at step 17600: 0.144548\n",
      "Minibatch learning rate at step 17600: 0.056880\n",
      "Minibatch loss at step 17800: 0.178331\n",
      "Minibatch learning rate at step 17800: 0.056880\n",
      "Minibatch loss at step 18000: 0.095622\n",
      "Minibatch learning rate at step 18000: 0.056880\n",
      "Minibatch loss at step 18200: 0.242755\n",
      "Minibatch learning rate at step 18200: 0.056880\n",
      "Minibatch loss at step 18400: 0.111582\n",
      "Minibatch learning rate at step 18400: 0.056880\n",
      "Minibatch loss at step 18600: 0.122791\n",
      "Minibatch learning rate at step 18600: 0.056880\n",
      "Minibatch loss at step 18800: 0.155595\n",
      "Minibatch learning rate at step 18800: 0.054036\n",
      "Minibatch loss at step 19000: 0.091528\n",
      "Minibatch learning rate at step 19000: 0.054036\n",
      "Minibatch loss at step 19200: 0.208843\n",
      "Minibatch learning rate at step 19200: 0.054036\n",
      "Minibatch loss at step 19400: 0.110906\n",
      "Minibatch learning rate at step 19400: 0.054036\n",
      "Minibatch loss at step 19600: 0.142352\n",
      "Minibatch learning rate at step 19600: 0.054036\n",
      "Minibatch loss at step 19800: 0.114738\n",
      "Minibatch learning rate at step 19800: 0.054036\n",
      "Minibatch loss at step 20000: 0.157540\n",
      "Minibatch learning rate at step 20000: 0.054036\n",
      "Minibatch loss at step 20200: 0.157681\n",
      "Minibatch learning rate at step 20200: 0.054036\n",
      "Minibatch loss at step 20400: 0.158231\n",
      "Minibatch learning rate at step 20400: 0.051334\n",
      "Minibatch loss at step 20600: 0.130104\n",
      "Minibatch learning rate at step 20600: 0.051334\n",
      "Minibatch loss at step 20800: 0.230867\n",
      "Minibatch learning rate at step 20800: 0.051334\n",
      "Minibatch loss at step 21000: 0.092592\n",
      "Minibatch learning rate at step 21000: 0.051334\n",
      "Minibatch loss at step 21200: 0.122398\n",
      "Minibatch learning rate at step 21200: 0.051334\n",
      "Minibatch loss at step 21400: 0.131108\n",
      "Minibatch learning rate at step 21400: 0.051334\n",
      "Minibatch loss at step 21600: 0.145214\n",
      "Minibatch learning rate at step 21600: 0.051334\n",
      "Minibatch loss at step 21800: 0.190913\n",
      "Minibatch learning rate at step 21800: 0.051334\n",
      "Minibatch loss at step 22000: 0.082440\n",
      "Minibatch learning rate at step 22000: 0.048767\n",
      "Minibatch loss at step 22200: 0.108180\n",
      "Minibatch learning rate at step 22200: 0.048767\n",
      "Minibatch loss at step 22400: 0.094053\n",
      "Minibatch learning rate at step 22400: 0.048767\n",
      "Minibatch loss at step 22600: 0.239886\n",
      "Minibatch learning rate at step 22600: 0.048767\n",
      "Minibatch loss at step 22800: 0.114058\n",
      "Minibatch learning rate at step 22800: 0.048767\n",
      "Minibatch loss at step 23000: 0.132014\n",
      "Minibatch learning rate at step 23000: 0.048767\n",
      "Minibatch loss at step 23200: 0.081452\n",
      "Minibatch learning rate at step 23200: 0.048767\n",
      "Minibatch loss at step 23400: 0.065609\n",
      "Minibatch learning rate at step 23400: 0.048767\n",
      "Minibatch loss at step 23600: 0.203839\n",
      "Minibatch learning rate at step 23600: 0.046329\n",
      "Minibatch loss at step 23800: 0.087438\n",
      "Minibatch learning rate at step 23800: 0.046329\n",
      "Minibatch loss at step 24000: 0.114176\n",
      "Minibatch learning rate at step 24000: 0.046329\n",
      "Minibatch loss at step 24200: 0.113604\n",
      "Minibatch learning rate at step 24200: 0.046329\n",
      "Minibatch loss at step 24400: 0.151664\n",
      "Minibatch learning rate at step 24400: 0.046329\n",
      "Minibatch loss at step 24600: 0.086359\n",
      "Minibatch learning rate at step 24600: 0.046329\n",
      "Minibatch loss at step 24800: 0.091095\n",
      "Minibatch learning rate at step 24800: 0.046329\n",
      "Minibatch loss at step 25000: 0.101324\n",
      "Minibatch learning rate at step 25000: 0.044013\n",
      "Minibatch loss at step 25200: 0.078406\n",
      "Minibatch learning rate at step 25200: 0.044013\n",
      "Minibatch loss at step 25400: 0.123165\n",
      "Minibatch learning rate at step 25400: 0.044013\n",
      "Minibatch loss at step 25600: 0.040226\n",
      "Minibatch learning rate at step 25600: 0.044013\n",
      "Minibatch loss at step 25800: 0.049217\n",
      "Minibatch learning rate at step 25800: 0.044013\n",
      "Minibatch loss at step 26000: 0.034699\n",
      "Minibatch learning rate at step 26000: 0.044013\n",
      "Minibatch loss at step 26200: 0.068983\n",
      "Minibatch learning rate at step 26200: 0.044013\n",
      "Minibatch loss at step 26400: 0.085033\n",
      "Minibatch learning rate at step 26400: 0.044013\n",
      "Minibatch loss at step 26600: 0.147190\n",
      "Minibatch learning rate at step 26600: 0.041812\n",
      "Minibatch loss at step 26800: 0.103221\n",
      "Minibatch learning rate at step 26800: 0.041812\n",
      "Minibatch loss at step 27000: 0.111204\n",
      "Minibatch learning rate at step 27000: 0.041812\n",
      "Minibatch loss at step 27200: 0.071973\n",
      "Minibatch learning rate at step 27200: 0.041812\n",
      "Minibatch loss at step 27400: 0.086127\n",
      "Minibatch learning rate at step 27400: 0.041812\n",
      "Minibatch loss at step 27600: 0.102076\n",
      "Minibatch learning rate at step 27600: 0.041812\n",
      "Minibatch loss at step 27800: 0.135241\n",
      "Minibatch learning rate at step 27800: 0.041812\n",
      "Minibatch loss at step 28000: 0.071494\n",
      "Minibatch learning rate at step 28000: 0.041812\n",
      "Minibatch loss at step 28200: 0.059799\n",
      "Minibatch learning rate at step 28200: 0.039721\n",
      "Minibatch loss at step 28400: 0.065403\n",
      "Minibatch learning rate at step 28400: 0.039721\n",
      "Minibatch loss at step 28600: 0.132148\n",
      "Minibatch learning rate at step 28600: 0.039721\n",
      "Minibatch loss at step 28800: 0.054041\n",
      "Minibatch learning rate at step 28800: 0.039721\n",
      "Minibatch loss at step 29000: 0.069131\n",
      "Minibatch learning rate at step 29000: 0.039721\n",
      "Minibatch loss at step 29200: 0.035953\n",
      "Minibatch learning rate at step 29200: 0.039721\n",
      "Minibatch loss at step 29400: 0.047575\n",
      "Minibatch learning rate at step 29400: 0.039721\n",
      "Minibatch loss at step 29600: 0.101635\n",
      "Minibatch learning rate at step 29600: 0.039721\n",
      "Minibatch loss at step 29800: 0.052270\n",
      "Minibatch learning rate at step 29800: 0.037735\n",
      "Minibatch loss at step 30000: 0.049599\n",
      "Minibatch learning rate at step 30000: 0.037735\n",
      "Minibatch loss at step 30200: 0.067035\n",
      "Minibatch learning rate at step 30200: 0.037735\n",
      "Minibatch loss at step 30400: 0.052565\n",
      "Minibatch learning rate at step 30400: 0.037735\n",
      "Minibatch loss at step 30600: 0.075232\n",
      "Minibatch learning rate at step 30600: 0.037735\n",
      "Minibatch loss at step 30800: 0.100379\n",
      "Minibatch learning rate at step 30800: 0.037735\n",
      "Minibatch loss at step 31000: 0.137598\n",
      "Minibatch learning rate at step 31000: 0.037735\n",
      "Minibatch loss at step 31200: 0.042895\n",
      "Minibatch learning rate at step 31200: 0.037735\n",
      "Minibatch loss at step 31400: 0.135370\n",
      "Minibatch learning rate at step 31400: 0.035849\n",
      "Minibatch loss at step 31600: 0.058345\n",
      "Minibatch learning rate at step 31600: 0.035849\n",
      "Minibatch loss at step 31800: 0.130151\n",
      "Minibatch learning rate at step 31800: 0.035849\n",
      "Minibatch loss at step 32000: 0.064382\n",
      "Minibatch learning rate at step 32000: 0.035849\n",
      "Minibatch loss at step 32200: 0.078964\n",
      "Minibatch learning rate at step 32200: 0.035849\n",
      "Minibatch loss at step 32400: 0.069578\n",
      "Minibatch learning rate at step 32400: 0.035849\n",
      "Minibatch loss at step 32600: 0.039996\n",
      "Minibatch learning rate at step 32600: 0.035849\n",
      "Minibatch loss at step 32800: 0.017051\n",
      "Minibatch learning rate at step 32800: 0.035849\n",
      "Minibatch loss at step 33000: 0.072912\n",
      "Minibatch learning rate at step 33000: 0.034056\n",
      "Minibatch loss at step 33200: 0.043218\n",
      "Minibatch learning rate at step 33200: 0.034056\n",
      "Minibatch loss at step 33400: 0.051023\n",
      "Minibatch learning rate at step 33400: 0.034056\n",
      "Minibatch loss at step 33600: 0.060504\n",
      "Minibatch learning rate at step 33600: 0.034056\n",
      "Minibatch loss at step 33800: 0.037521\n",
      "Minibatch learning rate at step 33800: 0.034056\n",
      "Minibatch loss at step 34000: 0.150343\n",
      "Minibatch learning rate at step 34000: 0.034056\n",
      "Minibatch loss at step 34200: 0.088765\n",
      "Minibatch learning rate at step 34200: 0.034056\n",
      "Minibatch loss at step 34400: 0.052219\n",
      "Minibatch learning rate at step 34400: 0.032353\n",
      "Minibatch loss at step 34600: 0.047420\n",
      "Minibatch learning rate at step 34600: 0.032353\n",
      "Minibatch loss at step 34800: 0.143951\n",
      "Minibatch learning rate at step 34800: 0.032353\n",
      "Minibatch loss at step 35000: 0.016918\n",
      "Minibatch learning rate at step 35000: 0.032353\n",
      "Minibatch loss at step 35200: 0.095238\n",
      "Minibatch learning rate at step 35200: 0.032353\n",
      "Minibatch loss at step 35400: 0.054706\n",
      "Minibatch learning rate at step 35400: 0.032353\n",
      "Minibatch loss at step 35600: 0.019111\n",
      "Minibatch learning rate at step 35600: 0.032353\n",
      "Minibatch loss at step 35800: 0.055228\n",
      "Minibatch learning rate at step 35800: 0.032353\n",
      "Minibatch loss at step 36000: 0.111953\n",
      "Minibatch learning rate at step 36000: 0.030736\n",
      "Minibatch loss at step 36200: 0.088397\n",
      "Minibatch learning rate at step 36200: 0.030736\n",
      "Minibatch loss at step 36400: 0.076197\n",
      "Minibatch learning rate at step 36400: 0.030736\n",
      "Minibatch loss at step 36600: 0.101517\n",
      "Minibatch learning rate at step 36600: 0.030736\n",
      "Minibatch loss at step 36800: 0.043499\n",
      "Minibatch learning rate at step 36800: 0.030736\n",
      "Minibatch loss at step 37000: 0.088022\n",
      "Minibatch learning rate at step 37000: 0.030736\n",
      "Minibatch loss at step 37200: 0.028747\n",
      "Minibatch learning rate at step 37200: 0.030736\n",
      "Minibatch loss at step 37400: 0.062433\n",
      "Minibatch learning rate at step 37400: 0.030736\n",
      "Minibatch loss at step 37600: 0.150801\n",
      "Minibatch learning rate at step 37600: 0.029199\n",
      "Minibatch loss at step 37800: 0.052014\n",
      "Minibatch learning rate at step 37800: 0.029199\n",
      "Minibatch loss at step 38000: 0.054087\n",
      "Minibatch learning rate at step 38000: 0.029199\n",
      "Minibatch loss at step 38200: 0.053537\n",
      "Minibatch learning rate at step 38200: 0.029199\n",
      "Minibatch loss at step 38400: 0.074879\n",
      "Minibatch learning rate at step 38400: 0.029199\n",
      "Minibatch loss at step 38600: 0.020988\n",
      "Minibatch learning rate at step 38600: 0.029199\n",
      "Minibatch loss at step 38800: 0.014948\n",
      "Minibatch learning rate at step 38800: 0.029199\n",
      "Minibatch loss at step 39000: 0.059462\n",
      "Minibatch learning rate at step 39000: 0.029199\n",
      "Minibatch loss at step 39200: 0.031948\n",
      "Minibatch learning rate at step 39200: 0.027739\n",
      "Minibatch loss at step 39400: 0.071289\n",
      "Minibatch learning rate at step 39400: 0.027739\n",
      "Minibatch loss at step 39600: 0.035750\n",
      "Minibatch learning rate at step 39600: 0.027739\n",
      "Minibatch loss at step 39800: 0.082259\n",
      "Minibatch learning rate at step 39800: 0.027739\n",
      "Minibatch loss at step 40000: 0.026708\n",
      "Minibatch learning rate at step 40000: 0.027739\n",
      "Minibatch loss at step 40200: 0.034970\n",
      "Minibatch learning rate at step 40200: 0.027739\n",
      "Minibatch loss at step 40400: 0.105210\n",
      "Minibatch learning rate at step 40400: 0.027739\n",
      "Minibatch loss at step 40600: 0.065547\n",
      "Minibatch learning rate at step 40600: 0.027739\n",
      "Minibatch loss at step 40800: 0.072122\n",
      "Minibatch learning rate at step 40800: 0.026352\n",
      "Minibatch loss at step 41000: 0.052128\n",
      "Minibatch learning rate at step 41000: 0.026352\n",
      "Minibatch loss at step 41200: 0.017703\n",
      "Minibatch learning rate at step 41200: 0.026352\n",
      "Minibatch loss at step 41400: 0.051428\n",
      "Minibatch learning rate at step 41400: 0.026352\n",
      "Minibatch loss at step 41600: 0.041352\n",
      "Minibatch learning rate at step 41600: 0.026352\n",
      "Minibatch loss at step 41800: 0.055085\n",
      "Minibatch learning rate at step 41800: 0.026352\n",
      "Minibatch loss at step 42000: 0.083452\n",
      "Minibatch learning rate at step 42000: 0.026352\n",
      "Minibatch loss at step 42200: 0.043532\n",
      "Minibatch learning rate at step 42200: 0.025034\n",
      "Minibatch loss at step 42400: 0.099534\n",
      "Minibatch learning rate at step 42400: 0.025034\n",
      "Minibatch loss at step 42600: 0.050054\n",
      "Minibatch learning rate at step 42600: 0.025034\n",
      "Minibatch loss at step 42800: 0.087136\n",
      "Minibatch learning rate at step 42800: 0.025034\n",
      "Minibatch loss at step 43000: 0.013703\n",
      "Minibatch learning rate at step 43000: 0.025034\n",
      "Minibatch loss at step 43200: 0.025570\n",
      "Minibatch learning rate at step 43200: 0.025034\n",
      "Minibatch loss at step 43400: 0.025914\n",
      "Minibatch learning rate at step 43400: 0.025034\n",
      "Minibatch loss at step 43600: 0.055036\n",
      "Minibatch learning rate at step 43600: 0.025034\n",
      "Minibatch loss at step 43800: 0.063195\n",
      "Minibatch learning rate at step 43800: 0.023783\n",
      "Minibatch loss at step 44000: 0.014408\n",
      "Minibatch learning rate at step 44000: 0.023783\n",
      "Minibatch loss at step 44200: 0.037039\n",
      "Minibatch learning rate at step 44200: 0.023783\n",
      "Minibatch loss at step 44400: 0.022541\n",
      "Minibatch learning rate at step 44400: 0.023783\n",
      "Minibatch loss at step 44600: 0.019577\n",
      "Minibatch learning rate at step 44600: 0.023783\n",
      "Minibatch loss at step 44800: 0.056849\n",
      "Minibatch learning rate at step 44800: 0.023783\n",
      "Minibatch loss at step 45000: 0.016016\n",
      "Minibatch learning rate at step 45000: 0.023783\n",
      "Minibatch loss at step 45200: 0.022286\n",
      "Minibatch learning rate at step 45200: 0.023783\n",
      "Minibatch loss at step 45400: 0.052822\n",
      "Minibatch learning rate at step 45400: 0.022594\n",
      "Minibatch loss at step 45600: 0.019955\n",
      "Minibatch learning rate at step 45600: 0.022594\n",
      "Minibatch loss at step 45800: 0.041144\n",
      "Minibatch learning rate at step 45800: 0.022594\n",
      "Minibatch loss at step 46000: 0.030606\n",
      "Minibatch learning rate at step 46000: 0.022594\n",
      "Minibatch loss at step 46200: 0.056359\n",
      "Minibatch learning rate at step 46200: 0.022594\n",
      "Minibatch loss at step 46400: 0.129126\n",
      "Minibatch learning rate at step 46400: 0.022594\n",
      "Minibatch loss at step 46600: 0.021322\n",
      "Minibatch learning rate at step 46600: 0.022594\n",
      "Minibatch loss at step 46800: 0.083862\n",
      "Minibatch learning rate at step 46800: 0.022594\n",
      "Minibatch loss at step 47000: 0.030524\n",
      "Minibatch learning rate at step 47000: 0.021464\n",
      "Minibatch loss at step 47200: 0.024538\n",
      "Minibatch learning rate at step 47200: 0.021464\n",
      "Minibatch loss at step 47400: 0.026041\n",
      "Minibatch learning rate at step 47400: 0.021464\n",
      "Minibatch loss at step 47600: 0.054245\n",
      "Minibatch learning rate at step 47600: 0.021464\n",
      "Minibatch loss at step 47800: 0.042985\n",
      "Minibatch learning rate at step 47800: 0.021464\n",
      "Minibatch loss at step 48000: 0.020299\n",
      "Minibatch learning rate at step 48000: 0.021464\n",
      "Minibatch loss at step 48200: 0.031816\n",
      "Minibatch learning rate at step 48200: 0.021464\n",
      "Minibatch loss at step 48400: 0.056007\n",
      "Minibatch learning rate at step 48400: 0.021464\n",
      "Minibatch loss at step 48600: 0.041209\n",
      "Minibatch learning rate at step 48600: 0.020391\n",
      "Minibatch loss at step 48800: 0.048542\n",
      "Minibatch learning rate at step 48800: 0.020391\n",
      "Minibatch loss at step 49000: 0.050116\n",
      "Minibatch learning rate at step 49000: 0.020391\n",
      "Minibatch loss at step 49200: 0.010150\n",
      "Minibatch learning rate at step 49200: 0.020391\n",
      "Minibatch loss at step 49400: 0.036864\n",
      "Minibatch learning rate at step 49400: 0.020391\n",
      "Minibatch loss at step 49600: 0.030564\n",
      "Minibatch learning rate at step 49600: 0.020391\n",
      "Minibatch loss at step 49800: 0.069661\n",
      "Minibatch learning rate at step 49800: 0.020391\n",
      "Minibatch loss at step 50000: 0.015785\n",
      "Minibatch learning rate at step 50000: 0.019371\n",
      "Test accuracy: 97.3%\n"
     ]
    }
   ],
   "source": [
    "num_steps = 50001\n",
    "\n",
    "with tf.Session(graph=graph) as session:\n",
    "  tf.initialize_all_variables().run()\n",
    "  lossVec = []\n",
    "  trainAcc = []\n",
    "  validAcc = []\n",
    "  lrVec = []\n",
    "  print('Initialized')\n",
    "  for step in range(num_steps):\n",
    "    offset = (step * batch_size) % (train_labels.shape[0] - batch_size)\n",
    "    batch_data = train_dataset[offset:(offset + batch_size), :, :, :]\n",
    "    batch_labels = train_labels[offset:(offset + batch_size), :]\n",
    "    feed_dict = {tf_train_dataset : batch_data, tf_train_labels : batch_labels}\n",
    "    _, l, lr, predictions = session.run([optimizer, loss, learning_rate, train_prediction], feed_dict=feed_dict)\n",
    "    lossVec.append(l)\n",
    "    lrVec.append(lr)\n",
    "    if (step % 200 == 0):\n",
    "      print(\"Minibatch loss at step %d: %f\" % (step, l))\n",
    "      print(\"Minibatch learning rate at step %d: %f\" % (step, lr))\n",
    "      trainAcc.append(accuracy(predictions, batch_labels))\n",
    "      validAcc.append(accuracy(valid_prediction.eval(), valid_labels))\n",
    "  print('Test accuracy: %.1f%%' % accuracy(test_prediction.eval(), test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Saving the objects:\n",
    "with open('Ex_9.pickle', 'w') as f:\n",
    "    pickle.dump([lossVec, lrVec, trainAcc, validAcc], f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Getting back the objects:\n",
    "with open('Ex_9.pickle') as f:\n",
    "    lossVec, lrVec, trainAcc, validAcc = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ex 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import math as math\n",
    "batch_size = 64\n",
    "patch_size = 4\n",
    "depth = 16\n",
    "l1_size = 2048\n",
    "l2_size = 2048\n",
    "SEED = 66478\n",
    "train_size = train_labels.shape[0]\n",
    "\n",
    "graph = tf.Graph()\n",
    "\n",
    "with graph.as_default():\n",
    "\n",
    "  # Input data.\n",
    "  tf_train_dataset = tf.placeholder(tf.float32, shape=(batch_size, image_size, image_size, num_channels))\n",
    "  tf_train_labels = tf.placeholder(tf.float32, shape=(batch_size, num_labels))\n",
    "  tf_valid_dataset = tf.constant(valid_dataset)\n",
    "  tf_test_dataset = tf.constant(test_dataset)\n",
    "  \n",
    "  # Variables.\n",
    "  layerConv1_weights = tf.Variable(tf.truncated_normal(\n",
    "            [4, 4, num_channels, depth], stddev=0.1, seed=SEED))\n",
    "  layerConv1_biases = tf.Variable(tf.zeros([depth]))\n",
    "  layerConv2_weights = tf.Variable(tf.truncated_normal(\n",
    "            [4, 4, depth, depth*2], stddev=0.1, seed=SEED))\n",
    "  layerConv2_biases = tf.Variable(tf.zeros([depth*2]))\n",
    "  layerConv3_weights = tf.Variable(tf.truncated_normal(\n",
    "            [3, 3, depth*2, depth*4], stddev=0.03, seed=SEED))\n",
    "  layerConv3_biases = tf.Variable(tf.zeros([depth*4]))\n",
    "  layerConv4_weights = tf.Variable(tf.truncated_normal(\n",
    "            [3, 3, depth*4, depth*4], stddev=0.03, seed=SEED))\n",
    "  layerConv4_biases = tf.Variable(tf.zeros([depth*4]))\n",
    "  layerConv5_weights = tf.Variable(tf.truncated_normal(\n",
    "            [3, 3, depth*4, depth*16], stddev=0.03, seed=SEED))\n",
    "  layerConv5_biases = tf.Variable(tf.zeros([depth*16]))\n",
    "\n",
    "  layer1_weights = tf.Variable(tf.truncated_normal([image_size//7*image_size//7*(depth*4), l1_size], stddev=0.03, seed=SEED))\n",
    "  layer1_biases = tf.Variable(tf.zeros([l1_size]))\n",
    "  layer2_weights = tf.Variable(tf.truncated_normal([l1_size, l2_size], stddev=0.05, seed=SEED))\n",
    "  layer2_biases = tf.Variable(tf.zeros([l2_size]))\n",
    "  layer3_weights = tf.Variable(tf.truncated_normal([l2_size, num_labels], stddev=0.1, seed=SEED))\n",
    "  layer3_biases = tf.Variable(tf.zeros([num_labels]))\n",
    "  \n",
    "  # Model.\n",
    "  def model(data, use_dropout=False):\n",
    "    conv = tf.nn.conv2d(data, layerConv1_weights, [1, 1, 1, 1], padding='SAME')\n",
    "    hidden = tf.nn.elu(conv + layerConv1_biases)\n",
    "    pool = tf.nn.max_pool(hidden, [1, 2, 2, 1], [1, 2, 2, 1], padding='SAME')\n",
    "    \n",
    "    conv = tf.nn.conv2d(pool, layerConv2_weights, [1, 1, 1, 1], padding='SAME')\n",
    "    hidden = tf.nn.elu(conv + layerConv2_biases)\n",
    "    pool = tf.nn.max_pool(hidden, [1, 2, 2, 1], [1, 2, 2, 1], padding='SAME')\n",
    "\n",
    "    conv = tf.nn.conv2d(hidden, layerConv3_weights, [1, 1, 1, 1], padding='SAME')\n",
    "    hidden = tf.nn.elu(conv + layerConv3_biases)\n",
    "    pool = tf.nn.max_pool(hidden, [1, 2, 2, 1], [1, 2, 2, 1], padding='SAME')\n",
    "    \n",
    "    conv = tf.nn.conv2d(pool, layerConv4_weights, [1, 1, 1, 1], padding='SAME')\n",
    "    hidden = tf.nn.relu(conv + layerConv4_biases)\n",
    "    pool = tf.nn.max_pool(hidden, [1, 2, 2, 1], [1, 2, 2, 1], padding='SAME')\n",
    "   \n",
    "    conv = tf.nn.conv2d(pool, layerConv5_weights, [1, 1, 1, 1], padding='SAME')\n",
    "    hidden = tf.nn.elu(conv + layerConv5_biases)\n",
    "    pool = tf.nn.max_pool(hidden, [1, 2, 2, 1], [1, 2, 2, 1], padding='SAME')\n",
    "\n",
    "    shape = pool.get_shape().as_list()\n",
    "    reshape = tf.reshape(pool, [shape[0], shape[1] * shape[2] * shape[3]])\n",
    "    hidden = tf.nn.elu(tf.matmul(reshape, layer1_weights) + layer1_biases)\n",
    "    \n",
    "    if use_dropout:\n",
    "        hidden = tf.nn.dropout(hidden, 0.5, seed=SEED)\n",
    "    \n",
    "    nn_hidden_layer = tf.matmul(hidden, layer2_weights) + layer2_biases\n",
    "    hidden = tf.nn.elu(nn_hidden_layer)\n",
    "    \n",
    "    if use_dropout:\n",
    "        hidden = tf.nn.dropout(hidden, 0.5, seed=SEED)\n",
    "    return tf.matmul(hidden, layer3_weights) + layer3_biases\n",
    "  \n",
    "  # Training computation.\n",
    "  logits = model(tf_train_dataset, True)\n",
    "  loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits, tf_train_labels))\n",
    "\n",
    "  # L2 regularization for the fully connected parameters.\n",
    "  regularizers = (tf.nn.l2_loss(layer1_weights) + tf.nn.l2_loss(layer1_biases) +\n",
    "                  tf.nn.l2_loss(layer2_weights) + tf.nn.l2_loss(layer2_biases) +\n",
    "                  tf.nn.l2_loss(layer3_weights) + tf.nn.l2_loss(layer3_biases)) \n",
    "  # Add the regularization term to the loss.\n",
    "  #loss += 1e-5 * regularizers\n",
    "    \n",
    "  # Optimizer.\n",
    "  global_step = tf.Variable(0)  # count the number of steps taken.\n",
    "  learning_rate = tf.train.exponential_decay(\n",
    "      0.1,                # Base learning rate.\n",
    "      global_step,  # Current index into the dataset.\n",
    "      3000,          # Decay step.\n",
    "      0.95,                # Decay rate.\n",
    "      staircase=True)\n",
    "  optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(loss, global_step=global_step)\n",
    "  \n",
    "  # Predictions for the training, validation, and test data.\n",
    "  train_prediction = tf.nn.softmax(logits)\n",
    "  valid_prediction = tf.nn.softmax(model(tf_valid_dataset))\n",
    "  test_prediction = tf.nn.softmax(model(tf_test_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized\n",
      "Minibatch loss at step 0: 2.332487\n",
      "Minibatch learning rate at step 0: 0.100000\n",
      "Train accuracy at step 0: 9.375000\n",
      "Valid accuracy at step 0: 13.640000\n",
      "Minibatch loss at step 200: 0.610644\n",
      "Minibatch learning rate at step 200: 0.100000\n",
      "Train accuracy at step 200: 79.687500\n",
      "Valid accuracy at step 200: 85.140000\n",
      "Minibatch loss at step 400: 0.935725\n",
      "Minibatch learning rate at step 400: 0.100000\n",
      "Train accuracy at step 400: 78.125000\n",
      "Valid accuracy at step 400: 86.030000\n",
      "Minibatch loss at step 600: 0.488342\n",
      "Minibatch learning rate at step 600: 0.100000\n",
      "Train accuracy at step 600: 85.937500\n",
      "Valid accuracy at step 600: 86.800000\n",
      "Minibatch loss at step 800: 0.374529\n",
      "Minibatch learning rate at step 800: 0.100000\n",
      "Train accuracy at step 800: 89.062500\n",
      "Valid accuracy at step 800: 87.680000\n",
      "Minibatch loss at step 1000: 0.326039\n",
      "Minibatch learning rate at step 1000: 0.100000\n",
      "Train accuracy at step 1000: 87.500000\n",
      "Valid accuracy at step 1000: 88.100000\n",
      "Minibatch loss at step 1200: 0.347635\n",
      "Minibatch learning rate at step 1200: 0.100000\n",
      "Train accuracy at step 1200: 90.625000\n",
      "Valid accuracy at step 1200: 88.290000\n",
      "Minibatch loss at step 1400: 0.594372\n",
      "Minibatch learning rate at step 1400: 0.100000\n",
      "Train accuracy at step 1400: 89.062500\n",
      "Valid accuracy at step 1400: 88.340000\n",
      "Minibatch loss at step 1600: 0.135465\n",
      "Minibatch learning rate at step 1600: 0.100000\n",
      "Train accuracy at step 1600: 93.750000\n",
      "Valid accuracy at step 1600: 88.280000\n",
      "Minibatch loss at step 1800: 0.332666\n",
      "Minibatch learning rate at step 1800: 0.100000\n",
      "Train accuracy at step 1800: 89.062500\n",
      "Valid accuracy at step 1800: 88.530000\n",
      "Minibatch loss at step 2000: 0.322379\n",
      "Minibatch learning rate at step 2000: 0.100000\n",
      "Train accuracy at step 2000: 92.187500\n",
      "Valid accuracy at step 2000: 88.120000\n",
      "Minibatch loss at step 2200: 0.421466\n",
      "Minibatch learning rate at step 2200: 0.100000\n",
      "Train accuracy at step 2200: 90.625000\n",
      "Valid accuracy at step 2200: 88.980000\n",
      "Minibatch loss at step 2400: 0.411495\n",
      "Minibatch learning rate at step 2400: 0.100000\n",
      "Train accuracy at step 2400: 87.500000\n",
      "Valid accuracy at step 2400: 88.520000\n",
      "Minibatch loss at step 2600: 0.228093\n",
      "Minibatch learning rate at step 2600: 0.100000\n",
      "Train accuracy at step 2600: 93.750000\n",
      "Valid accuracy at step 2600: 88.890000\n",
      "Minibatch loss at step 2800: 0.451926\n",
      "Minibatch learning rate at step 2800: 0.100000\n",
      "Train accuracy at step 2800: 89.062500\n",
      "Valid accuracy at step 2800: 89.670000\n",
      "Minibatch loss at step 3000: 0.237471\n",
      "Minibatch learning rate at step 3000: 0.095000\n",
      "Train accuracy at step 3000: 92.187500\n",
      "Valid accuracy at step 3000: 88.920000\n",
      "Minibatch loss at step 3200: 0.221515\n",
      "Minibatch learning rate at step 3200: 0.095000\n",
      "Train accuracy at step 3200: 92.187500\n",
      "Valid accuracy at step 3200: 90.040000\n",
      "Minibatch loss at step 3400: 0.243026\n",
      "Minibatch learning rate at step 3400: 0.095000\n",
      "Train accuracy at step 3400: 93.750000\n",
      "Valid accuracy at step 3400: 89.930000\n",
      "Minibatch loss at step 3600: 0.418793\n",
      "Minibatch learning rate at step 3600: 0.095000\n",
      "Train accuracy at step 3600: 90.625000\n",
      "Valid accuracy at step 3600: 90.130000\n",
      "Minibatch loss at step 3800: 0.380673\n",
      "Minibatch learning rate at step 3800: 0.095000\n",
      "Train accuracy at step 3800: 89.062500\n",
      "Valid accuracy at step 3800: 89.750000\n",
      "Minibatch loss at step 4000: 0.340002\n",
      "Minibatch learning rate at step 4000: 0.095000\n",
      "Train accuracy at step 4000: 87.500000\n",
      "Valid accuracy at step 4000: 90.050000\n",
      "Minibatch loss at step 4200: 0.521531\n",
      "Minibatch learning rate at step 4200: 0.095000\n",
      "Train accuracy at step 4200: 85.937500\n",
      "Valid accuracy at step 4200: 89.400000\n",
      "Minibatch loss at step 4400: 0.245302\n",
      "Minibatch learning rate at step 4400: 0.095000\n",
      "Train accuracy at step 4400: 93.750000\n",
      "Valid accuracy at step 4400: 89.820000\n",
      "Minibatch loss at step 4600: 0.619587\n",
      "Minibatch learning rate at step 4600: 0.095000\n",
      "Train accuracy at step 4600: 82.812500\n",
      "Valid accuracy at step 4600: 89.500000\n",
      "Minibatch loss at step 4800: 0.434527\n",
      "Minibatch learning rate at step 4800: 0.095000\n",
      "Train accuracy at step 4800: 89.062500\n",
      "Valid accuracy at step 4800: 90.530000\n",
      "Minibatch loss at step 5000: 0.261770\n",
      "Minibatch learning rate at step 5000: 0.095000\n",
      "Train accuracy at step 5000: 90.625000\n",
      "Valid accuracy at step 5000: 90.440000\n",
      "Minibatch loss at step 5200: 0.357230\n",
      "Minibatch learning rate at step 5200: 0.095000\n",
      "Train accuracy at step 5200: 90.625000\n",
      "Valid accuracy at step 5200: 90.020000\n",
      "Minibatch loss at step 5400: 0.317463\n",
      "Minibatch learning rate at step 5400: 0.095000\n",
      "Train accuracy at step 5400: 89.062500\n",
      "Valid accuracy at step 5400: 90.410000\n",
      "Minibatch loss at step 5600: 0.251759\n",
      "Minibatch learning rate at step 5600: 0.095000\n",
      "Train accuracy at step 5600: 92.187500\n",
      "Valid accuracy at step 5600: 90.570000\n",
      "Minibatch loss at step 5800: 0.431337\n",
      "Minibatch learning rate at step 5800: 0.095000\n",
      "Train accuracy at step 5800: 87.500000\n",
      "Valid accuracy at step 5800: 90.380000\n",
      "Minibatch loss at step 6000: 0.119854\n",
      "Minibatch learning rate at step 6000: 0.090250\n",
      "Train accuracy at step 6000: 96.875000\n",
      "Valid accuracy at step 6000: 90.230000\n",
      "Minibatch loss at step 6200: 0.444322\n",
      "Minibatch learning rate at step 6200: 0.090250\n",
      "Train accuracy at step 6200: 93.750000\n",
      "Valid accuracy at step 6200: 90.780000\n",
      "Minibatch loss at step 6400: 0.320365\n",
      "Minibatch learning rate at step 6400: 0.090250\n",
      "Train accuracy at step 6400: 90.625000\n",
      "Valid accuracy at step 6400: 90.480000\n",
      "Minibatch loss at step 6600: 0.275630\n",
      "Minibatch learning rate at step 6600: 0.090250\n",
      "Train accuracy at step 6600: 92.187500\n",
      "Valid accuracy at step 6600: 91.010000\n",
      "Minibatch loss at step 6800: 0.154044\n",
      "Minibatch learning rate at step 6800: 0.090250\n",
      "Train accuracy at step 6800: 95.312500\n",
      "Valid accuracy at step 6800: 90.600000\n",
      "Minibatch loss at step 7000: 0.254215\n",
      "Minibatch learning rate at step 7000: 0.090250\n",
      "Train accuracy at step 7000: 93.750000\n",
      "Valid accuracy at step 7000: 90.820000\n",
      "Minibatch loss at step 7200: 0.380291\n",
      "Minibatch learning rate at step 7200: 0.090250\n",
      "Train accuracy at step 7200: 87.500000\n",
      "Valid accuracy at step 7200: 90.580000\n",
      "Minibatch loss at step 7400: 0.625197\n",
      "Minibatch learning rate at step 7400: 0.090250\n",
      "Train accuracy at step 7400: 79.687500\n",
      "Valid accuracy at step 7400: 90.750000\n",
      "Minibatch loss at step 7600: 0.405144\n",
      "Minibatch learning rate at step 7600: 0.090250\n",
      "Train accuracy at step 7600: 89.062500\n",
      "Valid accuracy at step 7600: 91.080000\n",
      "Minibatch loss at step 7800: 0.209362\n",
      "Minibatch learning rate at step 7800: 0.090250\n",
      "Train accuracy at step 7800: 90.625000\n",
      "Valid accuracy at step 7800: 91.230000\n",
      "Minibatch loss at step 8000: 0.443635\n",
      "Minibatch learning rate at step 8000: 0.090250\n",
      "Train accuracy at step 8000: 87.500000\n",
      "Valid accuracy at step 8000: 90.340000\n",
      "Minibatch loss at step 8200: 0.223618\n",
      "Minibatch learning rate at step 8200: 0.090250\n",
      "Train accuracy at step 8200: 95.312500\n",
      "Valid accuracy at step 8200: 90.760000\n",
      "Minibatch loss at step 8400: 0.489736\n",
      "Minibatch learning rate at step 8400: 0.090250\n",
      "Train accuracy at step 8400: 81.250000\n",
      "Valid accuracy at step 8400: 91.220000\n",
      "Minibatch loss at step 8600: 0.200879\n",
      "Minibatch learning rate at step 8600: 0.090250\n",
      "Train accuracy at step 8600: 93.750000\n",
      "Valid accuracy at step 8600: 91.230000\n",
      "Minibatch loss at step 8800: 0.303409\n",
      "Minibatch learning rate at step 8800: 0.090250\n",
      "Train accuracy at step 8800: 92.187500\n",
      "Valid accuracy at step 8800: 91.310000\n",
      "Minibatch loss at step 9000: 0.221232\n",
      "Minibatch learning rate at step 9000: 0.085737\n",
      "Train accuracy at step 9000: 92.187500\n",
      "Valid accuracy at step 9000: 90.850000\n",
      "Minibatch loss at step 9200: 0.300320\n",
      "Minibatch learning rate at step 9200: 0.085737\n",
      "Train accuracy at step 9200: 90.625000\n",
      "Valid accuracy at step 9200: 90.710000\n",
      "Minibatch loss at step 9400: 0.255022\n",
      "Minibatch learning rate at step 9400: 0.085737\n",
      "Train accuracy at step 9400: 92.187500\n",
      "Valid accuracy at step 9400: 90.390000\n",
      "Minibatch loss at step 9600: 0.279023\n",
      "Minibatch learning rate at step 9600: 0.085737\n",
      "Train accuracy at step 9600: 89.062500\n",
      "Valid accuracy at step 9600: 90.920000\n",
      "Minibatch loss at step 9800: 0.298215\n",
      "Minibatch learning rate at step 9800: 0.085737\n",
      "Train accuracy at step 9800: 90.625000\n",
      "Valid accuracy at step 9800: 90.860000\n",
      "Minibatch loss at step 10000: 0.212191\n",
      "Minibatch learning rate at step 10000: 0.085737\n",
      "Train accuracy at step 10000: 95.312500\n",
      "Valid accuracy at step 10000: 91.300000\n",
      "Minibatch loss at step 10200: 0.095419\n",
      "Minibatch learning rate at step 10200: 0.085737\n",
      "Train accuracy at step 10200: 96.875000\n",
      "Valid accuracy at step 10200: 91.470000\n",
      "Minibatch loss at step 10400: 0.274831\n",
      "Minibatch learning rate at step 10400: 0.085737\n",
      "Train accuracy at step 10400: 93.750000\n",
      "Valid accuracy at step 10400: 91.610000\n",
      "Minibatch loss at step 10600: 0.114977\n",
      "Minibatch learning rate at step 10600: 0.085737\n",
      "Train accuracy at step 10600: 95.312500\n",
      "Valid accuracy at step 10600: 91.520000\n",
      "Minibatch loss at step 10800: 0.557026\n",
      "Minibatch learning rate at step 10800: 0.085737\n",
      "Train accuracy at step 10800: 84.375000\n",
      "Valid accuracy at step 10800: 91.170000\n",
      "Minibatch loss at step 11000: 0.283853\n",
      "Minibatch learning rate at step 11000: 0.085737\n",
      "Train accuracy at step 11000: 92.187500\n",
      "Valid accuracy at step 11000: 91.240000\n",
      "Minibatch loss at step 11200: 0.161508\n",
      "Minibatch learning rate at step 11200: 0.085737\n",
      "Train accuracy at step 11200: 93.750000\n",
      "Valid accuracy at step 11200: 91.460000\n",
      "Minibatch loss at step 11400: 0.192025\n",
      "Minibatch learning rate at step 11400: 0.085737\n",
      "Train accuracy at step 11400: 95.312500\n",
      "Valid accuracy at step 11400: 91.480000\n",
      "Minibatch loss at step 11600: 0.383001\n",
      "Minibatch learning rate at step 11600: 0.085737\n",
      "Train accuracy at step 11600: 92.187500\n",
      "Valid accuracy at step 11600: 91.210000\n",
      "Minibatch loss at step 11800: 0.272214\n",
      "Minibatch learning rate at step 11800: 0.085737\n",
      "Train accuracy at step 11800: 89.062500\n",
      "Valid accuracy at step 11800: 91.340000\n",
      "Minibatch loss at step 12000: 0.291592\n",
      "Minibatch learning rate at step 12000: 0.081451\n",
      "Train accuracy at step 12000: 85.937500\n",
      "Valid accuracy at step 12000: 91.490000\n",
      "Minibatch loss at step 12200: 0.232436\n",
      "Minibatch learning rate at step 12200: 0.081451\n",
      "Train accuracy at step 12200: 92.187500\n",
      "Valid accuracy at step 12200: 91.350000\n",
      "Minibatch loss at step 12400: 0.289185\n",
      "Minibatch learning rate at step 12400: 0.081451\n",
      "Train accuracy at step 12400: 92.187500\n",
      "Valid accuracy at step 12400: 91.300000\n",
      "Minibatch loss at step 12600: 0.356876\n",
      "Minibatch learning rate at step 12600: 0.081451\n",
      "Train accuracy at step 12600: 87.500000\n",
      "Valid accuracy at step 12600: 91.100000\n",
      "Minibatch loss at step 12800: 0.242930\n",
      "Minibatch learning rate at step 12800: 0.081451\n",
      "Train accuracy at step 12800: 93.750000\n",
      "Valid accuracy at step 12800: 91.550000\n",
      "Minibatch loss at step 13000: 0.324164\n",
      "Minibatch learning rate at step 13000: 0.081451\n",
      "Train accuracy at step 13000: 87.500000\n",
      "Valid accuracy at step 13000: 91.310000\n",
      "Minibatch loss at step 13200: 0.344848\n",
      "Minibatch learning rate at step 13200: 0.081451\n",
      "Train accuracy at step 13200: 90.625000\n",
      "Valid accuracy at step 13200: 91.600000\n",
      "Minibatch loss at step 13400: 0.097821\n",
      "Minibatch learning rate at step 13400: 0.081451\n",
      "Train accuracy at step 13400: 93.750000\n",
      "Valid accuracy at step 13400: 91.360000\n",
      "Minibatch loss at step 13600: 0.336381\n",
      "Minibatch learning rate at step 13600: 0.081451\n",
      "Train accuracy at step 13600: 87.500000\n",
      "Valid accuracy at step 13600: 91.640000\n",
      "Minibatch loss at step 13800: 0.128129\n",
      "Minibatch learning rate at step 13800: 0.081451\n",
      "Train accuracy at step 13800: 95.312500\n",
      "Valid accuracy at step 13800: 91.520000\n",
      "Minibatch loss at step 14000: 0.094895\n",
      "Minibatch learning rate at step 14000: 0.081451\n",
      "Train accuracy at step 14000: 96.875000\n",
      "Valid accuracy at step 14000: 91.340000\n",
      "Minibatch loss at step 14200: 0.248136\n",
      "Minibatch learning rate at step 14200: 0.081451\n",
      "Train accuracy at step 14200: 93.750000\n",
      "Valid accuracy at step 14200: 91.550000\n",
      "Minibatch loss at step 14400: 0.143764\n",
      "Minibatch learning rate at step 14400: 0.081451\n",
      "Train accuracy at step 14400: 98.437500\n",
      "Valid accuracy at step 14400: 91.360000\n",
      "Minibatch loss at step 14600: 0.370381\n",
      "Minibatch learning rate at step 14600: 0.081451\n",
      "Train accuracy at step 14600: 90.625000\n",
      "Valid accuracy at step 14600: 91.590000\n",
      "Minibatch loss at step 14800: 0.294367\n",
      "Minibatch learning rate at step 14800: 0.081451\n",
      "Train accuracy at step 14800: 85.937500\n",
      "Valid accuracy at step 14800: 91.330000\n",
      "Minibatch loss at step 15000: 0.163957\n",
      "Minibatch learning rate at step 15000: 0.077378\n",
      "Train accuracy at step 15000: 93.750000\n",
      "Valid accuracy at step 15000: 91.620000\n",
      "Minibatch loss at step 15200: 0.311288\n",
      "Minibatch learning rate at step 15200: 0.077378\n",
      "Train accuracy at step 15200: 93.750000\n",
      "Valid accuracy at step 15200: 91.590000\n",
      "Minibatch loss at step 15400: 0.188752\n",
      "Minibatch learning rate at step 15400: 0.077378\n",
      "Train accuracy at step 15400: 95.312500\n",
      "Valid accuracy at step 15400: 91.590000\n",
      "Minibatch loss at step 15600: 0.258525\n",
      "Minibatch learning rate at step 15600: 0.077378\n",
      "Train accuracy at step 15600: 92.187500\n",
      "Valid accuracy at step 15600: 91.690000\n",
      "Minibatch loss at step 15800: 0.262239\n",
      "Minibatch learning rate at step 15800: 0.077378\n",
      "Train accuracy at step 15800: 90.625000\n",
      "Valid accuracy at step 15800: 91.450000\n",
      "Minibatch loss at step 16000: 0.260116\n",
      "Minibatch learning rate at step 16000: 0.077378\n",
      "Train accuracy at step 16000: 90.625000\n",
      "Valid accuracy at step 16000: 91.160000\n",
      "Minibatch loss at step 16200: 0.188652\n",
      "Minibatch learning rate at step 16200: 0.077378\n",
      "Train accuracy at step 16200: 93.750000\n",
      "Valid accuracy at step 16200: 91.350000\n",
      "Minibatch loss at step 16400: 0.188696\n",
      "Minibatch learning rate at step 16400: 0.077378\n",
      "Train accuracy at step 16400: 92.187500\n",
      "Valid accuracy at step 16400: 91.300000\n",
      "Minibatch loss at step 16600: 0.260092\n",
      "Minibatch learning rate at step 16600: 0.077378\n",
      "Train accuracy at step 16600: 90.625000\n",
      "Valid accuracy at step 16600: 91.350000\n",
      "Minibatch loss at step 16800: 0.295855\n",
      "Minibatch learning rate at step 16800: 0.077378\n",
      "Train accuracy at step 16800: 89.062500\n",
      "Valid accuracy at step 16800: 91.140000\n",
      "Minibatch loss at step 17000: 0.327740\n",
      "Minibatch learning rate at step 17000: 0.077378\n",
      "Train accuracy at step 17000: 89.062500\n",
      "Valid accuracy at step 17000: 91.200000\n",
      "Minibatch loss at step 17200: 0.234660\n",
      "Minibatch learning rate at step 17200: 0.077378\n",
      "Train accuracy at step 17200: 92.187500\n",
      "Valid accuracy at step 17200: 91.470000\n",
      "Minibatch loss at step 17400: 0.234504\n",
      "Minibatch learning rate at step 17400: 0.077378\n",
      "Train accuracy at step 17400: 92.187500\n",
      "Valid accuracy at step 17400: 91.610000\n",
      "Minibatch loss at step 17600: 0.265092\n",
      "Minibatch learning rate at step 17600: 0.077378\n",
      "Train accuracy at step 17600: 93.750000\n",
      "Valid accuracy at step 17600: 91.800000\n",
      "Minibatch loss at step 17800: 0.194539\n",
      "Minibatch learning rate at step 17800: 0.077378\n",
      "Train accuracy at step 17800: 93.750000\n",
      "Valid accuracy at step 17800: 91.640000\n",
      "Minibatch loss at step 18000: 0.287815\n",
      "Minibatch learning rate at step 18000: 0.073509\n",
      "Train accuracy at step 18000: 92.187500\n",
      "Valid accuracy at step 18000: 91.340000\n",
      "Minibatch loss at step 18200: 0.221806\n",
      "Minibatch learning rate at step 18200: 0.073509\n",
      "Train accuracy at step 18200: 93.750000\n",
      "Valid accuracy at step 18200: 91.950000\n",
      "Minibatch loss at step 18400: 0.204622\n",
      "Minibatch learning rate at step 18400: 0.073509\n",
      "Train accuracy at step 18400: 93.750000\n",
      "Valid accuracy at step 18400: 91.550000\n",
      "Minibatch loss at step 18600: 0.119237\n",
      "Minibatch learning rate at step 18600: 0.073509\n",
      "Train accuracy at step 18600: 96.875000\n",
      "Valid accuracy at step 18600: 91.740000\n",
      "Minibatch loss at step 18800: 0.098706\n",
      "Minibatch learning rate at step 18800: 0.073509\n",
      "Train accuracy at step 18800: 95.312500\n",
      "Valid accuracy at step 18800: 91.400000\n",
      "Minibatch loss at step 19000: 0.092934\n",
      "Minibatch learning rate at step 19000: 0.073509\n",
      "Train accuracy at step 19000: 95.312500\n",
      "Valid accuracy at step 19000: 91.110000\n",
      "Minibatch loss at step 19200: 0.108852\n",
      "Minibatch learning rate at step 19200: 0.073509\n",
      "Train accuracy at step 19200: 98.437500\n",
      "Valid accuracy at step 19200: 91.160000\n",
      "Minibatch loss at step 19400: 0.047843\n",
      "Minibatch learning rate at step 19400: 0.073509\n",
      "Train accuracy at step 19400: 96.875000\n",
      "Valid accuracy at step 19400: 91.700000\n",
      "Minibatch loss at step 19600: 0.148350\n",
      "Minibatch learning rate at step 19600: 0.073509\n",
      "Train accuracy at step 19600: 93.750000\n",
      "Valid accuracy at step 19600: 91.740000\n",
      "Minibatch loss at step 19800: 0.228777\n",
      "Minibatch learning rate at step 19800: 0.073509\n",
      "Train accuracy at step 19800: 93.750000\n",
      "Valid accuracy at step 19800: 91.630000\n",
      "Minibatch loss at step 20000: 0.055780\n",
      "Minibatch learning rate at step 20000: 0.073509\n",
      "Train accuracy at step 20000: 98.437500\n",
      "Valid accuracy at step 20000: 91.790000\n",
      "Minibatch loss at step 20200: 0.308299\n",
      "Minibatch learning rate at step 20200: 0.073509\n",
      "Train accuracy at step 20200: 93.750000\n",
      "Valid accuracy at step 20200: 91.460000\n",
      "Minibatch loss at step 20400: 0.301298\n",
      "Minibatch learning rate at step 20400: 0.073509\n",
      "Train accuracy at step 20400: 89.062500\n",
      "Valid accuracy at step 20400: 91.660000\n",
      "Minibatch loss at step 20600: 0.111933\n",
      "Minibatch learning rate at step 20600: 0.073509\n",
      "Train accuracy at step 20600: 95.312500\n",
      "Valid accuracy at step 20600: 91.520000\n",
      "Minibatch loss at step 20800: 0.209404\n",
      "Minibatch learning rate at step 20800: 0.073509\n",
      "Train accuracy at step 20800: 93.750000\n",
      "Valid accuracy at step 20800: 91.460000\n",
      "Minibatch loss at step 21000: 0.202910\n",
      "Minibatch learning rate at step 21000: 0.069834\n",
      "Train accuracy at step 21000: 90.625000\n",
      "Valid accuracy at step 21000: 91.720000\n",
      "Minibatch loss at step 21200: 0.109332\n",
      "Minibatch learning rate at step 21200: 0.069834\n",
      "Train accuracy at step 21200: 95.312500\n",
      "Valid accuracy at step 21200: 91.330000\n",
      "Minibatch loss at step 21400: 0.246308\n",
      "Minibatch learning rate at step 21400: 0.069834\n",
      "Train accuracy at step 21400: 92.187500\n",
      "Valid accuracy at step 21400: 91.760000\n",
      "Minibatch loss at step 21600: 0.062965\n",
      "Minibatch learning rate at step 21600: 0.069834\n",
      "Train accuracy at step 21600: 98.437500\n",
      "Valid accuracy at step 21600: 91.450000\n",
      "Minibatch loss at step 21800: 0.184596\n",
      "Minibatch learning rate at step 21800: 0.069834\n",
      "Train accuracy at step 21800: 95.312500\n",
      "Valid accuracy at step 21800: 91.300000\n",
      "Minibatch loss at step 22000: 0.090095\n",
      "Minibatch learning rate at step 22000: 0.069834\n",
      "Train accuracy at step 22000: 95.312500\n",
      "Valid accuracy at step 22000: 91.470000\n",
      "Minibatch loss at step 22200: 0.241361\n",
      "Minibatch learning rate at step 22200: 0.069834\n",
      "Train accuracy at step 22200: 89.062500\n",
      "Valid accuracy at step 22200: 91.290000\n",
      "Minibatch loss at step 22400: 0.350504\n",
      "Minibatch learning rate at step 22400: 0.069834\n",
      "Train accuracy at step 22400: 90.625000\n",
      "Valid accuracy at step 22400: 91.650000\n",
      "Minibatch loss at step 22600: 0.377842\n",
      "Minibatch learning rate at step 22600: 0.069834\n",
      "Train accuracy at step 22600: 92.187500\n",
      "Valid accuracy at step 22600: 91.430000\n",
      "Minibatch loss at step 22800: 0.116440\n",
      "Minibatch learning rate at step 22800: 0.069834\n",
      "Train accuracy at step 22800: 93.750000\n",
      "Valid accuracy at step 22800: 91.580000\n",
      "Minibatch loss at step 23000: 0.169788\n",
      "Minibatch learning rate at step 23000: 0.069834\n",
      "Train accuracy at step 23000: 95.312500\n",
      "Valid accuracy at step 23000: 91.810000\n",
      "Minibatch loss at step 23200: 0.484209\n",
      "Minibatch learning rate at step 23200: 0.069834\n",
      "Train accuracy at step 23200: 82.812500\n",
      "Valid accuracy at step 23200: 90.890000\n",
      "Minibatch loss at step 23400: 0.245809\n",
      "Minibatch learning rate at step 23400: 0.069834\n",
      "Train accuracy at step 23400: 95.312500\n",
      "Valid accuracy at step 23400: 91.570000\n",
      "Minibatch loss at step 23600: 0.015562\n",
      "Minibatch learning rate at step 23600: 0.069834\n",
      "Train accuracy at step 23600: 100.000000\n",
      "Valid accuracy at step 23600: 91.720000\n",
      "Minibatch loss at step 23800: 0.248657\n",
      "Minibatch learning rate at step 23800: 0.069834\n",
      "Train accuracy at step 23800: 93.750000\n",
      "Valid accuracy at step 23800: 91.780000\n",
      "Minibatch loss at step 24000: 0.444348\n",
      "Minibatch learning rate at step 24000: 0.066342\n",
      "Train accuracy at step 24000: 79.687500\n",
      "Valid accuracy at step 24000: 91.460000\n",
      "Minibatch loss at step 24200: 0.082115\n",
      "Minibatch learning rate at step 24200: 0.066342\n",
      "Train accuracy at step 24200: 98.437500\n",
      "Valid accuracy at step 24200: 91.350000\n",
      "Minibatch loss at step 24400: 0.077944\n",
      "Minibatch learning rate at step 24400: 0.066342\n",
      "Train accuracy at step 24400: 100.000000\n",
      "Valid accuracy at step 24400: 91.500000\n",
      "Minibatch loss at step 24600: 0.113120\n",
      "Minibatch learning rate at step 24600: 0.066342\n",
      "Train accuracy at step 24600: 96.875000\n",
      "Valid accuracy at step 24600: 91.690000\n",
      "Minibatch loss at step 24800: 0.221121\n",
      "Minibatch learning rate at step 24800: 0.066342\n",
      "Train accuracy at step 24800: 92.187500\n",
      "Valid accuracy at step 24800: 91.640000\n",
      "Minibatch loss at step 25000: 0.183790\n",
      "Minibatch learning rate at step 25000: 0.066342\n",
      "Train accuracy at step 25000: 96.875000\n",
      "Valid accuracy at step 25000: 91.500000\n",
      "Minibatch loss at step 25200: 0.083673\n",
      "Minibatch learning rate at step 25200: 0.066342\n",
      "Train accuracy at step 25200: 96.875000\n",
      "Valid accuracy at step 25200: 91.420000\n",
      "Minibatch loss at step 25400: 0.328629\n",
      "Minibatch learning rate at step 25400: 0.066342\n",
      "Train accuracy at step 25400: 92.187500\n",
      "Valid accuracy at step 25400: 91.420000\n",
      "Minibatch loss at step 25600: 0.236771\n",
      "Minibatch learning rate at step 25600: 0.066342\n",
      "Train accuracy at step 25600: 95.312500\n",
      "Valid accuracy at step 25600: 91.440000\n",
      "Minibatch loss at step 25800: 0.233296\n",
      "Minibatch learning rate at step 25800: 0.066342\n",
      "Train accuracy at step 25800: 93.750000\n",
      "Valid accuracy at step 25800: 91.390000\n",
      "Minibatch loss at step 26000: 0.204975\n",
      "Minibatch learning rate at step 26000: 0.066342\n",
      "Train accuracy at step 26000: 95.312500\n",
      "Valid accuracy at step 26000: 91.320000\n",
      "Minibatch loss at step 26200: 0.152508\n",
      "Minibatch learning rate at step 26200: 0.066342\n",
      "Train accuracy at step 26200: 93.750000\n",
      "Valid accuracy at step 26200: 91.510000\n",
      "Minibatch loss at step 26400: 0.254061\n",
      "Minibatch learning rate at step 26400: 0.066342\n",
      "Train accuracy at step 26400: 90.625000\n",
      "Valid accuracy at step 26400: 91.430000\n",
      "Minibatch loss at step 26600: 0.176743\n",
      "Minibatch learning rate at step 26600: 0.066342\n",
      "Train accuracy at step 26600: 95.312500\n",
      "Valid accuracy at step 26600: 91.440000\n",
      "Minibatch loss at step 26800: 0.324235\n",
      "Minibatch learning rate at step 26800: 0.066342\n",
      "Train accuracy at step 26800: 89.062500\n",
      "Valid accuracy at step 26800: 91.790000\n",
      "Minibatch loss at step 27000: 0.153507\n",
      "Minibatch learning rate at step 27000: 0.063025\n",
      "Train accuracy at step 27000: 95.312500\n",
      "Valid accuracy at step 27000: 91.400000\n",
      "Minibatch loss at step 27200: 0.195614\n",
      "Minibatch learning rate at step 27200: 0.063025\n",
      "Train accuracy at step 27200: 93.750000\n",
      "Valid accuracy at step 27200: 91.620000\n",
      "Minibatch loss at step 27400: 0.155766\n",
      "Minibatch learning rate at step 27400: 0.063025\n",
      "Train accuracy at step 27400: 95.312500\n",
      "Valid accuracy at step 27400: 91.930000\n",
      "Minibatch loss at step 27600: 0.057990\n",
      "Minibatch learning rate at step 27600: 0.063025\n",
      "Train accuracy at step 27600: 100.000000\n",
      "Valid accuracy at step 27600: 91.780000\n",
      "Minibatch loss at step 27800: 0.114674\n",
      "Minibatch learning rate at step 27800: 0.063025\n",
      "Train accuracy at step 27800: 96.875000\n",
      "Valid accuracy at step 27800: 91.560000\n",
      "Minibatch loss at step 28000: 0.179419\n",
      "Minibatch learning rate at step 28000: 0.063025\n",
      "Train accuracy at step 28000: 92.187500\n",
      "Valid accuracy at step 28000: 91.660000\n",
      "Minibatch loss at step 28200: 0.226008\n",
      "Minibatch learning rate at step 28200: 0.063025\n",
      "Train accuracy at step 28200: 93.750000\n",
      "Valid accuracy at step 28200: 91.720000\n",
      "Minibatch loss at step 28400: 0.059859\n",
      "Minibatch learning rate at step 28400: 0.063025\n",
      "Train accuracy at step 28400: 98.437500\n",
      "Valid accuracy at step 28400: 91.350000\n",
      "Minibatch loss at step 28600: 0.214485\n",
      "Minibatch learning rate at step 28600: 0.063025\n",
      "Train accuracy at step 28600: 93.750000\n",
      "Valid accuracy at step 28600: 91.330000\n",
      "Minibatch loss at step 28800: 0.087037\n",
      "Minibatch learning rate at step 28800: 0.063025\n",
      "Train accuracy at step 28800: 96.875000\n",
      "Valid accuracy at step 28800: 91.610000\n",
      "Minibatch loss at step 29000: 0.144519\n",
      "Minibatch learning rate at step 29000: 0.063025\n",
      "Train accuracy at step 29000: 95.312500\n",
      "Valid accuracy at step 29000: 91.360000\n",
      "Minibatch loss at step 29200: 0.100201\n",
      "Minibatch learning rate at step 29200: 0.063025\n",
      "Train accuracy at step 29200: 96.875000\n",
      "Valid accuracy at step 29200: 91.870000\n",
      "Minibatch loss at step 29400: 0.090235\n",
      "Minibatch learning rate at step 29400: 0.063025\n",
      "Train accuracy at step 29400: 96.875000\n",
      "Valid accuracy at step 29400: 91.680000\n",
      "Minibatch loss at step 29600: 0.094569\n",
      "Minibatch learning rate at step 29600: 0.063025\n",
      "Train accuracy at step 29600: 96.875000\n",
      "Valid accuracy at step 29600: 91.540000\n",
      "Minibatch loss at step 29800: 0.153670\n",
      "Minibatch learning rate at step 29800: 0.063025\n",
      "Train accuracy at step 29800: 98.437500\n",
      "Valid accuracy at step 29800: 91.520000\n",
      "Minibatch loss at step 30000: 0.205721\n",
      "Minibatch learning rate at step 30000: 0.059874\n",
      "Train accuracy at step 30000: 95.312500\n",
      "Valid accuracy at step 30000: 91.750000\n",
      "Minibatch loss at step 30200: 0.136972\n",
      "Minibatch learning rate at step 30200: 0.059874\n",
      "Train accuracy at step 30200: 95.312500\n",
      "Valid accuracy at step 30200: 91.800000\n",
      "Minibatch loss at step 30400: 0.075995\n",
      "Minibatch learning rate at step 30400: 0.059874\n",
      "Train accuracy at step 30400: 96.875000\n",
      "Valid accuracy at step 30400: 91.830000\n",
      "Minibatch loss at step 30600: 0.117513\n",
      "Minibatch learning rate at step 30600: 0.059874\n",
      "Train accuracy at step 30600: 95.312500\n",
      "Valid accuracy at step 30600: 91.470000\n",
      "Minibatch loss at step 30800: 0.081509\n",
      "Minibatch learning rate at step 30800: 0.059874\n",
      "Train accuracy at step 30800: 95.312500\n",
      "Valid accuracy at step 30800: 91.760000\n",
      "Minibatch loss at step 31000: 0.199616\n",
      "Minibatch learning rate at step 31000: 0.059874\n",
      "Train accuracy at step 31000: 93.750000\n",
      "Valid accuracy at step 31000: 90.950000\n",
      "Minibatch loss at step 31200: 0.155754\n",
      "Minibatch learning rate at step 31200: 0.059874\n",
      "Train accuracy at step 31200: 95.312500\n",
      "Valid accuracy at step 31200: 91.890000\n",
      "Minibatch loss at step 31400: 0.321984\n",
      "Minibatch learning rate at step 31400: 0.059874\n",
      "Train accuracy at step 31400: 89.062500\n",
      "Valid accuracy at step 31400: 91.070000\n",
      "Minibatch loss at step 31600: 0.141417\n",
      "Minibatch learning rate at step 31600: 0.059874\n",
      "Train accuracy at step 31600: 93.750000\n",
      "Valid accuracy at step 31600: 91.630000\n",
      "Minibatch loss at step 31800: 0.016861\n",
      "Minibatch learning rate at step 31800: 0.059874\n",
      "Train accuracy at step 31800: 100.000000\n",
      "Valid accuracy at step 31800: 91.620000\n",
      "Minibatch loss at step 32000: 0.091880\n",
      "Minibatch learning rate at step 32000: 0.059874\n",
      "Train accuracy at step 32000: 96.875000\n",
      "Valid accuracy at step 32000: 91.710000\n",
      "Minibatch loss at step 32200: 0.224992\n",
      "Minibatch learning rate at step 32200: 0.059874\n",
      "Train accuracy at step 32200: 92.187500\n",
      "Valid accuracy at step 32200: 91.440000\n",
      "Minibatch loss at step 32400: 0.024612\n",
      "Minibatch learning rate at step 32400: 0.059874\n",
      "Train accuracy at step 32400: 100.000000\n",
      "Valid accuracy at step 32400: 91.530000\n",
      "Minibatch loss at step 32600: 0.091300\n",
      "Minibatch learning rate at step 32600: 0.059874\n",
      "Train accuracy at step 32600: 96.875000\n",
      "Valid accuracy at step 32600: 90.840000\n",
      "Minibatch loss at step 32800: 0.027235\n",
      "Minibatch learning rate at step 32800: 0.059874\n",
      "Train accuracy at step 32800: 98.437500\n",
      "Valid accuracy at step 32800: 91.530000\n",
      "Minibatch loss at step 33000: 0.150952\n",
      "Minibatch learning rate at step 33000: 0.056880\n",
      "Train accuracy at step 33000: 96.875000\n",
      "Valid accuracy at step 33000: 91.790000\n",
      "Minibatch loss at step 33200: 0.182506\n",
      "Minibatch learning rate at step 33200: 0.056880\n",
      "Train accuracy at step 33200: 95.312500\n",
      "Valid accuracy at step 33200: 91.420000\n",
      "Minibatch loss at step 33400: 0.156107\n",
      "Minibatch learning rate at step 33400: 0.056880\n",
      "Train accuracy at step 33400: 95.312500\n",
      "Valid accuracy at step 33400: 91.490000\n",
      "Minibatch loss at step 33600: 0.139354\n",
      "Minibatch learning rate at step 33600: 0.056880\n",
      "Train accuracy at step 33600: 96.875000\n",
      "Valid accuracy at step 33600: 91.840000\n",
      "Minibatch loss at step 33800: 0.134354\n",
      "Minibatch learning rate at step 33800: 0.056880\n",
      "Train accuracy at step 33800: 96.875000\n",
      "Valid accuracy at step 33800: 91.770000\n",
      "Minibatch loss at step 34000: 0.062991\n",
      "Minibatch learning rate at step 34000: 0.056880\n",
      "Train accuracy at step 34000: 96.875000\n",
      "Valid accuracy at step 34000: 91.220000\n",
      "Minibatch loss at step 34200: 0.082986\n",
      "Minibatch learning rate at step 34200: 0.056880\n",
      "Train accuracy at step 34200: 96.875000\n",
      "Valid accuracy at step 34200: 91.660000\n",
      "Minibatch loss at step 34400: 0.118309\n",
      "Minibatch learning rate at step 34400: 0.056880\n",
      "Train accuracy at step 34400: 96.875000\n",
      "Valid accuracy at step 34400: 91.860000\n",
      "Minibatch loss at step 34600: 0.082508\n",
      "Minibatch learning rate at step 34600: 0.056880\n",
      "Train accuracy at step 34600: 98.437500\n",
      "Valid accuracy at step 34600: 91.190000\n",
      "Minibatch loss at step 34800: 0.134822\n",
      "Minibatch learning rate at step 34800: 0.056880\n",
      "Train accuracy at step 34800: 93.750000\n",
      "Valid accuracy at step 34800: 91.630000\n",
      "Minibatch loss at step 35000: 0.217553\n",
      "Minibatch learning rate at step 35000: 0.056880\n",
      "Train accuracy at step 35000: 93.750000\n",
      "Valid accuracy at step 35000: 91.840000\n",
      "Minibatch loss at step 35200: 0.054097\n",
      "Minibatch learning rate at step 35200: 0.056880\n",
      "Train accuracy at step 35200: 98.437500\n",
      "Valid accuracy at step 35200: 91.890000\n",
      "Minibatch loss at step 35400: 0.110519\n",
      "Minibatch learning rate at step 35400: 0.056880\n",
      "Train accuracy at step 35400: 96.875000\n",
      "Valid accuracy at step 35400: 91.610000\n",
      "Minibatch loss at step 35600: 0.066338\n",
      "Minibatch learning rate at step 35600: 0.056880\n",
      "Train accuracy at step 35600: 96.875000\n",
      "Valid accuracy at step 35600: 91.650000\n",
      "Minibatch loss at step 35800: 0.040399\n",
      "Minibatch learning rate at step 35800: 0.056880\n",
      "Train accuracy at step 35800: 96.875000\n",
      "Valid accuracy at step 35800: 91.650000\n",
      "Minibatch loss at step 36000: 0.194197\n",
      "Minibatch learning rate at step 36000: 0.054036\n",
      "Train accuracy at step 36000: 92.187500\n",
      "Valid accuracy at step 36000: 91.780000\n",
      "Minibatch loss at step 36200: 0.059146\n",
      "Minibatch learning rate at step 36200: 0.054036\n",
      "Train accuracy at step 36200: 96.875000\n",
      "Valid accuracy at step 36200: 91.980000\n",
      "Minibatch loss at step 36400: 0.149452\n",
      "Minibatch learning rate at step 36400: 0.054036\n",
      "Train accuracy at step 36400: 95.312500\n",
      "Valid accuracy at step 36400: 91.730000\n",
      "Minibatch loss at step 36600: 0.016994\n",
      "Minibatch learning rate at step 36600: 0.054036\n",
      "Train accuracy at step 36600: 100.000000\n",
      "Valid accuracy at step 36600: 91.630000\n",
      "Minibatch loss at step 36800: 0.078648\n",
      "Minibatch learning rate at step 36800: 0.054036\n",
      "Train accuracy at step 36800: 96.875000\n",
      "Valid accuracy at step 36800: 91.400000\n",
      "Minibatch loss at step 37000: 0.031404\n",
      "Minibatch learning rate at step 37000: 0.054036\n",
      "Train accuracy at step 37000: 98.437500\n",
      "Valid accuracy at step 37000: 91.690000\n",
      "Minibatch loss at step 37200: 0.030560\n",
      "Minibatch learning rate at step 37200: 0.054036\n",
      "Train accuracy at step 37200: 100.000000\n",
      "Valid accuracy at step 37200: 91.520000\n",
      "Minibatch loss at step 37400: 0.066682\n",
      "Minibatch learning rate at step 37400: 0.054036\n",
      "Train accuracy at step 37400: 96.875000\n",
      "Valid accuracy at step 37400: 91.790000\n",
      "Minibatch loss at step 37600: 0.118319\n",
      "Minibatch learning rate at step 37600: 0.054036\n",
      "Train accuracy at step 37600: 98.437500\n",
      "Valid accuracy at step 37600: 91.510000\n",
      "Minibatch loss at step 37800: 0.253084\n",
      "Minibatch learning rate at step 37800: 0.054036\n",
      "Train accuracy at step 37800: 90.625000\n",
      "Valid accuracy at step 37800: 91.720000\n",
      "Minibatch loss at step 38000: 0.139019\n",
      "Minibatch learning rate at step 38000: 0.054036\n",
      "Train accuracy at step 38000: 93.750000\n",
      "Valid accuracy at step 38000: 91.690000\n",
      "Minibatch loss at step 38200: 0.200263\n",
      "Minibatch learning rate at step 38200: 0.054036\n",
      "Train accuracy at step 38200: 96.875000\n",
      "Valid accuracy at step 38200: 91.500000\n",
      "Minibatch loss at step 38400: 0.240609\n",
      "Minibatch learning rate at step 38400: 0.054036\n",
      "Train accuracy at step 38400: 89.062500\n",
      "Valid accuracy at step 38400: 91.660000\n",
      "Minibatch loss at step 38600: 0.119249\n",
      "Minibatch learning rate at step 38600: 0.054036\n",
      "Train accuracy at step 38600: 95.312500\n",
      "Valid accuracy at step 38600: 92.130000\n",
      "Minibatch loss at step 38800: 0.068860\n",
      "Minibatch learning rate at step 38800: 0.054036\n",
      "Train accuracy at step 38800: 98.437500\n",
      "Valid accuracy at step 38800: 91.840000\n",
      "Minibatch loss at step 39000: 0.117276\n",
      "Minibatch learning rate at step 39000: 0.051334\n",
      "Train accuracy at step 39000: 95.312500\n",
      "Valid accuracy at step 39000: 91.530000\n",
      "Minibatch loss at step 39200: 0.116746\n",
      "Minibatch learning rate at step 39200: 0.051334\n",
      "Train accuracy at step 39200: 95.312500\n",
      "Valid accuracy at step 39200: 91.590000\n",
      "Minibatch loss at step 39400: 0.057622\n",
      "Minibatch learning rate at step 39400: 0.051334\n",
      "Train accuracy at step 39400: 96.875000\n",
      "Valid accuracy at step 39400: 91.520000\n",
      "Minibatch loss at step 39600: 0.087790\n",
      "Minibatch learning rate at step 39600: 0.051334\n",
      "Train accuracy at step 39600: 98.437500\n",
      "Valid accuracy at step 39600: 91.820000\n",
      "Minibatch loss at step 39800: 0.163495\n",
      "Minibatch learning rate at step 39800: 0.051334\n",
      "Train accuracy at step 39800: 95.312500\n",
      "Valid accuracy at step 39800: 91.690000\n",
      "Minibatch loss at step 40000: 0.102759\n",
      "Minibatch learning rate at step 40000: 0.051334\n",
      "Train accuracy at step 40000: 95.312500\n",
      "Valid accuracy at step 40000: 91.920000\n",
      "Minibatch loss at step 40200: 0.071690\n",
      "Minibatch learning rate at step 40200: 0.051334\n",
      "Train accuracy at step 40200: 98.437500\n",
      "Valid accuracy at step 40200: 91.710000\n",
      "Minibatch loss at step 40400: 0.230263\n",
      "Minibatch learning rate at step 40400: 0.051334\n",
      "Train accuracy at step 40400: 95.312500\n",
      "Valid accuracy at step 40400: 91.560000\n",
      "Minibatch loss at step 40600: 0.220858\n",
      "Minibatch learning rate at step 40600: 0.051334\n",
      "Train accuracy at step 40600: 92.187500\n",
      "Valid accuracy at step 40600: 91.880000\n",
      "Minibatch loss at step 40800: 0.272658\n",
      "Minibatch learning rate at step 40800: 0.051334\n",
      "Train accuracy at step 40800: 93.750000\n",
      "Valid accuracy at step 40800: 91.390000\n",
      "Minibatch loss at step 41000: 0.205545\n",
      "Minibatch learning rate at step 41000: 0.051334\n",
      "Train accuracy at step 41000: 93.750000\n",
      "Valid accuracy at step 41000: 91.680000\n",
      "Minibatch loss at step 41200: 0.100537\n",
      "Minibatch learning rate at step 41200: 0.051334\n",
      "Train accuracy at step 41200: 96.875000\n",
      "Valid accuracy at step 41200: 91.900000\n",
      "Minibatch loss at step 41400: 0.205703\n",
      "Minibatch learning rate at step 41400: 0.051334\n",
      "Train accuracy at step 41400: 93.750000\n",
      "Valid accuracy at step 41400: 91.930000\n",
      "Minibatch loss at step 41600: 0.174207\n",
      "Minibatch learning rate at step 41600: 0.051334\n",
      "Train accuracy at step 41600: 95.312500\n",
      "Valid accuracy at step 41600: 91.590000\n",
      "Minibatch loss at step 41800: 0.079202\n",
      "Minibatch learning rate at step 41800: 0.051334\n",
      "Train accuracy at step 41800: 95.312500\n",
      "Valid accuracy at step 41800: 91.600000\n",
      "Minibatch loss at step 42000: 0.013369\n",
      "Minibatch learning rate at step 42000: 0.048767\n",
      "Train accuracy at step 42000: 100.000000\n",
      "Valid accuracy at step 42000: 91.600000\n",
      "Minibatch loss at step 42200: 0.109206\n",
      "Minibatch learning rate at step 42200: 0.048767\n",
      "Train accuracy at step 42200: 96.875000\n",
      "Valid accuracy at step 42200: 91.950000\n",
      "Minibatch loss at step 42400: 0.095876\n",
      "Minibatch learning rate at step 42400: 0.048767\n",
      "Train accuracy at step 42400: 96.875000\n",
      "Valid accuracy at step 42400: 91.820000\n",
      "Minibatch loss at step 42600: 0.033931\n",
      "Minibatch learning rate at step 42600: 0.048767\n",
      "Train accuracy at step 42600: 98.437500\n",
      "Valid accuracy at step 42600: 91.970000\n",
      "Minibatch loss at step 42800: 0.040724\n",
      "Minibatch learning rate at step 42800: 0.048767\n",
      "Train accuracy at step 42800: 98.437500\n",
      "Valid accuracy at step 42800: 91.650000\n",
      "Minibatch loss at step 43000: 0.095630\n",
      "Minibatch learning rate at step 43000: 0.048767\n",
      "Train accuracy at step 43000: 96.875000\n",
      "Valid accuracy at step 43000: 91.810000\n",
      "Minibatch loss at step 43200: 0.050235\n",
      "Minibatch learning rate at step 43200: 0.048767\n",
      "Train accuracy at step 43200: 98.437500\n",
      "Valid accuracy at step 43200: 91.990000\n",
      "Minibatch loss at step 43400: 0.188749\n",
      "Minibatch learning rate at step 43400: 0.048767\n",
      "Train accuracy at step 43400: 92.187500\n",
      "Valid accuracy at step 43400: 91.730000\n",
      "Minibatch loss at step 43600: 0.142699\n",
      "Minibatch learning rate at step 43600: 0.048767\n",
      "Train accuracy at step 43600: 98.437500\n",
      "Valid accuracy at step 43600: 91.810000\n",
      "Minibatch loss at step 43800: 0.044977\n",
      "Minibatch learning rate at step 43800: 0.048767\n",
      "Train accuracy at step 43800: 98.437500\n",
      "Valid accuracy at step 43800: 92.010000\n",
      "Minibatch loss at step 44000: 0.013960\n",
      "Minibatch learning rate at step 44000: 0.048767\n",
      "Train accuracy at step 44000: 98.437500\n",
      "Valid accuracy at step 44000: 91.610000\n",
      "Minibatch loss at step 44200: 0.039858\n",
      "Minibatch learning rate at step 44200: 0.048767\n",
      "Train accuracy at step 44200: 96.875000\n",
      "Valid accuracy at step 44200: 91.970000\n",
      "Minibatch loss at step 44400: 0.007916\n",
      "Minibatch learning rate at step 44400: 0.048767\n",
      "Train accuracy at step 44400: 100.000000\n",
      "Valid accuracy at step 44400: 91.800000\n",
      "Minibatch loss at step 44600: 0.110594\n",
      "Minibatch learning rate at step 44600: 0.048767\n",
      "Train accuracy at step 44600: 95.312500\n",
      "Valid accuracy at step 44600: 91.750000\n",
      "Minibatch loss at step 44800: 0.084519\n",
      "Minibatch learning rate at step 44800: 0.048767\n",
      "Train accuracy at step 44800: 96.875000\n",
      "Valid accuracy at step 44800: 91.830000\n",
      "Minibatch loss at step 45000: 0.036336\n",
      "Minibatch learning rate at step 45000: 0.046329\n",
      "Train accuracy at step 45000: 98.437500\n",
      "Valid accuracy at step 45000: 91.720000\n",
      "Minibatch loss at step 45200: 0.011515\n",
      "Minibatch learning rate at step 45200: 0.046329\n",
      "Train accuracy at step 45200: 100.000000\n",
      "Valid accuracy at step 45200: 91.550000\n",
      "Minibatch loss at step 45400: 0.235668\n",
      "Minibatch learning rate at step 45400: 0.046329\n",
      "Train accuracy at step 45400: 95.312500\n",
      "Valid accuracy at step 45400: 91.440000\n",
      "Minibatch loss at step 45600: 0.152581\n",
      "Minibatch learning rate at step 45600: 0.046329\n",
      "Train accuracy at step 45600: 93.750000\n",
      "Valid accuracy at step 45600: 92.060000\n",
      "Minibatch loss at step 45800: 0.042883\n",
      "Minibatch learning rate at step 45800: 0.046329\n",
      "Train accuracy at step 45800: 98.437500\n",
      "Valid accuracy at step 45800: 92.160000\n",
      "Minibatch loss at step 46000: 0.330650\n",
      "Minibatch learning rate at step 46000: 0.046329\n",
      "Train accuracy at step 46000: 89.062500\n",
      "Valid accuracy at step 46000: 92.210000\n",
      "Minibatch loss at step 46200: 0.072877\n",
      "Minibatch learning rate at step 46200: 0.046329\n",
      "Train accuracy at step 46200: 98.437500\n",
      "Valid accuracy at step 46200: 91.760000\n",
      "Minibatch loss at step 46400: 0.110873\n",
      "Minibatch learning rate at step 46400: 0.046329\n",
      "Train accuracy at step 46400: 96.875000\n",
      "Valid accuracy at step 46400: 91.880000\n",
      "Minibatch loss at step 46600: 0.090388\n",
      "Minibatch learning rate at step 46600: 0.046329\n",
      "Train accuracy at step 46600: 96.875000\n",
      "Valid accuracy at step 46600: 91.820000\n",
      "Minibatch loss at step 46800: 0.074673\n",
      "Minibatch learning rate at step 46800: 0.046329\n",
      "Train accuracy at step 46800: 95.312500\n",
      "Valid accuracy at step 46800: 91.920000\n",
      "Minibatch loss at step 47000: 0.113711\n",
      "Minibatch learning rate at step 47000: 0.046329\n",
      "Train accuracy at step 47000: 96.875000\n",
      "Valid accuracy at step 47000: 92.140000\n",
      "Minibatch loss at step 47200: 0.042223\n",
      "Minibatch learning rate at step 47200: 0.046329\n",
      "Train accuracy at step 47200: 98.437500\n",
      "Valid accuracy at step 47200: 91.590000\n",
      "Minibatch loss at step 47400: 0.093125\n",
      "Minibatch learning rate at step 47400: 0.046329\n",
      "Train accuracy at step 47400: 96.875000\n",
      "Valid accuracy at step 47400: 91.810000\n",
      "Minibatch loss at step 47600: 0.102728\n",
      "Minibatch learning rate at step 47600: 0.046329\n",
      "Train accuracy at step 47600: 96.875000\n",
      "Valid accuracy at step 47600: 92.120000\n",
      "Minibatch loss at step 47800: 0.184510\n",
      "Minibatch learning rate at step 47800: 0.046329\n",
      "Train accuracy at step 47800: 96.875000\n",
      "Valid accuracy at step 47800: 91.950000\n",
      "Minibatch loss at step 48000: 0.112167\n",
      "Minibatch learning rate at step 48000: 0.044013\n",
      "Train accuracy at step 48000: 96.875000\n",
      "Valid accuracy at step 48000: 91.710000\n",
      "Minibatch loss at step 48200: 0.050443\n",
      "Minibatch learning rate at step 48200: 0.044013\n",
      "Train accuracy at step 48200: 98.437500\n",
      "Valid accuracy at step 48200: 91.750000\n",
      "Minibatch loss at step 48400: 0.134030\n",
      "Minibatch learning rate at step 48400: 0.044013\n",
      "Train accuracy at step 48400: 95.312500\n",
      "Valid accuracy at step 48400: 91.460000\n",
      "Minibatch loss at step 48600: 0.111278\n",
      "Minibatch learning rate at step 48600: 0.044013\n",
      "Train accuracy at step 48600: 96.875000\n",
      "Valid accuracy at step 48600: 91.990000\n",
      "Minibatch loss at step 48800: 0.028006\n",
      "Minibatch learning rate at step 48800: 0.044013\n",
      "Train accuracy at step 48800: 98.437500\n",
      "Valid accuracy at step 48800: 91.900000\n",
      "Minibatch loss at step 49000: 0.095829\n",
      "Minibatch learning rate at step 49000: 0.044013\n",
      "Train accuracy at step 49000: 96.875000\n",
      "Valid accuracy at step 49000: 92.020000\n",
      "Minibatch loss at step 49200: 0.069755\n",
      "Minibatch learning rate at step 49200: 0.044013\n",
      "Train accuracy at step 49200: 96.875000\n",
      "Valid accuracy at step 49200: 91.530000\n",
      "Minibatch loss at step 49400: 0.120989\n",
      "Minibatch learning rate at step 49400: 0.044013\n",
      "Train accuracy at step 49400: 96.875000\n",
      "Valid accuracy at step 49400: 92.110000\n",
      "Minibatch loss at step 49600: 0.015247\n",
      "Minibatch learning rate at step 49600: 0.044013\n",
      "Train accuracy at step 49600: 98.437500\n",
      "Valid accuracy at step 49600: 92.090000\n",
      "Minibatch loss at step 49800: 0.022126\n",
      "Minibatch learning rate at step 49800: 0.044013\n",
      "Train accuracy at step 49800: 98.437500\n",
      "Valid accuracy at step 49800: 91.680000\n",
      "Minibatch loss at step 50000: 0.050483\n",
      "Minibatch learning rate at step 50000: 0.044013\n",
      "Train accuracy at step 50000: 98.437500\n",
      "Valid accuracy at step 50000: 91.850000\n",
      "Minibatch loss at step 50200: 0.040661\n",
      "Minibatch learning rate at step 50200: 0.044013\n",
      "Train accuracy at step 50200: 98.437500\n",
      "Valid accuracy at step 50200: 91.350000\n",
      "Minibatch loss at step 50400: 0.108515\n",
      "Minibatch learning rate at step 50400: 0.044013\n",
      "Train accuracy at step 50400: 96.875000\n",
      "Valid accuracy at step 50400: 91.880000\n",
      "Minibatch loss at step 50600: 0.018591\n",
      "Minibatch learning rate at step 50600: 0.044013\n",
      "Train accuracy at step 50600: 100.000000\n",
      "Valid accuracy at step 50600: 92.060000\n",
      "Minibatch loss at step 50800: 0.226223\n",
      "Minibatch learning rate at step 50800: 0.044013\n",
      "Train accuracy at step 50800: 95.312500\n",
      "Valid accuracy at step 50800: 91.660000\n",
      "Minibatch loss at step 51000: 0.030747\n",
      "Minibatch learning rate at step 51000: 0.041812\n",
      "Train accuracy at step 51000: 100.000000\n",
      "Valid accuracy at step 51000: 91.900000\n",
      "Minibatch loss at step 51200: 0.076114\n",
      "Minibatch learning rate at step 51200: 0.041812\n",
      "Train accuracy at step 51200: 96.875000\n",
      "Valid accuracy at step 51200: 91.930000\n",
      "Minibatch loss at step 51400: 0.058312\n",
      "Minibatch learning rate at step 51400: 0.041812\n",
      "Train accuracy at step 51400: 96.875000\n",
      "Valid accuracy at step 51400: 91.590000\n",
      "Minibatch loss at step 51600: 0.051260\n",
      "Minibatch learning rate at step 51600: 0.041812\n",
      "Train accuracy at step 51600: 98.437500\n",
      "Valid accuracy at step 51600: 91.970000\n",
      "Minibatch loss at step 51800: 0.039932\n",
      "Minibatch learning rate at step 51800: 0.041812\n",
      "Train accuracy at step 51800: 98.437500\n",
      "Valid accuracy at step 51800: 91.810000\n",
      "Minibatch loss at step 52000: 0.118303\n",
      "Minibatch learning rate at step 52000: 0.041812\n",
      "Train accuracy at step 52000: 95.312500\n",
      "Valid accuracy at step 52000: 91.660000\n",
      "Minibatch loss at step 52200: 0.085762\n",
      "Minibatch learning rate at step 52200: 0.041812\n",
      "Train accuracy at step 52200: 98.437500\n",
      "Valid accuracy at step 52200: 91.770000\n",
      "Minibatch loss at step 52400: 0.066581\n",
      "Minibatch learning rate at step 52400: 0.041812\n",
      "Train accuracy at step 52400: 95.312500\n",
      "Valid accuracy at step 52400: 91.910000\n",
      "Minibatch loss at step 52600: 0.067929\n",
      "Minibatch learning rate at step 52600: 0.041812\n",
      "Train accuracy at step 52600: 96.875000\n",
      "Valid accuracy at step 52600: 92.110000\n",
      "Minibatch loss at step 52800: 0.008424\n",
      "Minibatch learning rate at step 52800: 0.041812\n",
      "Train accuracy at step 52800: 100.000000\n",
      "Valid accuracy at step 52800: 91.920000\n",
      "Minibatch loss at step 53000: 0.228795\n",
      "Minibatch learning rate at step 53000: 0.041812\n",
      "Train accuracy at step 53000: 89.062500\n",
      "Valid accuracy at step 53000: 91.720000\n",
      "Minibatch loss at step 53200: 0.033341\n",
      "Minibatch learning rate at step 53200: 0.041812\n",
      "Train accuracy at step 53200: 98.437500\n",
      "Valid accuracy at step 53200: 91.780000\n",
      "Minibatch loss at step 53400: 0.062554\n",
      "Minibatch learning rate at step 53400: 0.041812\n",
      "Train accuracy at step 53400: 96.875000\n",
      "Valid accuracy at step 53400: 91.920000\n",
      "Minibatch loss at step 53600: 0.006987\n",
      "Minibatch learning rate at step 53600: 0.041812\n",
      "Train accuracy at step 53600: 100.000000\n",
      "Valid accuracy at step 53600: 91.630000\n",
      "Minibatch loss at step 53800: 0.097099\n",
      "Minibatch learning rate at step 53800: 0.041812\n",
      "Train accuracy at step 53800: 96.875000\n",
      "Valid accuracy at step 53800: 91.710000\n",
      "Minibatch loss at step 54000: 0.068941\n",
      "Minibatch learning rate at step 54000: 0.039721\n",
      "Train accuracy at step 54000: 98.437500\n",
      "Valid accuracy at step 54000: 91.780000\n",
      "Minibatch loss at step 54200: 0.056766\n",
      "Minibatch learning rate at step 54200: 0.039721\n",
      "Train accuracy at step 54200: 98.437500\n",
      "Valid accuracy at step 54200: 92.050000\n",
      "Minibatch loss at step 54400: 0.057344\n",
      "Minibatch learning rate at step 54400: 0.039721\n",
      "Train accuracy at step 54400: 98.437500\n",
      "Valid accuracy at step 54400: 91.490000\n",
      "Minibatch loss at step 54600: 0.140383\n",
      "Minibatch learning rate at step 54600: 0.039721\n",
      "Train accuracy at step 54600: 95.312500\n",
      "Valid accuracy at step 54600: 91.720000\n",
      "Minibatch loss at step 54800: 0.005658\n",
      "Minibatch learning rate at step 54800: 0.039721\n",
      "Train accuracy at step 54800: 100.000000\n",
      "Valid accuracy at step 54800: 91.950000\n",
      "Minibatch loss at step 55000: 0.064603\n",
      "Minibatch learning rate at step 55000: 0.039721\n",
      "Train accuracy at step 55000: 98.437500\n",
      "Valid accuracy at step 55000: 92.180000\n",
      "Minibatch loss at step 55200: 0.016696\n",
      "Minibatch learning rate at step 55200: 0.039721\n",
      "Train accuracy at step 55200: 100.000000\n",
      "Valid accuracy at step 55200: 91.970000\n",
      "Minibatch loss at step 55400: 0.019453\n",
      "Minibatch learning rate at step 55400: 0.039721\n",
      "Train accuracy at step 55400: 100.000000\n",
      "Valid accuracy at step 55400: 92.160000\n",
      "Minibatch loss at step 55600: 0.010984\n",
      "Minibatch learning rate at step 55600: 0.039721\n",
      "Train accuracy at step 55600: 100.000000\n",
      "Valid accuracy at step 55600: 92.070000\n",
      "Minibatch loss at step 55800: 0.060177\n",
      "Minibatch learning rate at step 55800: 0.039721\n",
      "Train accuracy at step 55800: 96.875000\n",
      "Valid accuracy at step 55800: 92.140000\n",
      "Minibatch loss at step 56000: 0.062074\n",
      "Minibatch learning rate at step 56000: 0.039721\n",
      "Train accuracy at step 56000: 96.875000\n",
      "Valid accuracy at step 56000: 91.890000\n",
      "Minibatch loss at step 56200: 0.040492\n",
      "Minibatch learning rate at step 56200: 0.039721\n",
      "Train accuracy at step 56200: 98.437500\n",
      "Valid accuracy at step 56200: 91.860000\n",
      "Minibatch loss at step 56400: 0.044474\n",
      "Minibatch learning rate at step 56400: 0.039721\n",
      "Train accuracy at step 56400: 98.437500\n",
      "Valid accuracy at step 56400: 91.820000\n",
      "Minibatch loss at step 56600: 0.071772\n",
      "Minibatch learning rate at step 56600: 0.039721\n",
      "Train accuracy at step 56600: 98.437500\n",
      "Valid accuracy at step 56600: 91.930000\n",
      "Minibatch loss at step 56800: 0.091816\n",
      "Minibatch learning rate at step 56800: 0.039721\n",
      "Train accuracy at step 56800: 96.875000\n",
      "Valid accuracy at step 56800: 91.800000\n",
      "Minibatch loss at step 57000: 0.084529\n",
      "Minibatch learning rate at step 57000: 0.037735\n",
      "Train accuracy at step 57000: 95.312500\n",
      "Valid accuracy at step 57000: 91.680000\n",
      "Minibatch loss at step 57200: 0.152089\n",
      "Minibatch learning rate at step 57200: 0.037735\n",
      "Train accuracy at step 57200: 95.312500\n",
      "Valid accuracy at step 57200: 91.830000\n",
      "Minibatch loss at step 57400: 0.042120\n",
      "Minibatch learning rate at step 57400: 0.037735\n",
      "Train accuracy at step 57400: 98.437500\n",
      "Valid accuracy at step 57400: 91.860000\n",
      "Minibatch loss at step 57600: 0.017950\n",
      "Minibatch learning rate at step 57600: 0.037735\n",
      "Train accuracy at step 57600: 98.437500\n",
      "Valid accuracy at step 57600: 91.910000\n",
      "Minibatch loss at step 57800: 0.020353\n",
      "Minibatch learning rate at step 57800: 0.037735\n",
      "Train accuracy at step 57800: 100.000000\n",
      "Valid accuracy at step 57800: 91.630000\n",
      "Minibatch loss at step 58000: 0.001045\n",
      "Minibatch learning rate at step 58000: 0.037735\n",
      "Train accuracy at step 58000: 100.000000\n",
      "Valid accuracy at step 58000: 91.730000\n",
      "Minibatch loss at step 58200: 0.132765\n",
      "Minibatch learning rate at step 58200: 0.037735\n",
      "Train accuracy at step 58200: 96.875000\n",
      "Valid accuracy at step 58200: 92.030000\n",
      "Minibatch loss at step 58400: 0.213599\n",
      "Minibatch learning rate at step 58400: 0.037735\n",
      "Train accuracy at step 58400: 95.312500\n",
      "Valid accuracy at step 58400: 91.950000\n",
      "Minibatch loss at step 58600: 0.041029\n",
      "Minibatch learning rate at step 58600: 0.037735\n",
      "Train accuracy at step 58600: 98.437500\n",
      "Valid accuracy at step 58600: 91.960000\n",
      "Minibatch loss at step 58800: 0.025915\n",
      "Minibatch learning rate at step 58800: 0.037735\n",
      "Train accuracy at step 58800: 98.437500\n",
      "Valid accuracy at step 58800: 92.010000\n",
      "Minibatch loss at step 59000: 0.046181\n",
      "Minibatch learning rate at step 59000: 0.037735\n",
      "Train accuracy at step 59000: 98.437500\n",
      "Valid accuracy at step 59000: 91.930000\n",
      "Minibatch loss at step 59200: 0.014939\n",
      "Minibatch learning rate at step 59200: 0.037735\n",
      "Train accuracy at step 59200: 100.000000\n",
      "Valid accuracy at step 59200: 92.080000\n",
      "Minibatch loss at step 59400: 0.030770\n",
      "Minibatch learning rate at step 59400: 0.037735\n",
      "Train accuracy at step 59400: 98.437500\n",
      "Valid accuracy at step 59400: 91.980000\n",
      "Minibatch loss at step 59600: 0.026007\n",
      "Minibatch learning rate at step 59600: 0.037735\n",
      "Train accuracy at step 59600: 98.437500\n",
      "Valid accuracy at step 59600: 91.780000\n",
      "Minibatch loss at step 59800: 0.018892\n",
      "Minibatch learning rate at step 59800: 0.037735\n",
      "Train accuracy at step 59800: 100.000000\n",
      "Valid accuracy at step 59800: 91.810000\n",
      "Minibatch loss at step 60000: 0.079805\n",
      "Minibatch learning rate at step 60000: 0.035849\n",
      "Train accuracy at step 60000: 95.312500\n",
      "Valid accuracy at step 60000: 91.750000\n",
      "Minibatch loss at step 60200: 0.037251\n",
      "Minibatch learning rate at step 60200: 0.035849\n",
      "Train accuracy at step 60200: 98.437500\n",
      "Valid accuracy at step 60200: 92.100000\n",
      "Minibatch loss at step 60400: 0.302959\n",
      "Minibatch learning rate at step 60400: 0.035849\n",
      "Train accuracy at step 60400: 93.750000\n",
      "Valid accuracy at step 60400: 92.060000\n",
      "Minibatch loss at step 60600: 0.090255\n",
      "Minibatch learning rate at step 60600: 0.035849\n",
      "Train accuracy at step 60600: 95.312500\n",
      "Valid accuracy at step 60600: 91.970000\n",
      "Minibatch loss at step 60800: 0.009480\n",
      "Minibatch learning rate at step 60800: 0.035849\n",
      "Train accuracy at step 60800: 100.000000\n",
      "Valid accuracy at step 60800: 91.880000\n",
      "Minibatch loss at step 61000: 0.141830\n",
      "Minibatch learning rate at step 61000: 0.035849\n",
      "Train accuracy at step 61000: 98.437500\n",
      "Valid accuracy at step 61000: 92.230000\n",
      "Minibatch loss at step 61200: 0.008072\n",
      "Minibatch learning rate at step 61200: 0.035849\n",
      "Train accuracy at step 61200: 100.000000\n",
      "Valid accuracy at step 61200: 92.030000\n",
      "Minibatch loss at step 61400: 0.057260\n",
      "Minibatch learning rate at step 61400: 0.035849\n",
      "Train accuracy at step 61400: 98.437500\n",
      "Valid accuracy at step 61400: 91.790000\n",
      "Minibatch loss at step 61600: 0.140558\n",
      "Minibatch learning rate at step 61600: 0.035849\n",
      "Train accuracy at step 61600: 96.875000\n",
      "Valid accuracy at step 61600: 91.980000\n",
      "Minibatch loss at step 61800: 0.051503\n",
      "Minibatch learning rate at step 61800: 0.035849\n",
      "Train accuracy at step 61800: 96.875000\n",
      "Valid accuracy at step 61800: 91.770000\n",
      "Minibatch loss at step 62000: 0.007143\n",
      "Minibatch learning rate at step 62000: 0.035849\n",
      "Train accuracy at step 62000: 100.000000\n",
      "Valid accuracy at step 62000: 91.940000\n",
      "Minibatch loss at step 62200: 0.137403\n",
      "Minibatch learning rate at step 62200: 0.035849\n",
      "Train accuracy at step 62200: 98.437500\n",
      "Valid accuracy at step 62200: 91.940000\n",
      "Minibatch loss at step 62400: 0.037341\n",
      "Minibatch learning rate at step 62400: 0.035849\n",
      "Train accuracy at step 62400: 96.875000\n",
      "Valid accuracy at step 62400: 92.130000\n",
      "Minibatch loss at step 62600: 0.077201\n",
      "Minibatch learning rate at step 62600: 0.035849\n",
      "Train accuracy at step 62600: 95.312500\n",
      "Valid accuracy at step 62600: 91.790000\n",
      "Minibatch loss at step 62800: 0.027156\n",
      "Minibatch learning rate at step 62800: 0.035849\n",
      "Train accuracy at step 62800: 98.437500\n",
      "Valid accuracy at step 62800: 91.850000\n",
      "Minibatch loss at step 63000: 0.002170\n",
      "Minibatch learning rate at step 63000: 0.034056\n",
      "Train accuracy at step 63000: 100.000000\n",
      "Valid accuracy at step 63000: 91.990000\n",
      "Minibatch loss at step 63200: 0.052503\n",
      "Minibatch learning rate at step 63200: 0.034056\n",
      "Train accuracy at step 63200: 98.437500\n",
      "Valid accuracy at step 63200: 92.170000\n",
      "Minibatch loss at step 63400: 0.105133\n",
      "Minibatch learning rate at step 63400: 0.034056\n",
      "Train accuracy at step 63400: 96.875000\n",
      "Valid accuracy at step 63400: 92.020000\n",
      "Minibatch loss at step 63600: 0.067737\n",
      "Minibatch learning rate at step 63600: 0.034056\n",
      "Train accuracy at step 63600: 98.437500\n",
      "Valid accuracy at step 63600: 92.070000\n",
      "Minibatch loss at step 63800: 0.077981\n",
      "Minibatch learning rate at step 63800: 0.034056\n",
      "Train accuracy at step 63800: 98.437500\n",
      "Valid accuracy at step 63800: 92.120000\n",
      "Minibatch loss at step 64000: 0.033249\n",
      "Minibatch learning rate at step 64000: 0.034056\n",
      "Train accuracy at step 64000: 98.437500\n",
      "Valid accuracy at step 64000: 91.710000\n",
      "Minibatch loss at step 64200: 0.073367\n",
      "Minibatch learning rate at step 64200: 0.034056\n",
      "Train accuracy at step 64200: 96.875000\n",
      "Valid accuracy at step 64200: 92.010000\n",
      "Minibatch loss at step 64400: 0.018277\n",
      "Minibatch learning rate at step 64400: 0.034056\n",
      "Train accuracy at step 64400: 100.000000\n",
      "Valid accuracy at step 64400: 91.960000\n",
      "Minibatch loss at step 64600: 0.008854\n",
      "Minibatch learning rate at step 64600: 0.034056\n",
      "Train accuracy at step 64600: 100.000000\n",
      "Valid accuracy at step 64600: 92.080000\n",
      "Minibatch loss at step 64800: 0.181673\n",
      "Minibatch learning rate at step 64800: 0.034056\n",
      "Train accuracy at step 64800: 98.437500\n",
      "Valid accuracy at step 64800: 92.150000\n",
      "Minibatch loss at step 65000: 0.270845\n",
      "Minibatch learning rate at step 65000: 0.034056\n",
      "Train accuracy at step 65000: 95.312500\n",
      "Valid accuracy at step 65000: 92.400000\n",
      "Minibatch loss at step 65200: 0.074054\n",
      "Minibatch learning rate at step 65200: 0.034056\n",
      "Train accuracy at step 65200: 96.875000\n",
      "Valid accuracy at step 65200: 92.170000\n",
      "Minibatch loss at step 65400: 0.014334\n",
      "Minibatch learning rate at step 65400: 0.034056\n",
      "Train accuracy at step 65400: 98.437500\n",
      "Valid accuracy at step 65400: 92.140000\n",
      "Minibatch loss at step 65600: 0.031180\n",
      "Minibatch learning rate at step 65600: 0.034056\n",
      "Train accuracy at step 65600: 100.000000\n",
      "Valid accuracy at step 65600: 91.940000\n",
      "Minibatch loss at step 65800: 0.106796\n",
      "Minibatch learning rate at step 65800: 0.034056\n",
      "Train accuracy at step 65800: 98.437500\n",
      "Valid accuracy at step 65800: 92.030000\n",
      "Minibatch loss at step 66000: 0.125108\n",
      "Minibatch learning rate at step 66000: 0.032353\n",
      "Train accuracy at step 66000: 96.875000\n",
      "Valid accuracy at step 66000: 92.170000\n",
      "Minibatch loss at step 66200: 0.028684\n",
      "Minibatch learning rate at step 66200: 0.032353\n",
      "Train accuracy at step 66200: 100.000000\n",
      "Valid accuracy at step 66200: 92.090000\n",
      "Minibatch loss at step 66400: 0.022522\n",
      "Minibatch learning rate at step 66400: 0.032353\n",
      "Train accuracy at step 66400: 98.437500\n",
      "Valid accuracy at step 66400: 92.090000\n",
      "Minibatch loss at step 66600: 0.027547\n",
      "Minibatch learning rate at step 66600: 0.032353\n",
      "Train accuracy at step 66600: 98.437500\n",
      "Valid accuracy at step 66600: 91.940000\n",
      "Minibatch loss at step 66800: 0.011615\n",
      "Minibatch learning rate at step 66800: 0.032353\n",
      "Train accuracy at step 66800: 100.000000\n",
      "Valid accuracy at step 66800: 92.200000\n",
      "Minibatch loss at step 67000: 0.039242\n",
      "Minibatch learning rate at step 67000: 0.032353\n",
      "Train accuracy at step 67000: 98.437500\n",
      "Valid accuracy at step 67000: 92.300000\n",
      "Minibatch loss at step 67200: 0.025373\n",
      "Minibatch learning rate at step 67200: 0.032353\n",
      "Train accuracy at step 67200: 98.437500\n",
      "Valid accuracy at step 67200: 92.250000\n",
      "Minibatch loss at step 67400: 0.066915\n",
      "Minibatch learning rate at step 67400: 0.032353\n",
      "Train accuracy at step 67400: 98.437500\n",
      "Valid accuracy at step 67400: 92.120000\n",
      "Minibatch loss at step 67600: 0.010643\n",
      "Minibatch learning rate at step 67600: 0.032353\n",
      "Train accuracy at step 67600: 100.000000\n",
      "Valid accuracy at step 67600: 92.190000\n",
      "Minibatch loss at step 67800: 0.036588\n",
      "Minibatch learning rate at step 67800: 0.032353\n",
      "Train accuracy at step 67800: 98.437500\n",
      "Valid accuracy at step 67800: 92.290000\n",
      "Minibatch loss at step 68000: 0.030388\n",
      "Minibatch learning rate at step 68000: 0.032353\n",
      "Train accuracy at step 68000: 100.000000\n",
      "Valid accuracy at step 68000: 92.410000\n",
      "Minibatch loss at step 68200: 0.064013\n",
      "Minibatch learning rate at step 68200: 0.032353\n",
      "Train accuracy at step 68200: 98.437500\n",
      "Valid accuracy at step 68200: 92.160000\n",
      "Minibatch loss at step 68400: 0.093100\n",
      "Minibatch learning rate at step 68400: 0.032353\n",
      "Train accuracy at step 68400: 93.750000\n",
      "Valid accuracy at step 68400: 92.020000\n",
      "Minibatch loss at step 68600: 0.033576\n",
      "Minibatch learning rate at step 68600: 0.032353\n",
      "Train accuracy at step 68600: 98.437500\n",
      "Valid accuracy at step 68600: 92.290000\n",
      "Minibatch loss at step 68800: 0.032550\n",
      "Minibatch learning rate at step 68800: 0.032353\n",
      "Train accuracy at step 68800: 98.437500\n",
      "Valid accuracy at step 68800: 92.000000\n",
      "Minibatch loss at step 69000: 0.001334\n",
      "Minibatch learning rate at step 69000: 0.030736\n",
      "Train accuracy at step 69000: 100.000000\n",
      "Valid accuracy at step 69000: 92.120000\n",
      "Minibatch loss at step 69200: 0.094112\n",
      "Minibatch learning rate at step 69200: 0.030736\n",
      "Train accuracy at step 69200: 96.875000\n",
      "Valid accuracy at step 69200: 92.110000\n",
      "Minibatch loss at step 69400: 0.078639\n",
      "Minibatch learning rate at step 69400: 0.030736\n",
      "Train accuracy at step 69400: 96.875000\n",
      "Valid accuracy at step 69400: 91.950000\n",
      "Minibatch loss at step 69600: 0.066796\n",
      "Minibatch learning rate at step 69600: 0.030736\n",
      "Train accuracy at step 69600: 98.437500\n",
      "Valid accuracy at step 69600: 92.240000\n",
      "Minibatch loss at step 69800: 0.041765\n",
      "Minibatch learning rate at step 69800: 0.030736\n",
      "Train accuracy at step 69800: 98.437500\n",
      "Valid accuracy at step 69800: 91.970000\n",
      "Minibatch loss at step 70000: 0.112250\n",
      "Minibatch learning rate at step 70000: 0.030736\n",
      "Train accuracy at step 70000: 95.312500\n",
      "Valid accuracy at step 70000: 92.500000\n",
      "Minibatch loss at step 70200: 0.020029\n",
      "Minibatch learning rate at step 70200: 0.030736\n",
      "Train accuracy at step 70200: 98.437500\n",
      "Valid accuracy at step 70200: 92.130000\n",
      "Minibatch loss at step 70400: 0.063575\n",
      "Minibatch learning rate at step 70400: 0.030736\n",
      "Train accuracy at step 70400: 96.875000\n",
      "Valid accuracy at step 70400: 92.250000\n",
      "Minibatch loss at step 70600: 0.004714\n",
      "Minibatch learning rate at step 70600: 0.030736\n",
      "Train accuracy at step 70600: 100.000000\n",
      "Valid accuracy at step 70600: 92.340000\n",
      "Minibatch loss at step 70800: 0.003965\n",
      "Minibatch learning rate at step 70800: 0.030736\n",
      "Train accuracy at step 70800: 100.000000\n",
      "Valid accuracy at step 70800: 92.200000\n",
      "Minibatch loss at step 71000: 0.031714\n",
      "Minibatch learning rate at step 71000: 0.030736\n",
      "Train accuracy at step 71000: 98.437500\n",
      "Valid accuracy at step 71000: 92.180000\n",
      "Minibatch loss at step 71200: 0.031532\n",
      "Minibatch learning rate at step 71200: 0.030736\n",
      "Train accuracy at step 71200: 100.000000\n",
      "Valid accuracy at step 71200: 92.050000\n",
      "Minibatch loss at step 71400: 0.002132\n",
      "Minibatch learning rate at step 71400: 0.030736\n",
      "Train accuracy at step 71400: 100.000000\n",
      "Valid accuracy at step 71400: 92.330000\n",
      "Minibatch loss at step 71600: 0.025674\n",
      "Minibatch learning rate at step 71600: 0.030736\n",
      "Train accuracy at step 71600: 98.437500\n",
      "Valid accuracy at step 71600: 92.010000\n",
      "Minibatch loss at step 71800: 0.002370\n",
      "Minibatch learning rate at step 71800: 0.030736\n",
      "Train accuracy at step 71800: 100.000000\n",
      "Valid accuracy at step 71800: 92.410000\n",
      "Minibatch loss at step 72000: 0.010290\n",
      "Minibatch learning rate at step 72000: 0.029199\n",
      "Train accuracy at step 72000: 100.000000\n",
      "Valid accuracy at step 72000: 92.210000\n",
      "Minibatch loss at step 72200: 0.083377\n",
      "Minibatch learning rate at step 72200: 0.029199\n",
      "Train accuracy at step 72200: 96.875000\n",
      "Valid accuracy at step 72200: 91.950000\n",
      "Minibatch loss at step 72400: 0.046430\n",
      "Minibatch learning rate at step 72400: 0.029199\n",
      "Train accuracy at step 72400: 96.875000\n",
      "Valid accuracy at step 72400: 92.100000\n",
      "Minibatch loss at step 72600: 0.024244\n",
      "Minibatch learning rate at step 72600: 0.029199\n",
      "Train accuracy at step 72600: 98.437500\n",
      "Valid accuracy at step 72600: 91.990000\n",
      "Minibatch loss at step 72800: 0.110962\n",
      "Minibatch learning rate at step 72800: 0.029199\n",
      "Train accuracy at step 72800: 96.875000\n",
      "Valid accuracy at step 72800: 92.010000\n",
      "Minibatch loss at step 73000: 0.010490\n",
      "Minibatch learning rate at step 73000: 0.029199\n",
      "Train accuracy at step 73000: 100.000000\n",
      "Valid accuracy at step 73000: 92.080000\n",
      "Minibatch loss at step 73200: 0.002114\n",
      "Minibatch learning rate at step 73200: 0.029199\n",
      "Train accuracy at step 73200: 100.000000\n",
      "Valid accuracy at step 73200: 92.180000\n",
      "Minibatch loss at step 73400: 0.018592\n",
      "Minibatch learning rate at step 73400: 0.029199\n",
      "Train accuracy at step 73400: 98.437500\n",
      "Valid accuracy at step 73400: 92.180000\n",
      "Minibatch loss at step 73600: 0.002798\n",
      "Minibatch learning rate at step 73600: 0.029199\n",
      "Train accuracy at step 73600: 100.000000\n",
      "Valid accuracy at step 73600: 92.160000\n",
      "Minibatch loss at step 73800: 0.001298\n",
      "Minibatch learning rate at step 73800: 0.029199\n",
      "Train accuracy at step 73800: 100.000000\n",
      "Valid accuracy at step 73800: 92.160000\n",
      "Minibatch loss at step 74000: 0.000823\n",
      "Minibatch learning rate at step 74000: 0.029199\n",
      "Train accuracy at step 74000: 100.000000\n",
      "Valid accuracy at step 74000: 92.020000\n",
      "Minibatch loss at step 74200: 0.006765\n",
      "Minibatch learning rate at step 74200: 0.029199\n",
      "Train accuracy at step 74200: 100.000000\n",
      "Valid accuracy at step 74200: 92.330000\n",
      "Minibatch loss at step 74400: 0.013833\n",
      "Minibatch learning rate at step 74400: 0.029199\n",
      "Train accuracy at step 74400: 98.437500\n",
      "Valid accuracy at step 74400: 92.250000\n",
      "Minibatch loss at step 74600: 0.002164\n",
      "Minibatch learning rate at step 74600: 0.029199\n",
      "Train accuracy at step 74600: 100.000000\n",
      "Valid accuracy at step 74600: 92.330000\n",
      "Minibatch loss at step 74800: 0.064584\n",
      "Minibatch learning rate at step 74800: 0.029199\n",
      "Train accuracy at step 74800: 98.437500\n",
      "Valid accuracy at step 74800: 92.460000\n",
      "Minibatch loss at step 75000: 0.029121\n",
      "Minibatch learning rate at step 75000: 0.027739\n",
      "Train accuracy at step 75000: 98.437500\n",
      "Valid accuracy at step 75000: 92.110000\n",
      "Minibatch loss at step 75200: 0.008104\n",
      "Minibatch learning rate at step 75200: 0.027739\n",
      "Train accuracy at step 75200: 100.000000\n",
      "Valid accuracy at step 75200: 92.230000\n",
      "Minibatch loss at step 75400: 0.016474\n",
      "Minibatch learning rate at step 75400: 0.027739\n",
      "Train accuracy at step 75400: 98.437500\n",
      "Valid accuracy at step 75400: 92.180000\n",
      "Minibatch loss at step 75600: 0.027954\n",
      "Minibatch learning rate at step 75600: 0.027739\n",
      "Train accuracy at step 75600: 98.437500\n",
      "Valid accuracy at step 75600: 92.200000\n",
      "Minibatch loss at step 75800: 0.037240\n",
      "Minibatch learning rate at step 75800: 0.027739\n",
      "Train accuracy at step 75800: 98.437500\n",
      "Valid accuracy at step 75800: 92.180000\n",
      "Minibatch loss at step 76000: 0.001004\n",
      "Minibatch learning rate at step 76000: 0.027739\n",
      "Train accuracy at step 76000: 100.000000\n",
      "Valid accuracy at step 76000: 92.180000\n",
      "Minibatch loss at step 76200: 0.014109\n",
      "Minibatch learning rate at step 76200: 0.027739\n",
      "Train accuracy at step 76200: 100.000000\n",
      "Valid accuracy at step 76200: 92.530000\n",
      "Minibatch loss at step 76400: 0.002365\n",
      "Minibatch learning rate at step 76400: 0.027739\n",
      "Train accuracy at step 76400: 100.000000\n",
      "Valid accuracy at step 76400: 92.330000\n",
      "Minibatch loss at step 76600: 0.013970\n",
      "Minibatch learning rate at step 76600: 0.027739\n",
      "Train accuracy at step 76600: 98.437500\n",
      "Valid accuracy at step 76600: 92.290000\n",
      "Minibatch loss at step 76800: 0.010460\n",
      "Minibatch learning rate at step 76800: 0.027739\n",
      "Train accuracy at step 76800: 100.000000\n",
      "Valid accuracy at step 76800: 92.440000\n",
      "Minibatch loss at step 77000: 0.158899\n",
      "Minibatch learning rate at step 77000: 0.027739\n",
      "Train accuracy at step 77000: 98.437500\n",
      "Valid accuracy at step 77000: 92.240000\n",
      "Minibatch loss at step 77200: 0.014051\n",
      "Minibatch learning rate at step 77200: 0.027739\n",
      "Train accuracy at step 77200: 100.000000\n",
      "Valid accuracy at step 77200: 92.430000\n",
      "Minibatch loss at step 77400: 0.002104\n",
      "Minibatch learning rate at step 77400: 0.027739\n",
      "Train accuracy at step 77400: 100.000000\n",
      "Valid accuracy at step 77400: 92.230000\n",
      "Minibatch loss at step 77600: 0.014961\n",
      "Minibatch learning rate at step 77600: 0.027739\n",
      "Train accuracy at step 77600: 100.000000\n",
      "Valid accuracy at step 77600: 92.390000\n",
      "Minibatch loss at step 77800: 0.010208\n",
      "Minibatch learning rate at step 77800: 0.027739\n",
      "Train accuracy at step 77800: 100.000000\n",
      "Valid accuracy at step 77800: 92.360000\n",
      "Minibatch loss at step 78000: 0.001044\n",
      "Minibatch learning rate at step 78000: 0.026352\n",
      "Train accuracy at step 78000: 100.000000\n",
      "Valid accuracy at step 78000: 92.270000\n",
      "Minibatch loss at step 78200: 0.008695\n",
      "Minibatch learning rate at step 78200: 0.026352\n",
      "Train accuracy at step 78200: 100.000000\n",
      "Valid accuracy at step 78200: 92.320000\n",
      "Minibatch loss at step 78400: 0.077712\n",
      "Minibatch learning rate at step 78400: 0.026352\n",
      "Train accuracy at step 78400: 98.437500\n",
      "Valid accuracy at step 78400: 92.340000\n",
      "Minibatch loss at step 78600: 0.000123\n",
      "Minibatch learning rate at step 78600: 0.026352\n",
      "Train accuracy at step 78600: 100.000000\n",
      "Valid accuracy at step 78600: 92.250000\n",
      "Minibatch loss at step 78800: 0.047169\n",
      "Minibatch learning rate at step 78800: 0.026352\n",
      "Train accuracy at step 78800: 98.437500\n",
      "Valid accuracy at step 78800: 92.070000\n",
      "Minibatch loss at step 79000: 0.003364\n",
      "Minibatch learning rate at step 79000: 0.026352\n",
      "Train accuracy at step 79000: 100.000000\n",
      "Valid accuracy at step 79000: 92.350000\n",
      "Minibatch loss at step 79200: 0.043915\n",
      "Minibatch learning rate at step 79200: 0.026352\n",
      "Train accuracy at step 79200: 98.437500\n",
      "Valid accuracy at step 79200: 92.150000\n",
      "Minibatch loss at step 79400: 0.131906\n",
      "Minibatch learning rate at step 79400: 0.026352\n",
      "Train accuracy at step 79400: 98.437500\n",
      "Valid accuracy at step 79400: 92.280000\n",
      "Minibatch loss at step 79600: 0.005378\n",
      "Minibatch learning rate at step 79600: 0.026352\n",
      "Train accuracy at step 79600: 100.000000\n",
      "Valid accuracy at step 79600: 92.330000\n",
      "Minibatch loss at step 79800: 0.003816\n",
      "Minibatch learning rate at step 79800: 0.026352\n",
      "Train accuracy at step 79800: 100.000000\n",
      "Valid accuracy at step 79800: 92.430000\n",
      "Minibatch loss at step 80000: 0.021770\n",
      "Minibatch learning rate at step 80000: 0.026352\n",
      "Train accuracy at step 80000: 98.437500\n",
      "Valid accuracy at step 80000: 92.440000\n",
      "Minibatch loss at step 80200: 0.001339\n",
      "Minibatch learning rate at step 80200: 0.026352\n",
      "Train accuracy at step 80200: 100.000000\n",
      "Valid accuracy at step 80200: 92.280000\n",
      "Minibatch loss at step 80400: 0.000742\n",
      "Minibatch learning rate at step 80400: 0.026352\n",
      "Train accuracy at step 80400: 100.000000\n",
      "Valid accuracy at step 80400: 92.500000\n",
      "Minibatch loss at step 80600: 0.001436\n",
      "Minibatch learning rate at step 80600: 0.026352\n",
      "Train accuracy at step 80600: 100.000000\n",
      "Valid accuracy at step 80600: 92.280000\n",
      "Minibatch loss at step 80800: 0.006563\n",
      "Minibatch learning rate at step 80800: 0.026352\n",
      "Train accuracy at step 80800: 100.000000\n",
      "Valid accuracy at step 80800: 92.350000\n",
      "Minibatch loss at step 81000: 0.013225\n",
      "Minibatch learning rate at step 81000: 0.025034\n",
      "Train accuracy at step 81000: 100.000000\n",
      "Valid accuracy at step 81000: 92.310000\n",
      "Minibatch loss at step 81200: 0.001714\n",
      "Minibatch learning rate at step 81200: 0.025034\n",
      "Train accuracy at step 81200: 100.000000\n",
      "Valid accuracy at step 81200: 92.520000\n",
      "Minibatch loss at step 81400: 0.005887\n",
      "Minibatch learning rate at step 81400: 0.025034\n",
      "Train accuracy at step 81400: 100.000000\n",
      "Valid accuracy at step 81400: 92.260000\n",
      "Minibatch loss at step 81600: 0.026805\n",
      "Minibatch learning rate at step 81600: 0.025034\n",
      "Train accuracy at step 81600: 98.437500\n",
      "Valid accuracy at step 81600: 92.510000\n",
      "Minibatch loss at step 81800: 0.000609\n",
      "Minibatch learning rate at step 81800: 0.025034\n",
      "Train accuracy at step 81800: 100.000000\n",
      "Valid accuracy at step 81800: 92.270000\n",
      "Minibatch loss at step 82000: 0.007589\n",
      "Minibatch learning rate at step 82000: 0.025034\n",
      "Train accuracy at step 82000: 100.000000\n",
      "Valid accuracy at step 82000: 92.290000\n",
      "Minibatch loss at step 82200: 0.045040\n",
      "Minibatch learning rate at step 82200: 0.025034\n",
      "Train accuracy at step 82200: 98.437500\n",
      "Valid accuracy at step 82200: 92.190000\n",
      "Minibatch loss at step 82400: 0.029103\n",
      "Minibatch learning rate at step 82400: 0.025034\n",
      "Train accuracy at step 82400: 100.000000\n",
      "Valid accuracy at step 82400: 92.540000\n",
      "Minibatch loss at step 82600: 0.048484\n",
      "Minibatch learning rate at step 82600: 0.025034\n",
      "Train accuracy at step 82600: 98.437500\n",
      "Valid accuracy at step 82600: 92.490000\n",
      "Minibatch loss at step 82800: 0.009261\n",
      "Minibatch learning rate at step 82800: 0.025034\n",
      "Train accuracy at step 82800: 100.000000\n",
      "Valid accuracy at step 82800: 92.380000\n",
      "Minibatch loss at step 83000: 0.001379\n",
      "Minibatch learning rate at step 83000: 0.025034\n",
      "Train accuracy at step 83000: 100.000000\n",
      "Valid accuracy at step 83000: 92.350000\n",
      "Minibatch loss at step 83200: 0.006107\n",
      "Minibatch learning rate at step 83200: 0.025034\n",
      "Train accuracy at step 83200: 100.000000\n",
      "Valid accuracy at step 83200: 92.350000\n",
      "Minibatch loss at step 83400: 0.003088\n",
      "Minibatch learning rate at step 83400: 0.025034\n",
      "Train accuracy at step 83400: 100.000000\n",
      "Valid accuracy at step 83400: 92.030000\n",
      "Minibatch loss at step 83600: 0.006537\n",
      "Minibatch learning rate at step 83600: 0.025034\n",
      "Train accuracy at step 83600: 100.000000\n",
      "Valid accuracy at step 83600: 92.430000\n",
      "Minibatch loss at step 83800: 0.013896\n",
      "Minibatch learning rate at step 83800: 0.025034\n",
      "Train accuracy at step 83800: 100.000000\n",
      "Valid accuracy at step 83800: 92.350000\n",
      "Minibatch loss at step 84000: 0.014360\n",
      "Minibatch learning rate at step 84000: 0.023783\n",
      "Train accuracy at step 84000: 100.000000\n",
      "Valid accuracy at step 84000: 92.590000\n",
      "Minibatch loss at step 84200: 0.117282\n",
      "Minibatch learning rate at step 84200: 0.023783\n",
      "Train accuracy at step 84200: 96.875000\n",
      "Valid accuracy at step 84200: 92.130000\n",
      "Minibatch loss at step 84400: 0.011593\n",
      "Minibatch learning rate at step 84400: 0.023783\n",
      "Train accuracy at step 84400: 100.000000\n",
      "Valid accuracy at step 84400: 92.390000\n",
      "Minibatch loss at step 84600: 0.003430\n",
      "Minibatch learning rate at step 84600: 0.023783\n",
      "Train accuracy at step 84600: 100.000000\n",
      "Valid accuracy at step 84600: 92.280000\n",
      "Minibatch loss at step 84800: 0.156909\n",
      "Minibatch learning rate at step 84800: 0.023783\n",
      "Train accuracy at step 84800: 96.875000\n",
      "Valid accuracy at step 84800: 92.450000\n",
      "Minibatch loss at step 85000: 0.048772\n",
      "Minibatch learning rate at step 85000: 0.023783\n",
      "Train accuracy at step 85000: 98.437500\n",
      "Valid accuracy at step 85000: 92.070000\n",
      "Minibatch loss at step 85200: 0.025693\n",
      "Minibatch learning rate at step 85200: 0.023783\n",
      "Train accuracy at step 85200: 98.437500\n",
      "Valid accuracy at step 85200: 92.340000\n",
      "Minibatch loss at step 85400: 0.049173\n",
      "Minibatch learning rate at step 85400: 0.023783\n",
      "Train accuracy at step 85400: 98.437500\n",
      "Valid accuracy at step 85400: 92.270000\n",
      "Minibatch loss at step 85600: 0.055093\n",
      "Minibatch learning rate at step 85600: 0.023783\n",
      "Train accuracy at step 85600: 98.437500\n",
      "Valid accuracy at step 85600: 92.490000\n",
      "Minibatch loss at step 85800: 0.000927\n",
      "Minibatch learning rate at step 85800: 0.023783\n",
      "Train accuracy at step 85800: 100.000000\n",
      "Valid accuracy at step 85800: 92.350000\n",
      "Minibatch loss at step 86000: 0.023848\n",
      "Minibatch learning rate at step 86000: 0.023783\n",
      "Train accuracy at step 86000: 100.000000\n",
      "Valid accuracy at step 86000: 92.260000\n",
      "Minibatch loss at step 86200: 0.009536\n",
      "Minibatch learning rate at step 86200: 0.023783\n",
      "Train accuracy at step 86200: 100.000000\n",
      "Valid accuracy at step 86200: 92.330000\n",
      "Minibatch loss at step 86400: 0.045490\n",
      "Minibatch learning rate at step 86400: 0.023783\n",
      "Train accuracy at step 86400: 98.437500\n",
      "Valid accuracy at step 86400: 92.280000\n",
      "Minibatch loss at step 86600: 0.022735\n",
      "Minibatch learning rate at step 86600: 0.023783\n",
      "Train accuracy at step 86600: 98.437500\n",
      "Valid accuracy at step 86600: 92.560000\n",
      "Minibatch loss at step 86800: 0.009259\n",
      "Minibatch learning rate at step 86800: 0.023783\n",
      "Train accuracy at step 86800: 100.000000\n",
      "Valid accuracy at step 86800: 92.380000\n",
      "Minibatch loss at step 87000: 0.041791\n",
      "Minibatch learning rate at step 87000: 0.022594\n",
      "Train accuracy at step 87000: 98.437500\n",
      "Valid accuracy at step 87000: 92.530000\n",
      "Minibatch loss at step 87200: 0.005914\n",
      "Minibatch learning rate at step 87200: 0.022594\n",
      "Train accuracy at step 87200: 100.000000\n",
      "Valid accuracy at step 87200: 92.460000\n",
      "Minibatch loss at step 87400: 0.008274\n",
      "Minibatch learning rate at step 87400: 0.022594\n",
      "Train accuracy at step 87400: 100.000000\n",
      "Valid accuracy at step 87400: 92.510000\n",
      "Minibatch loss at step 87600: 0.013056\n",
      "Minibatch learning rate at step 87600: 0.022594\n",
      "Train accuracy at step 87600: 100.000000\n",
      "Valid accuracy at step 87600: 92.430000\n",
      "Minibatch loss at step 87800: 0.000211\n",
      "Minibatch learning rate at step 87800: 0.022594\n",
      "Train accuracy at step 87800: 100.000000\n",
      "Valid accuracy at step 87800: 92.450000\n",
      "Minibatch loss at step 88000: 0.003568\n",
      "Minibatch learning rate at step 88000: 0.022594\n",
      "Train accuracy at step 88000: 100.000000\n",
      "Valid accuracy at step 88000: 92.590000\n",
      "Minibatch loss at step 88200: 0.023140\n",
      "Minibatch learning rate at step 88200: 0.022594\n",
      "Train accuracy at step 88200: 98.437500\n",
      "Valid accuracy at step 88200: 92.400000\n",
      "Minibatch loss at step 88400: 0.033895\n",
      "Minibatch learning rate at step 88400: 0.022594\n",
      "Train accuracy at step 88400: 98.437500\n",
      "Valid accuracy at step 88400: 92.320000\n",
      "Minibatch loss at step 88600: 0.002382\n",
      "Minibatch learning rate at step 88600: 0.022594\n",
      "Train accuracy at step 88600: 100.000000\n",
      "Valid accuracy at step 88600: 92.360000\n",
      "Minibatch loss at step 88800: 0.007470\n",
      "Minibatch learning rate at step 88800: 0.022594\n",
      "Train accuracy at step 88800: 100.000000\n",
      "Valid accuracy at step 88800: 92.350000\n",
      "Minibatch loss at step 89000: 0.107133\n",
      "Minibatch learning rate at step 89000: 0.022594\n",
      "Train accuracy at step 89000: 98.437500\n",
      "Valid accuracy at step 89000: 92.350000\n",
      "Minibatch loss at step 89200: 0.013185\n",
      "Minibatch learning rate at step 89200: 0.022594\n",
      "Train accuracy at step 89200: 100.000000\n",
      "Valid accuracy at step 89200: 92.580000\n",
      "Minibatch loss at step 89400: 0.019100\n",
      "Minibatch learning rate at step 89400: 0.022594\n",
      "Train accuracy at step 89400: 98.437500\n",
      "Valid accuracy at step 89400: 92.540000\n",
      "Minibatch loss at step 89600: 0.146561\n",
      "Minibatch learning rate at step 89600: 0.022594\n",
      "Train accuracy at step 89600: 98.437500\n",
      "Valid accuracy at step 89600: 92.410000\n",
      "Minibatch loss at step 89800: 0.008921\n",
      "Minibatch learning rate at step 89800: 0.022594\n",
      "Train accuracy at step 89800: 100.000000\n",
      "Valid accuracy at step 89800: 92.540000\n",
      "Minibatch loss at step 90000: 0.000979\n",
      "Minibatch learning rate at step 90000: 0.021464\n",
      "Train accuracy at step 90000: 100.000000\n",
      "Valid accuracy at step 90000: 92.470000\n",
      "Minibatch loss at step 90200: 0.003513\n",
      "Minibatch learning rate at step 90200: 0.021464\n",
      "Train accuracy at step 90200: 100.000000\n",
      "Valid accuracy at step 90200: 92.230000\n",
      "Minibatch loss at step 90400: 0.002934\n",
      "Minibatch learning rate at step 90400: 0.021464\n",
      "Train accuracy at step 90400: 100.000000\n",
      "Valid accuracy at step 90400: 92.290000\n",
      "Minibatch loss at step 90600: 0.004147\n",
      "Minibatch learning rate at step 90600: 0.021464\n",
      "Train accuracy at step 90600: 100.000000\n",
      "Valid accuracy at step 90600: 92.420000\n",
      "Minibatch loss at step 90800: 0.003306\n",
      "Minibatch learning rate at step 90800: 0.021464\n",
      "Train accuracy at step 90800: 100.000000\n",
      "Valid accuracy at step 90800: 92.390000\n",
      "Minibatch loss at step 91000: 0.001023\n",
      "Minibatch learning rate at step 91000: 0.021464\n",
      "Train accuracy at step 91000: 100.000000\n",
      "Valid accuracy at step 91000: 92.430000\n",
      "Minibatch loss at step 91200: 0.012135\n",
      "Minibatch learning rate at step 91200: 0.021464\n",
      "Train accuracy at step 91200: 100.000000\n",
      "Valid accuracy at step 91200: 92.400000\n",
      "Minibatch loss at step 91400: 0.032654\n",
      "Minibatch learning rate at step 91400: 0.021464\n",
      "Train accuracy at step 91400: 98.437500\n",
      "Valid accuracy at step 91400: 92.320000\n",
      "Minibatch loss at step 91600: 0.000111\n",
      "Minibatch learning rate at step 91600: 0.021464\n",
      "Train accuracy at step 91600: 100.000000\n",
      "Valid accuracy at step 91600: 92.170000\n",
      "Minibatch loss at step 91800: 0.055563\n",
      "Minibatch learning rate at step 91800: 0.021464\n",
      "Train accuracy at step 91800: 98.437500\n",
      "Valid accuracy at step 91800: 92.360000\n",
      "Minibatch loss at step 92000: 0.061040\n",
      "Minibatch learning rate at step 92000: 0.021464\n",
      "Train accuracy at step 92000: 98.437500\n",
      "Valid accuracy at step 92000: 92.550000\n",
      "Minibatch loss at step 92200: 0.000799\n",
      "Minibatch learning rate at step 92200: 0.021464\n",
      "Train accuracy at step 92200: 100.000000\n",
      "Valid accuracy at step 92200: 92.410000\n",
      "Minibatch loss at step 92400: 0.000726\n",
      "Minibatch learning rate at step 92400: 0.021464\n",
      "Train accuracy at step 92400: 100.000000\n",
      "Valid accuracy at step 92400: 92.450000\n",
      "Minibatch loss at step 92600: 0.004692\n",
      "Minibatch learning rate at step 92600: 0.021464\n",
      "Train accuracy at step 92600: 100.000000\n",
      "Valid accuracy at step 92600: 92.510000\n",
      "Minibatch loss at step 92800: 0.008693\n",
      "Minibatch learning rate at step 92800: 0.021464\n",
      "Train accuracy at step 92800: 100.000000\n",
      "Valid accuracy at step 92800: 92.470000\n",
      "Minibatch loss at step 93000: 0.001190\n",
      "Minibatch learning rate at step 93000: 0.020391\n",
      "Train accuracy at step 93000: 100.000000\n",
      "Valid accuracy at step 93000: 92.540000\n",
      "Minibatch loss at step 93200: 0.001201\n",
      "Minibatch learning rate at step 93200: 0.020391\n",
      "Train accuracy at step 93200: 100.000000\n",
      "Valid accuracy at step 93200: 92.500000\n",
      "Minibatch loss at step 93400: 0.003254\n",
      "Minibatch learning rate at step 93400: 0.020391\n",
      "Train accuracy at step 93400: 100.000000\n",
      "Valid accuracy at step 93400: 92.490000\n",
      "Minibatch loss at step 93600: 0.081919\n",
      "Minibatch learning rate at step 93600: 0.020391\n",
      "Train accuracy at step 93600: 98.437500\n",
      "Valid accuracy at step 93600: 92.350000\n",
      "Minibatch loss at step 93800: 0.032758\n",
      "Minibatch learning rate at step 93800: 0.020391\n",
      "Train accuracy at step 93800: 98.437500\n",
      "Valid accuracy at step 93800: 92.420000\n",
      "Minibatch loss at step 94000: 0.009855\n",
      "Minibatch learning rate at step 94000: 0.020391\n",
      "Train accuracy at step 94000: 100.000000\n",
      "Valid accuracy at step 94000: 92.610000\n",
      "Minibatch loss at step 94200: 0.012748\n",
      "Minibatch learning rate at step 94200: 0.020391\n",
      "Train accuracy at step 94200: 100.000000\n",
      "Valid accuracy at step 94200: 92.500000\n",
      "Minibatch loss at step 94400: 0.055079\n",
      "Minibatch learning rate at step 94400: 0.020391\n",
      "Train accuracy at step 94400: 98.437500\n",
      "Valid accuracy at step 94400: 92.450000\n",
      "Minibatch loss at step 94600: 0.001334\n",
      "Minibatch learning rate at step 94600: 0.020391\n",
      "Train accuracy at step 94600: 100.000000\n",
      "Valid accuracy at step 94600: 92.380000\n",
      "Minibatch loss at step 94800: 0.038029\n",
      "Minibatch learning rate at step 94800: 0.020391\n",
      "Train accuracy at step 94800: 98.437500\n",
      "Valid accuracy at step 94800: 92.330000\n",
      "Minibatch loss at step 95000: 0.000707\n",
      "Minibatch learning rate at step 95000: 0.020391\n",
      "Train accuracy at step 95000: 100.000000\n",
      "Valid accuracy at step 95000: 92.560000\n",
      "Test accuracy: 96.9%\n"
     ]
    }
   ],
   "source": [
    "num_steps = 95001\n",
    "\n",
    "with tf.Session(graph=graph) as session:\n",
    "  tf.initialize_all_variables().run()\n",
    "  lossVec = []\n",
    "  trainAcc = []\n",
    "  validAcc = []\n",
    "  lrVec = []\n",
    "  print('Initialized')\n",
    "  for step in range(num_steps):\n",
    "    offset = (step * batch_size) % (train_labels.shape[0] - batch_size)\n",
    "    batch_data = train_dataset[offset:(offset + batch_size), :, :, :]\n",
    "    batch_labels = train_labels[offset:(offset + batch_size), :]\n",
    "    feed_dict = {tf_train_dataset : batch_data, tf_train_labels : batch_labels}\n",
    "    _, l, lr, predictions = session.run([optimizer, loss, learning_rate, train_prediction], feed_dict=feed_dict)\n",
    "    lossVec.append(l)\n",
    "    lrVec.append(lr)\n",
    "    if (step % 200 == 0):\n",
    "      print(\"Minibatch loss at step %d: %f\" % (step, l))\n",
    "      print(\"Minibatch learning rate at step %d: %f\" % (step, lr))\n",
    "      trainAccuracy = accuracy(predictions, batch_labels)\n",
    "      print(\"Train accuracy at step %d: %f\"% (step, trainAccuracy))\n",
    "      trainAcc.append(trainAccuracy)\n",
    "      validAccuracy = accuracy(valid_prediction.eval(), valid_labels)\n",
    "      print(\"Valid accuracy at step %d: %f\"% (step, validAccuracy))\n",
    "      validAcc.append(validAccuracy)\n",
    "  print('Test accuracy: %.1f%%' % accuracy(test_prediction.eval(), test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Saving the objects:\n",
    "with open('Ex_10.pickle', 'w') as f:\n",
    "    pickle.dump([lossVec, lrVec, trainAcc, validAcc], f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "# Getting back the objects:\n",
    "with open('Ex_10.pickle') as f:\n",
    "    lossVec, lrVec, trainAcc, validAcc = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.clf()\n",
    "plt.plot(lossVec)\n",
    "plt.xlabel('Steps')\n",
    "plt.ylabel('Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.clf()\n",
    "plt.plot(lrVec)\n",
    "plt.xlabel('Steps')\n",
    "plt.ylabel('Learning Rate')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.clf()\n",
    "plt.plot(xrange(0,30001,200),trainAcc, label= \"Minibatch Accuracy\")\n",
    "plt.plot(xrange(0,30001,200),validAcc, label= \"Valid Accuracy\")\n",
    "plt.xlabel('Steps')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend(loc=4)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "default_view": {},
   "name": "4_convolutions.ipynb",
   "provenance": [],
   "version": "0.3.2",
   "views": {}
  },
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
