{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kR-4eNdK6lYS"
   },
   "source": [
    "Deep Learning\n",
    "=============\n",
    "\n",
    "Assignment 2\n",
    "------------\n",
    "\n",
    "Previously in `1_notmnist.ipynb`, we created a pickle with formatted datasets for training, development and testing on the [notMNIST dataset](http://yaroslavvb.blogspot.com/2011/09/notmnist-dataset.html).\n",
    "\n",
    "The goal of this assignment is to progressively train deeper and more accurate models using TensorFlow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "cellView": "both",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": false,
    "id": "JLpLa8Jt7Vu4"
   },
   "outputs": [],
   "source": [
    "# These are all the modules we'll be using later. Make sure you can import them\n",
    "# before proceeding further.\n",
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from six.moves import cPickle as pickle\n",
    "from six.moves import range"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1HrCK6e17WzV"
   },
   "source": [
    "First reload the data we generated in `1_notmnist.ipynb`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "cellView": "both",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "collapsed": false,
    "executionInfo": {
     "elapsed": 19456,
     "status": "ok",
     "timestamp": 1449847956073,
     "user": {
      "color": "",
      "displayName": "",
      "isAnonymous": false,
      "isMe": true,
      "permissionId": "",
      "photoUrl": "",
      "sessionId": "0",
      "userId": ""
     },
     "user_tz": 480
    },
    "id": "y3-cj1bpmuxc",
    "outputId": "0ddb1607-1fc4-4ddb-de28-6c7ab7fb0c33"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set (200000, 28, 28) (200000,)\n",
      "Validation set (10000, 28, 28) (10000,)\n",
      "Test set (10000, 28, 28) (10000,)\n"
     ]
    }
   ],
   "source": [
    "pickle_file = 'notMNIST_200k.pickle'\n",
    "\n",
    "with open(pickle_file, 'rb') as f:\n",
    "  save = pickle.load(f)\n",
    "  train_dataset = save['train_dataset']\n",
    "  train_labels = save['train_labels']\n",
    "  valid_dataset = save['valid_dataset']\n",
    "  valid_labels = save['valid_labels']\n",
    "  test_dataset = save['test_dataset']\n",
    "  test_labels = save['test_labels']\n",
    "  del save  # hint to help gc free up memory\n",
    "  print('Training set', train_dataset.shape, train_labels.shape)\n",
    "  print('Validation set', valid_dataset.shape, valid_labels.shape)\n",
    "  print('Test set', test_dataset.shape, test_labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "L7aHrm6nGDMB"
   },
   "source": [
    "Reformat into a shape that's more adapted to the models we're going to train:\n",
    "- data as a flat matrix,\n",
    "- labels as float 1-hot encodings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "cellView": "both",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "collapsed": false,
    "executionInfo": {
     "elapsed": 19723,
     "status": "ok",
     "timestamp": 1449847956364,
     "user": {
      "color": "",
      "displayName": "",
      "isAnonymous": false,
      "isMe": true,
      "permissionId": "",
      "photoUrl": "",
      "sessionId": "0",
      "userId": ""
     },
     "user_tz": 480
    },
    "id": "IRSyYiIIGIzS",
    "outputId": "2ba0fc75-1487-4ace-a562-cf81cae82793"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set (200000, 784) (200000, 10)\n",
      "Validation set (10000, 784) (10000, 10)\n",
      "Test set (10000, 784) (10000, 10)\n"
     ]
    }
   ],
   "source": [
    "import pdb\n",
    "\n",
    "image_size = 28\n",
    "num_labels = 10\n",
    "\n",
    "def reformat(dataset, labels):\n",
    "  #pdb.set_trace()\n",
    "  dataset = dataset.reshape((-1, image_size * image_size)).astype(np.float32)\n",
    "  # Map 0 to [1.0, 0.0, 0.0 ...], 1 to [0.0, 1.0, 0.0 ...]\n",
    "  labels = (np.arange(num_labels) == labels[:,None]).astype(np.float32)\n",
    "  return dataset, labels\n",
    "train_dataset, train_labels = reformat(train_dataset, train_labels)\n",
    "valid_dataset, valid_labels = reformat(valid_dataset, valid_labels)\n",
    "test_dataset, test_labels = reformat(test_dataset, test_labels)\n",
    "print('Training set', train_dataset.shape, train_labels.shape)\n",
    "print('Validation set', valid_dataset.shape, valid_labels.shape)\n",
    "print('Test set', test_dataset.shape, test_labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nCLVqyQ5vPPH"
   },
   "source": [
    "We're first going to train a multinomial logistic regression using simple gradient descent.\n",
    "\n",
    "TensorFlow works like this:\n",
    "* First you describe the computation that you want to see performed: what the inputs, the variables, and the operations look like. These get created as nodes over a computation graph. This description is all contained within the block below:\n",
    "\n",
    "      with graph.as_default():\n",
    "          ...\n",
    "\n",
    "* Then you can run the operations on this graph as many times as you want by calling `session.run()`, providing it outputs to fetch from the graph that get returned. This runtime operation is all contained in the block below:\n",
    "\n",
    "      with tf.Session(graph=graph) as session:\n",
    "          ...\n",
    "\n",
    "Let's load all the data into TensorFlow and build the computation graph corresponding to our training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "cellView": "both",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": false,
    "id": "Nfv39qvtvOl_"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/site-packages/ipykernel/__main__.py:11: DeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
      "/usr/local/lib/python2.7/site-packages/ipykernel/__main__.py:12: DeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n"
     ]
    }
   ],
   "source": [
    "# With gradient descent training, even this much data is prohibitive.\n",
    "# Subset the training data for faster turnaround.\n",
    "train_subset = 10000. # Run all 200k training data\n",
    "\n",
    "graph = tf.Graph()\n",
    "with graph.as_default():\n",
    "\n",
    "  # Input data.\n",
    "  # Load the training, validation and test data into constants that are\n",
    "  # attached to the graph.\n",
    "  tf_train_dataset = tf.constant(train_dataset[:train_subset, :]) #train_dataset[:train_subset, :]\n",
    "  tf_train_labels = tf.constant(train_labels[:train_subset, :])\n",
    "  tf_valid_dataset = tf.constant(valid_dataset)\n",
    "  tf_test_dataset = tf.constant(test_dataset)\n",
    "  \n",
    "  # Variables.\n",
    "  # These are the parameters that we are going to be training. The weight\n",
    "  # matrix will be initialized using random valued following a (truncated)\n",
    "  # normal distribution. The biases get initialized to zero.\n",
    "  weights = tf.Variable(tf.truncated_normal([image_size * image_size, num_labels]))\n",
    "  biases = tf.Variable(tf.zeros([num_labels]))\n",
    "  \n",
    "  # Training computation.\n",
    "  # We multiply the inputs with the weight matrix, and add biases. We compute\n",
    "  # the softmax and cross-entropy (it's one operation in TensorFlow, because\n",
    "  # it's very common, and it can be optimized). We take the average of this\n",
    "  # cross-entropy across all training examples: that's our loss.\n",
    "  logits = tf.matmul(tf_train_dataset, weights) + biases\n",
    "  loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits, tf_train_labels))\n",
    "  \n",
    "  # Optimizer.\n",
    "  # We are going to find the minimum of this loss using gradient descent.\n",
    "  optimizer = tf.train.GradientDescentOptimizer(0.5).minimize(loss)\n",
    "  \n",
    "  # Predictions for the training, validation, and test data.\n",
    "  # These are not part of training, but merely here so that we can report\n",
    "  # accuracy figures as we train.\n",
    "  train_prediction = tf.nn.softmax(logits)\n",
    "  valid_prediction = tf.nn.softmax(tf.matmul(tf_valid_dataset, weights) + biases)\n",
    "  test_prediction = tf.nn.softmax(tf.matmul(tf_test_dataset, weights) + biases)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KQcL4uqISHjP"
   },
   "source": [
    "Let's run this computation and iterate:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "cellView": "both",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "output_extras": [
      {
       "item_id": 9
      }
     ]
    },
    "colab_type": "code",
    "collapsed": false,
    "executionInfo": {
     "elapsed": 57454,
     "status": "ok",
     "timestamp": 1449847994134,
     "user": {
      "color": "",
      "displayName": "",
      "isAnonymous": false,
      "isMe": true,
      "permissionId": "",
      "photoUrl": "",
      "sessionId": "0",
      "userId": ""
     },
     "user_tz": 480
    },
    "id": "z2cjdenH869W",
    "outputId": "4c037ba1-b526-4d8e-e632-91e2a0333267"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized\n",
      "Test accuracy: 83.5%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/site-packages/ipykernel/__main__.py:22: DeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n"
     ]
    }
   ],
   "source": [
    "num_steps = 3001\n",
    "\n",
    "def accuracy(predictions, labels):\n",
    "  return (100.0 * np.sum(np.argmax(predictions, 1) == np.argmax(labels, 1))\n",
    "          / predictions.shape[0])\n",
    "\n",
    "with tf.Session(graph=graph) as session:\n",
    "  # This is a one-time operation which ensures the parameters get initialized as\n",
    "  # we described in the graph: random weights for the matrix, zeros for the\n",
    "  # biases. \n",
    "  tf.initialize_all_variables().run()\n",
    "  lossVec = []\n",
    "  trainAcc = []\n",
    "  validAcc = []\n",
    "  print('Initialized')\n",
    "  for step in range(num_steps):\n",
    "    # Run the computations. We tell .run() that we want to run the optimizer,\n",
    "    # and get the loss value and the training predictions returned as numpy\n",
    "    # arrays.\n",
    "    _, l, predictions = session.run([optimizer, loss, train_prediction])\n",
    "    lossVec.append(l)\n",
    "    trainAcc.append(accuracy(predictions, train_labels[:train_subset, :]))\n",
    "    validAcc.append(accuracy(valid_prediction.eval(), valid_labels))\n",
    "    \"\"\"\n",
    "    if (step % 100 == 0):\n",
    "      print('Loss at step %d: %f' % (step, l))\n",
    "      print('Training accuracy: %.1f%%' % accuracy(predictions, train_labels[:train_subset, :]))\n",
    "      # Calling .eval() on valid_prediction is basically like calling run(), but\n",
    "      # just to get that one numpy array. Note that it recomputes all its graph\n",
    "      # dependencies.\n",
    "      print('Validation accuracy: %.1f%%' % accuracy(valid_prediction.eval(), valid_labels))\n",
    "    \"\"\"\n",
    "  print('Test accuracy: %.1f%%' % accuracy(test_prediction.eval(), test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.clf()\n",
    "plt.plot(lossVec)\n",
    "plt.xlabel('Steps')\n",
    "plt.ylabel('Loss')\n",
    "plt.show()\n",
    "\n",
    "plt.clf()\n",
    "plt.plot(trainAcc, label= \"Training Accuracy\")\n",
    "plt.plot(validAcc, label= \"Valid Accuracy\")\n",
    "plt.xlabel('Steps')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend(loc=4)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "x68f-hxRGm3H"
   },
   "source": [
    "Let's now switch to stochastic gradient descent training instead, which is much faster.\n",
    "\n",
    "The graph will be similar, except that instead of holding all the training data into a constant node, we create a `Placeholder` node which will be fed actual data at every call of `sesion.run()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "cellView": "both",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": false,
    "id": "qhPMzWYRGrzM"
   },
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "\n",
    "graph = tf.Graph()\n",
    "with graph.as_default():\n",
    "\n",
    "  # Input data. For the training data, we use a placeholder that will be fed\n",
    "  # at run time with a training minibatch.\n",
    "  tf_train_dataset = tf.placeholder(tf.float32,shape=(batch_size, image_size * image_size))\n",
    "  tf_train_labels = tf.placeholder(tf.float32, shape=(batch_size, num_labels))\n",
    "  tf_valid_dataset = tf.constant(valid_dataset)\n",
    "  tf_test_dataset = tf.constant(test_dataset)\n",
    "  \n",
    "  # Variables.\n",
    "  weights = tf.Variable(tf.truncated_normal([image_size * image_size, num_labels]))\n",
    "  biases = tf.Variable(tf.zeros([num_labels]))\n",
    "  \n",
    "  # Training computation.\n",
    "  logits = tf.matmul(tf_train_dataset, weights) + biases\n",
    "  loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits, tf_train_labels))\n",
    "    \n",
    "  # Optimizer.\n",
    "  optimizer = tf.train.GradientDescentOptimizer(0.5).minimize(loss)\n",
    "  \n",
    "  # Predictions for the training, validation, and test data.\n",
    "  train_prediction = tf.nn.softmax(logits)\n",
    "  valid_prediction = tf.nn.softmax(tf.matmul(tf_valid_dataset, weights) + biases)\n",
    "  test_prediction = tf.nn.softmax(tf.matmul(tf_test_dataset, weights) + biases)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XmVZESmtG4JH"
   },
   "source": [
    "Let's run it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "cellView": "both",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "output_extras": [
      {
       "item_id": 6
      }
     ]
    },
    "colab_type": "code",
    "collapsed": false,
    "executionInfo": {
     "elapsed": 66292,
     "status": "ok",
     "timestamp": 1449848003013,
     "user": {
      "color": "",
      "displayName": "",
      "isAnonymous": false,
      "isMe": true,
      "permissionId": "",
      "photoUrl": "",
      "sessionId": "0",
      "userId": ""
     },
     "user_tz": 480
    },
    "id": "FoF91pknG_YW",
    "outputId": "d255c80e-954d-4183-ca1c-c7333ce91d0a",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized\n",
      "Test accuracy: 86.8%\n"
     ]
    }
   ],
   "source": [
    "num_steps = 3001\n",
    "\n",
    "with tf.Session(graph=graph) as session:\n",
    "  tf.initialize_all_variables().run()\n",
    "  lossVec = []\n",
    "  trainAcc = []\n",
    "  validAcc = []\n",
    "  print(\"Initialized\")\n",
    "  for step in range(num_steps):\n",
    "    # Pick an offset within the training data, which has been randomized.\n",
    "    # Note: we could use better randomization across epochs.\n",
    "    offset = (step * batch_size) % (train_labels.shape[0] - batch_size)\n",
    "    # Generate a minibatch.\n",
    "    batch_data = train_dataset[offset:(offset + batch_size), :]\n",
    "    batch_labels = train_labels[offset:(offset + batch_size), :]\n",
    "    # Prepare a dictionary telling the session where to feed the minibatch.\n",
    "    # The key of the dictionary is the placeholder node of the graph to be fed,\n",
    "    # and the value is the numpy array to feed to it.\n",
    "    feed_dict = {tf_train_dataset : batch_data, tf_train_labels : batch_labels}\n",
    "    _, l, predictions = session.run(\n",
    "      [optimizer, loss, train_prediction], feed_dict=feed_dict)\n",
    "    \"\"\"\n",
    "    if (step % 500 == 0):\n",
    "      print(\"Minibatch loss at step %d: %f\" % (step, l))\n",
    "      print(\"Minibatch accuracy: %.1f%%\" % accuracy(predictions, batch_labels))\n",
    "      print(\"Validation accuracy: %.1f%%\" % accuracy(\n",
    "        valid_prediction.eval(), valid_labels))\n",
    "    \"\"\"\n",
    "    lossVec.append(l)\n",
    "    trainAcc.append(accuracy(predictions, batch_labels))\n",
    "    validAcc.append(accuracy(valid_prediction.eval(), valid_labels))\n",
    "  print(\"Test accuracy: %.1f%%\" % accuracy(test_prediction.eval(), test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.clf()\n",
    "plt.plot(lossVec)\n",
    "plt.xlabel('Steps')\n",
    "plt.ylabel('Loss')\n",
    "plt.show()\n",
    "\n",
    "plt.clf()\n",
    "plt.plot(trainAcc, label= \"Minibatch Accuracy\")\n",
    "plt.plot(validAcc, label= \"Valid Accuracy\")\n",
    "plt.xlabel('Steps')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend(loc=4)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7omWxtvLLxik"
   },
   "source": [
    "---\n",
    "Problem\n",
    "-------\n",
    "\n",
    "Turn the logistic regression example with SGD into a 1-hidden layer neural network with rectified linear units (nn.relu()) and 1024 hidden nodes. This model should improve your validation / test accuracy.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "hidden_layer_size = 1024\n",
    "\n",
    "graph = tf.Graph()\n",
    "with graph.as_default():\n",
    "\n",
    "  # Input data. For the training data, we use a placeholder that will be fed\n",
    "  # at run time with a training minibatch.\n",
    "  tf_train_dataset = tf.placeholder(tf.float32,shape=(batch_size, image_size * image_size))\n",
    "  tf_train_labels = tf.placeholder(tf.float32, shape=(batch_size, num_labels))\n",
    "  tf_valid_dataset = tf.constant(valid_dataset)\n",
    "  tf_test_dataset = tf.constant(test_dataset)\n",
    "  \n",
    "  # Variables.\n",
    "  weightsHidden = tf.Variable(tf.truncated_normal([image_size * image_size, hidden_layer_size]))\n",
    "  biasesHidden = tf.Variable(tf.zeros([hidden_layer_size]))\n",
    "\n",
    "  weights = tf.Variable(tf.truncated_normal([hidden_layer_size, num_labels]))\n",
    "  biases = tf.Variable(tf.zeros([num_labels]))\n",
    "    \n",
    "  logitsHidden = tf.matmul(tf_train_dataset, weightsHidden) + biasesHidden\n",
    "  hiddenLayer = tf.nn.relu(logitsHidden)\n",
    "\n",
    "  # Training computation.\n",
    "  logits = tf.matmul(hiddenLayer, weights) + biases\n",
    "  loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits, tf_train_labels))\n",
    " \n",
    "  # Optimizer.\n",
    "  optimizer = tf.train.GradientDescentOptimizer(0.5).minimize(loss)\n",
    "  \n",
    "  # Predictions for the training, validation, and test data.\n",
    "  train_prediction = tf.nn.softmax(logits)\n",
    "    \n",
    "  valid_hidden = tf.nn.relu(tf.matmul(tf_valid_dataset, weightsHidden) + biasesHidden)\n",
    "  valid_logits = tf.matmul(valid_hidden, weights) + biases\n",
    "  valid_prediction = tf.nn.softmax(valid_logits)\n",
    "    \n",
    "  test_hidden = tf.nn.relu(tf.matmul(tf_test_dataset, weightsHidden) + biasesHidden)\n",
    "  test_logits = tf.matmul(test_hidden, weights) + biases\n",
    "  test_prediction = tf.nn.softmax(test_logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized\n",
      "Minibatch loss at step 0: 294.453857\n",
      "Minibatch loss at step 100: 25.903187\n",
      "Minibatch loss at step 200: 49.014881\n",
      "Minibatch loss at step 300: 20.449303\n",
      "Minibatch loss at step 400: 32.304825\n",
      "Minibatch loss at step 500: 19.614372\n",
      "Minibatch loss at step 600: 12.178806\n",
      "Minibatch loss at step 700: 31.139439\n",
      "Minibatch loss at step 800: 6.888573\n",
      "Minibatch loss at step 900: 8.415754\n",
      "Minibatch loss at step 1000: 11.650371\n",
      "Minibatch loss at step 1100: 18.979389\n",
      "Minibatch loss at step 1200: 16.012829\n",
      "Minibatch loss at step 1300: 7.588346\n",
      "Minibatch loss at step 1400: 7.024184\n",
      "Minibatch loss at step 1500: 7.070252\n",
      "Minibatch loss at step 1600: 4.128470\n",
      "Minibatch loss at step 1700: 1.147847\n",
      "Minibatch loss at step 1800: 2.568570\n",
      "Minibatch loss at step 1900: 6.358519\n",
      "Minibatch loss at step 2000: 2.701953\n",
      "Minibatch loss at step 2100: 2.706118\n",
      "Minibatch loss at step 2200: 4.188989\n",
      "Minibatch loss at step 2300: 7.529970\n",
      "Minibatch loss at step 2400: 3.524499\n",
      "Minibatch loss at step 2500: 2.975404\n",
      "Minibatch loss at step 2600: 11.536954\n",
      "Minibatch loss at step 2700: 3.401830\n",
      "Minibatch loss at step 2800: 7.373300\n",
      "Minibatch loss at step 2900: 3.816592\n",
      "Minibatch loss at step 3000: 1.548020\n",
      "Minibatch loss at step 3100: 12.579281\n",
      "Minibatch loss at step 3200: 1.327483\n",
      "Minibatch loss at step 3300: 2.814205\n",
      "Minibatch loss at step 3400: 1.480454\n",
      "Minibatch loss at step 3500: 3.281763\n",
      "Minibatch loss at step 3600: 2.499498\n",
      "Minibatch loss at step 3700: 2.805440\n",
      "Minibatch loss at step 3800: 2.523272\n",
      "Minibatch loss at step 3900: 2.252828\n",
      "Minibatch loss at step 4000: 3.336914\n",
      "Minibatch loss at step 4100: 3.529598\n",
      "Minibatch loss at step 4200: 1.849236\n",
      "Minibatch loss at step 4300: 1.776566\n",
      "Minibatch loss at step 4400: 1.006235\n",
      "Minibatch loss at step 4500: 4.424067\n",
      "Minibatch loss at step 4600: 1.442372\n",
      "Minibatch loss at step 4700: 1.759334\n",
      "Minibatch loss at step 4800: 1.978947\n",
      "Minibatch loss at step 4900: 1.013080\n",
      "Minibatch loss at step 5000: 3.551954\n",
      "Minibatch loss at step 5100: 2.012565\n",
      "Minibatch loss at step 5200: 2.108474\n",
      "Minibatch loss at step 5300: 5.354352\n",
      "Minibatch loss at step 5400: 1.795453\n",
      "Minibatch loss at step 5500: 1.874335\n",
      "Minibatch loss at step 5600: 1.079604\n",
      "Minibatch loss at step 5700: 1.518193\n",
      "Minibatch loss at step 5800: 1.122317\n",
      "Minibatch loss at step 5900: 2.850909\n",
      "Minibatch loss at step 6000: 1.430222\n",
      "Minibatch loss at step 6100: 1.861188\n",
      "Minibatch loss at step 6200: 1.016305\n",
      "Minibatch loss at step 6300: 2.022735\n",
      "Minibatch loss at step 6400: 1.072056\n",
      "Minibatch loss at step 6500: 1.910763\n",
      "Minibatch loss at step 6600: 0.879029\n",
      "Minibatch loss at step 6700: 0.756726\n",
      "Minibatch loss at step 6800: 12.065266\n",
      "Minibatch loss at step 6900: 1.410707\n",
      "Minibatch loss at step 7000: 3.251422\n",
      "Minibatch loss at step 7100: 1.039092\n",
      "Minibatch loss at step 7200: 2.498635\n",
      "Minibatch loss at step 7300: 1.203728\n",
      "Minibatch loss at step 7400: 1.451530\n",
      "Minibatch loss at step 7500: 1.063941\n",
      "Minibatch loss at step 7600: 0.893496\n",
      "Minibatch loss at step 7700: 0.889989\n",
      "Minibatch loss at step 7800: 2.124074\n",
      "Minibatch loss at step 7900: 0.794723\n",
      "Minibatch loss at step 8000: 3.935196\n",
      "Minibatch loss at step 8100: 0.364151\n",
      "Minibatch loss at step 8200: 0.753234\n",
      "Minibatch loss at step 8300: 0.656651\n",
      "Minibatch loss at step 8400: 1.319725\n",
      "Minibatch loss at step 8500: 0.764236\n",
      "Minibatch loss at step 8600: 1.283152\n",
      "Minibatch loss at step 8700: 1.622744\n",
      "Minibatch loss at step 8800: 1.351705\n",
      "Minibatch loss at step 8900: 0.982598\n",
      "Minibatch loss at step 9000: 2.957081\n",
      "Minibatch loss at step 9100: 1.459604\n",
      "Minibatch loss at step 9200: 1.044530\n",
      "Minibatch loss at step 9300: 2.270825\n",
      "Minibatch loss at step 9400: 0.720741\n",
      "Minibatch loss at step 9500: 1.267664\n",
      "Minibatch loss at step 9600: 0.983369\n",
      "Minibatch loss at step 9700: 0.836543\n",
      "Minibatch loss at step 9800: 0.470976\n",
      "Minibatch loss at step 9900: 2.365846\n",
      "Minibatch loss at step 10000: 1.635082\n",
      "Minibatch loss at step 10100: 0.716806\n",
      "Minibatch loss at step 10200: 1.004128\n",
      "Minibatch loss at step 10300: 0.815724\n",
      "Minibatch loss at step 10400: 0.418800\n",
      "Minibatch loss at step 10500: 0.821494\n",
      "Minibatch loss at step 10600: 1.315052\n",
      "Minibatch loss at step 10700: 1.696714\n",
      "Minibatch loss at step 10800: 0.445419\n",
      "Minibatch loss at step 10900: 4.225011\n",
      "Minibatch loss at step 11000: 1.528905\n",
      "Minibatch loss at step 11100: 0.467783\n",
      "Minibatch loss at step 11200: 0.796314\n",
      "Minibatch loss at step 11300: 0.963287\n",
      "Minibatch loss at step 11400: 0.897549\n",
      "Minibatch loss at step 11500: 2.050446\n",
      "Minibatch loss at step 11600: 0.410985\n",
      "Minibatch loss at step 11700: 0.838445\n",
      "Minibatch loss at step 11800: 1.270450\n",
      "Minibatch loss at step 11900: 1.602324\n",
      "Minibatch loss at step 12000: 0.739151\n",
      "Minibatch loss at step 12100: 1.725303\n",
      "Minibatch loss at step 12200: 0.477759\n",
      "Minibatch loss at step 12300: 0.430718\n",
      "Minibatch loss at step 12400: 0.942060\n",
      "Minibatch loss at step 12500: 0.525136\n",
      "Minibatch loss at step 12600: 0.957376\n",
      "Minibatch loss at step 12700: 1.565584\n",
      "Minibatch loss at step 12800: 0.270184\n",
      "Minibatch loss at step 12900: 1.207797\n",
      "Minibatch loss at step 13000: 1.392238\n",
      "Minibatch loss at step 13100: 1.824334\n",
      "Minibatch loss at step 13200: 0.887912\n",
      "Minibatch loss at step 13300: 0.784245\n",
      "Minibatch loss at step 13400: 0.346112\n",
      "Minibatch loss at step 13500: 0.499562\n",
      "Minibatch loss at step 13600: 0.681927\n",
      "Minibatch loss at step 13700: 0.605343\n",
      "Minibatch loss at step 13800: 0.870073\n",
      "Minibatch loss at step 13900: 0.843869\n",
      "Minibatch loss at step 14000: 0.777867\n",
      "Minibatch loss at step 14100: 0.966982\n",
      "Minibatch loss at step 14200: 0.796190\n",
      "Minibatch loss at step 14300: 0.541319\n",
      "Minibatch loss at step 14400: 1.049681\n",
      "Minibatch loss at step 14500: 1.371041\n",
      "Minibatch loss at step 14600: 0.453637\n",
      "Minibatch loss at step 14700: 0.756912\n",
      "Minibatch loss at step 14800: 0.244506\n",
      "Minibatch loss at step 14900: 0.577720\n",
      "Minibatch loss at step 15000: 0.347514\n",
      "Minibatch loss at step 15100: 1.168377\n",
      "Minibatch loss at step 15200: 1.147576\n",
      "Minibatch loss at step 15300: 0.235603\n",
      "Minibatch loss at step 15400: 0.697287\n",
      "Minibatch loss at step 15500: 0.182077\n",
      "Minibatch loss at step 15600: 0.291727\n",
      "Minibatch loss at step 15700: 0.530012\n",
      "Minibatch loss at step 15800: 0.649417\n",
      "Minibatch loss at step 15900: 0.349189\n",
      "Minibatch loss at step 16000: 0.623704\n",
      "Minibatch loss at step 16100: 0.225557\n",
      "Minibatch loss at step 16200: 0.644796\n",
      "Minibatch loss at step 16300: 0.771679\n",
      "Minibatch loss at step 16400: 0.233538\n",
      "Minibatch loss at step 16500: 0.364133\n",
      "Minibatch loss at step 16600: 0.653934\n",
      "Minibatch loss at step 16700: 0.375447\n",
      "Minibatch loss at step 16800: 0.628156\n",
      "Minibatch loss at step 16900: 0.248846\n",
      "Minibatch loss at step 17000: 0.344036\n",
      "Minibatch loss at step 17100: 0.985513\n",
      "Minibatch loss at step 17200: 0.275376\n",
      "Minibatch loss at step 17300: 0.494754\n",
      "Minibatch loss at step 17400: 0.510059\n",
      "Minibatch loss at step 17500: 0.117899\n",
      "Minibatch loss at step 17600: 0.384146\n",
      "Minibatch loss at step 17700: 0.162731\n",
      "Minibatch loss at step 17800: 0.330041\n",
      "Minibatch loss at step 17900: 0.511874\n",
      "Minibatch loss at step 18000: 0.290963\n",
      "Minibatch loss at step 18100: 0.805215\n",
      "Minibatch loss at step 18200: 0.990127\n",
      "Minibatch loss at step 18300: 0.205956\n",
      "Minibatch loss at step 18400: 0.670277\n",
      "Minibatch loss at step 18500: 0.259705\n",
      "Minibatch loss at step 18600: 0.496681\n",
      "Minibatch loss at step 18700: 0.473148\n",
      "Minibatch loss at step 18800: 0.412306\n",
      "Minibatch loss at step 18900: 0.240793\n",
      "Minibatch loss at step 19000: 0.263045\n",
      "Minibatch loss at step 19100: 0.317606\n",
      "Minibatch loss at step 19200: 0.561768\n",
      "Minibatch loss at step 19300: 1.779343\n",
      "Minibatch loss at step 19400: 0.555228\n",
      "Minibatch loss at step 19500: 0.301800\n",
      "Minibatch loss at step 19600: 0.470481\n",
      "Minibatch loss at step 19700: 0.390448\n",
      "Minibatch loss at step 19800: 0.345220\n",
      "Minibatch loss at step 19900: 0.110892\n",
      "Minibatch loss at step 20000: 0.323562\n",
      "Minibatch loss at step 20100: 0.487733\n",
      "Minibatch loss at step 20200: 0.590531\n",
      "Minibatch loss at step 20300: 0.547975\n",
      "Minibatch loss at step 20400: 0.300912\n",
      "Minibatch loss at step 20500: 0.433102\n",
      "Minibatch loss at step 20600: 0.388257\n",
      "Minibatch loss at step 20700: 0.225931\n",
      "Minibatch loss at step 20800: 0.773299\n",
      "Minibatch loss at step 20900: 0.681158\n",
      "Minibatch loss at step 21000: 0.130802\n",
      "Minibatch loss at step 21100: 0.235138\n",
      "Minibatch loss at step 21200: 0.244547\n",
      "Minibatch loss at step 21300: 0.844028\n",
      "Minibatch loss at step 21400: 0.168453\n",
      "Minibatch loss at step 21500: 0.778883\n",
      "Minibatch loss at step 21600: 0.320575\n",
      "Minibatch loss at step 21700: 0.229644\n",
      "Minibatch loss at step 21800: 1.138306\n",
      "Minibatch loss at step 21900: 0.206836\n",
      "Minibatch loss at step 22000: 0.218232\n",
      "Minibatch loss at step 22100: 1.357517\n",
      "Minibatch loss at step 22200: 0.149938\n",
      "Minibatch loss at step 22300: 0.294386\n",
      "Minibatch loss at step 22400: 0.074506\n",
      "Minibatch loss at step 22500: 0.283791\n",
      "Minibatch loss at step 22600: 0.194990\n",
      "Minibatch loss at step 22700: 0.162283\n",
      "Minibatch loss at step 22800: 1.693314\n",
      "Minibatch loss at step 22900: 0.278517\n",
      "Minibatch loss at step 23000: 0.273308\n",
      "Minibatch loss at step 23100: 0.199686\n",
      "Minibatch loss at step 23200: 0.235381\n",
      "Minibatch loss at step 23300: 0.283484\n",
      "Minibatch loss at step 23400: 1.445218\n",
      "Minibatch loss at step 23500: 0.066904\n",
      "Minibatch loss at step 23600: 1.034102\n",
      "Minibatch loss at step 23700: 0.334237\n",
      "Minibatch loss at step 23800: 0.130033\n",
      "Minibatch loss at step 23900: 0.189780\n",
      "Minibatch loss at step 24000: 0.267530\n",
      "Minibatch loss at step 24100: 0.273046\n",
      "Minibatch loss at step 24200: 0.087742\n",
      "Minibatch loss at step 24300: 0.407221\n",
      "Minibatch loss at step 24400: 0.106932\n",
      "Minibatch loss at step 24500: 0.234990\n",
      "Minibatch loss at step 24600: 0.254324\n",
      "Minibatch loss at step 24700: 0.241227\n",
      "Minibatch loss at step 24800: 0.274170\n",
      "Minibatch loss at step 24900: 0.171487\n",
      "Minibatch loss at step 25000: 0.104733\n",
      "Minibatch loss at step 25100: 0.166963\n",
      "Minibatch loss at step 25200: 0.144948\n",
      "Minibatch loss at step 25300: 0.308323\n",
      "Minibatch loss at step 25400: 0.372121\n",
      "Minibatch loss at step 25500: 1.413770\n",
      "Minibatch loss at step 25600: 0.158214\n",
      "Minibatch loss at step 25700: 0.060248\n",
      "Minibatch loss at step 25800: 0.019272\n",
      "Minibatch loss at step 25900: 0.145595\n",
      "Minibatch loss at step 26000: 0.136563\n",
      "Minibatch loss at step 26100: 0.382577\n",
      "Minibatch loss at step 26200: 0.305326\n",
      "Minibatch loss at step 26300: 0.122268\n",
      "Minibatch loss at step 26400: 0.134030\n",
      "Minibatch loss at step 26500: 0.652167\n",
      "Minibatch loss at step 26600: 0.898645\n",
      "Minibatch loss at step 26700: 0.174304\n",
      "Minibatch loss at step 26800: 0.102663\n",
      "Minibatch loss at step 26900: 0.222599\n",
      "Minibatch loss at step 27000: 0.196838\n",
      "Minibatch loss at step 27100: 0.169060\n",
      "Minibatch loss at step 27200: 0.158052\n",
      "Minibatch loss at step 27300: 0.285065\n",
      "Minibatch loss at step 27400: 0.163020\n",
      "Minibatch loss at step 27500: 0.262155\n",
      "Minibatch loss at step 27600: 0.565628\n",
      "Minibatch loss at step 27700: 0.127586\n",
      "Minibatch loss at step 27800: 0.116779\n",
      "Minibatch loss at step 27900: 0.205948\n",
      "Minibatch loss at step 28000: 0.101185\n",
      "Minibatch loss at step 28100: 0.453152\n",
      "Minibatch loss at step 28200: 0.175294\n",
      "Minibatch loss at step 28300: 0.259385\n",
      "Minibatch loss at step 28400: 0.106584\n",
      "Minibatch loss at step 28500: 0.273667\n",
      "Minibatch loss at step 28600: 0.182612\n",
      "Minibatch loss at step 28700: 0.062098\n",
      "Minibatch loss at step 28800: 0.043988\n",
      "Minibatch loss at step 28900: 0.059083\n",
      "Minibatch loss at step 29000: 0.279337\n",
      "Minibatch loss at step 29100: 0.123068\n",
      "Minibatch loss at step 29200: 0.098137\n",
      "Minibatch loss at step 29300: 0.621024\n",
      "Minibatch loss at step 29400: 0.270106\n",
      "Minibatch loss at step 29500: 1.001060\n",
      "Minibatch loss at step 29600: 0.046687\n",
      "Minibatch loss at step 29700: 0.040088\n",
      "Minibatch loss at step 29800: 0.261322\n",
      "Minibatch loss at step 29900: 0.165829\n",
      "Minibatch loss at step 30000: 0.058415\n",
      "Test accuracy: 92.7%\n"
     ]
    }
   ],
   "source": [
    "num_steps = 30001\n",
    "\n",
    "def accuracy(predictions, labels):\n",
    "  return (100.0 * np.sum(np.argmax(predictions, 1) == np.argmax(labels, 1))\n",
    "          / predictions.shape[0])\n",
    "\n",
    "with tf.Session(graph=graph) as session:\n",
    "  tf.initialize_all_variables().run()\n",
    "  lossVec = []\n",
    "  trainAcc = []\n",
    "  validAcc = []\n",
    "  print(\"Initialized\")\n",
    "  for step in range(num_steps):\n",
    "    # Pick an offset within the training data, which has been randomized.\n",
    "    # Note: we could use better randomization across epochs.\n",
    "    offset = (step * batch_size) % (train_labels.shape[0] - batch_size)\n",
    "    # Generate a minibatch.\n",
    "    batch_data = train_dataset[offset:(offset + batch_size), :]\n",
    "    batch_labels = train_labels[offset:(offset + batch_size), :]\n",
    "    # Prepare a dictionary telling the session where to feed the minibatch.\n",
    "    # The key of the dictionary is the placeholder node of the graph to be fed,\n",
    "    # and the value is the numpy array to feed to it.\n",
    "    feed_dict = {tf_train_dataset : batch_data, tf_train_labels : batch_labels}\n",
    "    _, l, predictions = session.run([optimizer, loss, train_prediction], feed_dict=feed_dict)\n",
    "    lossVec.append(l)\n",
    "    if (step % 100 == 0):\n",
    "      print(\"Minibatch loss at step %d: %f\" % (step, l))\n",
    "      #print(\"Minibatch accuracy: %.1f%%\" % accuracy(predictions, batch_labels))\n",
    "      #print(\"Validation accuracy: %.1f%%\" % accuracy(valid_prediction.eval(), valid_labels))\n",
    "      \n",
    "      trainAcc.append(accuracy(predictions, batch_labels))\n",
    "      validAcc.append(accuracy(valid_prediction.eval(), valid_labels))\n",
    "  print(\"Test accuracy: %.1f%%\" % accuracy(test_prediction.eval(), test_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save train and valid accuracy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fName = 'Experiment_1.pickle'\n",
    "\n",
    "try:\n",
    "  f = open(fName, 'wb')\n",
    "  save = {\n",
    "    'lossVec': lossVec,\n",
    "    'trainAcc': trainAcc,\n",
    "    'validAcc': validAcc,\n",
    "    }\n",
    "  pickle.dump(save, f, pickle.HIGHEST_PROTOCOL)\n",
    "  f.close()\n",
    "except Exception as e:\n",
    "  print('Unable to save data to', pickle_file, ':', e)\n",
    "  raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pickle_file = 'Experiment_1.pickle'\n",
    "\n",
    "with open(pickle_file, 'rb') as f:\n",
    "  save = pickle.load(f)\n",
    "  lossVec = save['lossVec']\n",
    "  trainAcc = save['trainAcc']\n",
    "  validAcc = save['validAcc']\n",
    "  del save  # hint to help gc free up memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZkAAAEPCAYAAACQmrmQAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1453f5ad0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZMAAAEPCAYAAACHuClZAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nctT8fyMWkhPLiEGGAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x152a4f710>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib \n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.clf()\n",
    "plt.plot(lossVec)\n",
    "plt.xlabel('Steps')\n",
    "plt.ylabel('Loss')\n",
    "axes = plt.gca()\n",
    "axes.set_ylim([0,200])\n",
    "plt.show()\n",
    "\n",
    "plt.clf()\n",
    "plt.plot(xrange(0,30001,100),trainAcc, label= \"Minibatch Accuracy\")\n",
    "plt.plot(xrange(0,30001,100),validAcc, label= \"Valid Accuracy\")\n",
    "axes = plt.gca()\n",
    "axes.set_ylim([70,100])\n",
    "plt.xlabel('Steps')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend(loc=4)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test accuracy with a 1-hidden layer neural network with rectified linear units (nn.relu()) and 1024 hidden nodes is: 89.2%"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "default_view": {},
   "name": "2_fullyconnected.ipynb",
   "provenance": [],
   "version": "0.3.2",
   "views": {}
  },
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
